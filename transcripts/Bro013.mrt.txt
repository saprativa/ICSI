We're going? O_K. O_K. Sh- Close your door on - door on the way out? Thanks. Thanks. Oh. Yeah. Probably wanna get this other door, too. O_K. So. Um. What are we talking about today? Uh, well, first there are perhaps these uh Meeting Recorder digits Oh, yeah. That was kind of uh interesting. The - both the uh - that we tested. So. Um. the S_R_I System and the oth- And for one thing that - that sure shows the difference between having a lot of uh Of data? training data Yeah. or not, uh, the uh - The best kind of number we have on the English uh - on near microphone only is - is uh three or four percent. Mm-hmm. And uh it's significantly better than that, using fairly simple front-ends on - on the uh - Mm-hmm. uh, with the S_R_I system. So I th- I think that the uh - But that's - that's using uh a - a pretty huge amount of data, mostly not digits, of course, but - but then again - Well, yeah. In fact , mostly not digits for the actual training the H_M_ Ms whereas uh in this case we're just using digits for training the H_M_Ms. Yeah. Right. Did anybody mention about whether the - the S_R_I system is a - is - is doing the digits um the wor- as a word model or as uh a sub- s- sub-phone states? I guess it's - it's uh allophone models, so, well - Yeah. Probably. Huh? Yeah. I think so, because it's their very d- huge, their huge system. Yeah. And. But. So. There is one difference - Well, the S_R_I system - the result for the S_R_I system that are represented here are with adaptation. So there is - It's their complete system and - including on-line uh unsupervised adaptation. That's true. And if you don't use adaptation, the error rate is around fifty percent worse, I think, if I remember. Yeah. O_K. It's tha- it's that much, huh? Nnn. It's - Yeah. It's quite significant. Yeah. Oh. O_K. Still. Mm-hmm. But - but uh what - what I think I'd be interested to do given that, is that we - we should uh take - I guess that somebody's gonna do this, right? - is to take some of these tandem things and feed it into the S_R_I system, right? Yeah. Yeah. We can do something like that . Yeah. Yeah. Because - But - But I guess the main point is the data because uh I am not sure. Our back-end is - is fairly simple but until now, well, the attempts to improve it or - have fail- Ah, well, I mean uh what Chuck tried to - to - to do Yeah, but he's doing it with the same data, right? I mean so to - Yeah. So it's - Yeah. So there's - there's - there's two things being affected. I mean. One is that - that, you know, there's something simple that's wrong with the back-end. We've been playing a number of states uh I - I don't know if he got to the point of playing with the uh number of Gaussians yet but - but uh, Mm-hmm. Mm-hmm. uh, you know. But, yeah, so far he hadn't gotten any big improvement, but that's all with the same amount of data which is pretty small. Mm-hmm. Yeah. Mmm. And um. So, yeah, we could retrain some of these tandem Well, you could do that, but I'm saying even with it not - with that part not retrained, on - on huge - Ah, yeah. Just - just - just using - having the H_M_Ms - f- for the H_M_M models. Yeah. Mm-hmm. much better H_M_ Ms. Yeah. Mm-hmm. Um. But just train those H_M_Ms using different features, the features coming from our Aurora stuff. So. Yeah. Yeah. But what would be interesting to see also is what - what - perhaps it's not related, the amount of data but the um recording conditions. I don't know. Because it's probably not a problem of noise, because our features are supposed to be robust to noise. Well, yeah. It's not a problem of channel, because there is um normalization with respect to the channel. So - I - I - I'm sorry. What - what is the problem that you're trying to explain? The - the fact that - the result with the tandem and Aurora system are That the - Oh. So much worse? uh so much worse. Yeah. Oh. I uh but I'm - I'm almost certain that it - it - It - I mean, that it has to do with the um amount of training data. It - it's - it's orders of magnitude off. Yeah but - Yeah. Yeah but we train only on digits and it's - it's a digit task, so. Well. But - but having a huge - If - It - if you look at what commercial places do, they use a huge amount of data. This is a modest amount of data. Mm-hmm. Alright. Yeah. Mm-hmm. So. I mean, ordinarily you would say "well, given that you have enough occurrences of the digits, you can just train with digits rather than with, you know" - Mm-hmm. But the thing is, if you have a huge - in other words, do word models - But if you have a huge amount of data Right. Mmm. then you're going to have many occurrences of similar uh allophones. Yeah. And that's just a huge amount of training for it. So it's um - Mm-hmm. I - I think it has to be that, because, as you say, this is, you know, this is near-microphone, it's really pretty clean data. Mm-hmm. Um. Now, some of it could be the fact that uh - let's see, in the - in these multi-train things did we include noisy data in the Yeah. training? I mean, that could be hurting us actually, for the clean case. Yeah. Well, actually we see that the clean train for the Aurora proposals are - It is if - are better than the multi-train, yeah. Yeah. Yeah. Cuz this is clean data, and so that's not too surprising. Mm-hmm. But um. Uh. So. Well, o- I guess what I meant is that well, let's say if we - if we add enough data to train on the um Uh-huh. on the Meeting Recorder digits, Mm-hmm. I guess we could have better results than this. And. What I meant is that perhaps we can learn something uh from this, what's - what's wrong uh what - what is different between T_I-digits and these digits and - What kind of numbers are we getting on T_I-digits? It's point eight percent, so. Oh. I see. Four- Fourier. @@ So in the actual T_I-digits database we're getting point eight percent, Yeah. Yeah. and here we're getting three or four - three, let's see, three for this? Mm-hmm. Yeah. Sure, but I mean, um point eight percent is something like double uh or triple what people have gotten who've worked very hard at doing that. And - and also, as you point out, there's adaptation in these numbers also. Mm-hmm. Mmm. So if you, you know, put the ad- adap- take the adaptation off, then it - for the English-Near you get something like two percent. And here you had, you know, something like three point four. Mm-hmm. And I could easily see that difference coming from this huge amount of data that it was trained on. So it's - Mm-hmm. You know, I don't think there's anything magical here. It's, you know, we used a simple H_T_K system with a modest amount of data. And this is a - a, you know, modern uh system uh has - has a lot of nice points to it. Yeah. Yeah. Mm-hmm. Um. So. I mean, the H_T_K is an older H_T_K, even. So. Mm-hmm. Yeah it - it's not that surprising. But to me it just - it just meant a practical point that um if we want to publish results on digits that - that people pay attention to we probably should uh - Cuz we've had the problem before that you get - show some nice improvement on something that's - that's uh, uh - it seems like too large a number, and uh uh people don't necessarily take it so seriously. Mm-hmm. Um. Yeah. Yeah. So the three point four percent for this uh is - is uh - So why is it - It's an interesting question though, still. Why is - why is it three point four percent for the d- the digits recorded in this environment as opposed to the uh point eight percent for - for - for the original T_I-digits database? Um. Yeah. th- that's - th- that's my point I - I - I don't Given - given the same - Yeah. So ignore - ignoring the - the - the S_R_I system for a moment, just looking at I - Mm-hmm. the T_I-di- the uh tandem system, if we're getting point eight percent, which, yes, it's high. It's, you know, it - it's not awfully high, but it's, you know - it's - it's high. Mm-hmm. Um. Why is it uh four times as high, or more? Yeah, I guess. Right? I mean, there's - even though it's close-miked there's still - there really is background noise. Mm-hmm. Um. And uh I suspect when the T_I-digits were recorded if somebody fumbled or said something wrong or something that they probably made them take it over. Mm-hmm. It was not - I mean there was no attempt to have it be realistic in any - in any sense at all. Well. Yeah. And acoustically, it's q- it's - I listened. It's quite different. T_I-digit is - it's very, very clean and it's like studio recording Mm-hmm. whereas these Meeting Recorder digits sometimes you have breath noise and Mmm. Right. Yeah. So I think they were - It's not controlled at all, I mean. Bless you. Thanks. I - Yeah. I think it's - it's - Mm-hmm. But- So. Yes. It's - I think it's - it's the indication it's harder. Yeah. Uh. Yeah and again, you know, i- that's true either way. I mean so take a look at the uh - um, the S_R_I results. I mean, they're much much better, but still you're getting something like one point three percent Mm-hmm. for uh things that are same data as in T_ - T_I-digits the same - same text. Uh. And uh, I'm sure the same - same system would - would get, you know, point - point three or point four or something on the actual T_I-digits. So this - I think, on both systems the these digits are showing up as harder. Mmm. Um. Mm-hmm. Which I find sort of interesting cause I think this is closer to - uh I mean it's still read. But I still think it's much closer to - to what - what people actually face, um when they're - they're dealing with people saying digits over the telephone. I mean. I don't think uh - I mean, I'm sure they wouldn't release the numbers, but I don't think that uh the uh - the - the companies that - that do telephone speech get anything like point four percent on their digits. I'm - I'm - I'm sure they get - Uh, I mean, for one thing people do phone up who don't have uh uh Middle America accents and Mm-hmm. it's a we- we it's - it's - it's U_S. it has - has many people who sound in many different ways. So. Um. I mean. O_K. That was that topic. What else we got? Um. But - Did we end up giving up on - on, any Eurospeech submissions, or - ? I know Thilo and Dan Ellis are - are submitting something, but uh. Yeah. I - I guess e- the only thing with these - the Meeting Recorder and, well, - So, I think, yeah - I think we basically gave up. Um. But - Now, actually for the - for the Aur- uh we do have stuff for Aurora, right? Because - because we have ano- an extra month or something. Yeah. Yeah. Yeah. So. Yeah, for sure we will Yeah. do something for Well, that's fine. So th- so - so we have a couple - a couple little things on Meeting Recorder and we have - the special session. Yeah. Mm-hmm. We don't - we don't have to flood it with papers. We're not trying to prove anything to anybody. so. That's fine. Um. Anything else? Yeah. Well. So. Perhaps the point is that we've been working on is, yeah, we have put the um the good V_A_D in the system and it really makes a huge difference. Um. So, yeah. I think, yeah, this is perhaps one of the reason why our system was not - not the best, because with the new V_A_D, it's very - the results are similar to the France Telecom results and Hmm. perhaps even better sometimes. Huh. Um. So there is this point. Uh. The problem is that it's very big and we still have to think how to - where to put it and - um, Mm-hmm. because it - it - well, this V_A_D uh either some delay and we - if we put it on the server side, it doesn't work, because on the server side features you already have L_D_A applied from the f- from the terminal side and so you accumulate the delay so the V_A_D should be before the L_D_A which means perhaps on the terminal side and then smaller and So wha- where did this good V_A_D come from? So. It's um from O_G_I. So it's the network trained - it's the network with the huge amounts on hidden - of hidden units, and um nine input frames compared to the V_A_D that was in the proposal which has a very small amount of hidden units and fewer inputs. This is the one they had originally? Oh. Yeah. Yeah, but they had to get rid of it because of the space, didn't they? Yeah. So. Yeah. But the abso- assumption is that we will be able to make a V_A_D that's small and that works fine. And. Well. So that's a problem. Yeah. So we can - Yeah but - nnn. But the other thing is uh to use a different V_A_D entirely. I mean, uh i- if - if there's a if - if - I - I don't know what the thinking was amongst the - the - the the ETSI folk but um Mm-hmm. if everybody agreed sure let's use this V_A_D and take that out of there - Mm-hmm. They just want, apparently - they don't want to fix the V_A_D because they think there is some interaction between feature extraction and - and V_A_D or frame dropping But they still want to - just to give some um requirement for this V_A_D because it's - it will not be part of - they don't want it to be part of the standard. O_K. So. So it must be at least uh somewhat fixed but not completely. So there just will be some requirements that are still not - uh not yet uh ready I think. Determined. I see. Nnn. But I was thinking that - that uh s "Sure, there may be some interaction, but I don't think we need to be stuck on using our or O_G_I's V_A_D. We could use somebody else's if it's smaller or - Yeah. You know, as long as it did the job. Mm-hmm. So that's good. Uh. So there is this thing. There is um - Yeah. Uh I designed a new - a new filter because when I designed other filters with shorter delay from the L_D_A filters, there was one filter with fif- sixty millisecond delay and the other with ten milliseconds and Right. uh Hynek suggested that both could have sixty-five sixty-s- I think it's sixty-five. Yeah. Yeah. Both should have sixty-five because - Yeah. You didn't gain anything, right? And. So I did that and uh it's running. So, let's see what will happen. Uh but the filter is of course closer to the reference filter. Mm-hmm. Mmm. Um. Yeah. I think - So that means logically, in principle, it should be better. So probably it'll be worse. Yeah Or in the basic perverse nature uh of reality. Yeah. O_K. Yeah. Sure. Yeah. O_K. Yeah, and then we've started to work with this of um voiced-unvoiced Mm-hmm. stuff. And next week I think we will perhaps try to have um a new system with uh uh M_S_G stream also see what - what happens. So, something that's similar to the proposal too, but with M_S_G stream. Mm-hmm. Mm-hmm. Mmm. O_K. No, I w- I begin to play with Matlab and to found some parameter robust for voiced-unvoiced decision. But only to play. And we - they - we found that maybe w- is a classical parameter, the sq- the variance between the um F_F_T of the signal and the small spectrum of time we - after the um mel filter bank. Uh-huh. And, well, is more or less robust. Is good for clean speech. Is quite good Huh? for noisy speech. Mm-hmm. but um we must to have bigger statistic with TIMIT, and is not ready yet Mm-hmm. Yeah. to use on, well, I don't know. Yeah. Yeah. So, basically we wa- want to look at something like the ex- the ex- excitation signal and - Right. Mm-hmm. which are the variance of it and - I have here. I have here Mmm. for one signal, for one frame. Yeah. The - the mix of the two, noise and unnoise, and the signal is this. Uh-huh. Clean, and this noise. Uh. These are the two - the mixed, the big signal is for clean. Well, I'm s- uh - There's - None of these axes are labeled, so I don't know what this - What's this axis? Uh this is uh - this axis is nnn, "frame". Frame. Mm-hmm. And what's th- what this? Uh, this is uh energy, log-energy of the spectrum. Of the - No, this is the variance, the difference between the spectrum of the signal and F_F_T of each frame of the signal and this mouth spectrum of time after the f- For this one. may fit For the noi- for the two, this big, to here, they are to signal. This is for clean and this is for noise. Oh. There's two things on the same graph. Yeah. I don't know. I - I think that I have d- another graph, but I'm not sure. Yeah. So w- which is clean and which is noise? I think the lower one is noise. The lower is noise and the height is clean. O_K. So it's harder to distinguish It's height. but it - but it g- with noise of course but - but - Yeah. Oh. I must to have. Pity, but I don't have Uh. two different And presumably when there's a - a - So this should the - the - the t- voiced Uh-huh. Yeah, it is the height portions. is voiced portion. The p- the peaks should be voiced portion. And this is the noise portion. Uh-huh. And this is more or less like this. But I meant to have see @@ two - two the picture. Yeah. Yeah. This is, for example, for one frame. Yeah the - the spectrum of the signal. And this is the small version of the spectrum after M_L mel filter bank. Yeah. And this is the difference? And this is I don't know. This is not the different. This is trying to obtain with L_P_C model the spectrum but using Matlab without going factor and s- No pre-emphasis? Yeah. Not pre-emphasis. Nothing. Yeah so it's - doesn't do too well there. And the - I think that this is good. This is quite similar. this is - this is another frame. ho- how I obtained the envelope, this envelope, with the mel filter bank. Right. So now I wonder - I mean, do you want to - I know you want to get at something orthogonal from what you get with the smooth spectrum Um. But if you were to really try and get a voiced-unvoiced, do you - do you want to totally ignore that? I mean, do you - do you - I mean, clearly a - a very big - very big cues for voiced-unvoiced come from uh spectral slope and so on, right? Mm-hmm. Um. Yeah. Well, this would be - this would be perhaps an additional parameter, simply isn't - Yeah. I see. Yeah. Yeah because when did noise Uh. clear in these section is clear Mm-hmm. if s- @@ val- value is indicative that is a voice frame and it's low values @@ Yeah. Yeah. Well, you probably want - I mean, certainly if you want to do good voiced-unvoiced detection, you need a few features. Each - each feature is by itself not enough. But, you know, people look at - at slope and uh Mmm. first auto-correlation coefficient, divided by power. Or - or uh um there's uh - I guess we prob- probably don't have enough computation to do a simple pitch detector or something? I mean with a pitch detector you could have a - Mmm. have a - an estimate of - of what the - Uh. Or maybe you could you just do it going through the P_ F_F_T's figuring out some um probable um harmonic structure. Right. And - and uh. Mmm. you have read up and - you have a paper, the paper that you s- give me yesterday. Oh, yeah. But - they say that yesterday they are some problem Yeah, but it's not - it's, yeah, it's - it's another problem. Yeah and the - Is another problem. Um. Yeah, there is th- this fact actually. If you look at this um spectrum, Yeah. What's this again? Is it the mel-filters? Yeah like this. Of kind like this. Yeah. O_K. So the envelope here is the output of the mel-filters Mm-hmm. and what we clearly see is that in some cases, and it clearly appears here, and the - the harmonics are resolved by the f- Well, there are still appear after mel-filtering, Mm-hmm. and it happens for high pitched voice because the width of the lower frequency mel-filters is sometimes even smaller than the pitch. Yeah. It's around one hundred, one hundred and fifty hertz Right. Nnn. And so what happens is that this uh, add additional variability to this envelope and Yeah. um so we were thinking to modify the mel-spectrum to have something that - that's smoother on low frequencies. That's as - as a separate thing. Yeah. i- Yeah. This is a separate thing. Yeah. Separate thing? Yeah. And. Yeah. Maybe so. Um. Yeah. So, what - Yeah. What I was talking about was just, starting with the F_F_T you could - you could uh do a very rough thing to estimate - estimate uh pitch. Yeah. Mm-hmm. And uh uh, given - you know, given that, uh you could uh uh come up with some kind of estimate of how much of the low frequency energy was - was explained by - by uh Mm-hmm. uh those harmonics. Uh. It's uh a variant on what you're s- what you're doing . The - I mean, the - the the mel does give a smooth thing. But as you say it's not that smooth here. And - and so if you - if you just you know subtracted off uh your guess of the harmonics then something like this would end up with quite a bit lower energy in the first fifteen hundred hertz or so and - Mm-hmm. and our first kilohertz, even. And um if was uh noisy, the proportion that it would go down would be if it was - if it was unvoiced or something. Mm-hmm. So you oughta be able to pick out voiced segments. At least it should be another - another cue. Mm-hmm. So. Anyway. O_K? That's what's going on. Uh. What's up with you? Um our t- I went to talk with uh Mike Jordan this - this week Mm-hmm. um and uh shared with him the ideas about um extending the Larry Saul work and um I asked him some questions about factorial H_M_Ms so like later down the line when we've come up with these - these feature detectors, how do we - how do we uh you know, uh model the time series that - that happens um and and we talked a little bit about factorial H_M_Ms and how um when you're doing inference - or w- when you're doing recognition, there's like simple Viterbi stuff that you can do for - for these H_M_Ms and the uh - the great advantages that um a lot of times the factorial H_M_Ms don't um don't over- alert the problem there they have a limited number of parameters and they focus directly on - on uh the sub-problems at hand so you can imagine um five or so parallel um features um transitioning independently and then at the end you - you uh couple these factorial H_M_Ms with uh - with uh undirected links um based on - Hmm. based on some more data. So he - he seemed - he seemed like really interested in - in um - in this and said - said this is - this is something very do-able and can learn a lot and um yeah, I've just been continue reading um about certain things. Mm-hmm. um thinking of maybe using um um m- modulation spectrum stuff to um - as features um also in the - in the sub-bands because Mm-hmm. it seems like the modulation um spectrum tells you a lot about the intelligibility of - of certain um words and stuff So, um. Yeah. Just that's about it. O_K. O_K. And um so I've been looking at Avendano's work and um uh I'll try to write up in my next stat- status report a nice description of what he's doing, but it's - it's an approach to deal with reverberation or that - the aspect of his work that I'm interested in the idea is that um normally an- analysis frames are um too short to encompass reverberation effects um in full. You miss most of the reverberation tail in a ten millisecond window and so you - you'd like it to be that um the reverberation responses um simply convolved um in, but it's not really with these ten millisecond frames cuz you j- But if you take, say, a two millisecond um window - I'm sorry a two second window then in a room like this, most of the reverberation response is included in the window and the - then it um then things are l- more linear. It is - it is more like the reverberation response is simply c- convolved and um - and you can use channel normalization techniques like uh in his thesis he's assuming that the reverberation response is fixed. He just does um mean subtraction, which is like removing the D_C component of the modulation spectrum and that's supposed to d- um deal - uh deal pretty well with the um reverberation and um the neat thing is you can't take these two second frames and feed them to a speech recognizer um so he does this um method training trading the um the spectral resolution for time resolution and um come ca- uh synthesizes a new representation which is with say ten second frames but a lower s- um frequency resolution. So I don't really know the theory. I guess it's - these are called "time frequency representations" and h- he's making the - the time sh- um finer grained and the frequency resolution um less fine grained. Mm-hmm. s- so I'm - I guess my first stab actually in continuing his work is to um re-implement this - this thing which um changes the time and frequency resolutions cuz he doesn't have code for me. So that that'll take some reading about the theory. I don't really know the theory. Mm-hmm. Oh, and um, another f- first step is um, so the - the way I want to extend his work is make it able to deal with a time varying reverberation response um and um we don't really know how fast the um - the reverberation response is varying the Meeting Recorder data um so um we - we have this um block least squares um imp- echo canceller implementation and um I want to try finding the - the response, say, between a near mike and the table mike for someone using the echo canceller and looking at the echo canceller taps and then see how fast that varies from block to block. That should give an idea of how fast the reverberation response is changing. Mm-hmm. Mm-hmm. O_K. Um. I think we're sort of done. Yeah. So let's read our digits and go home. O_K. I'm reading transcript L_ dash forty three four nine one one O_ five one eight three six two O_ five seven O_ four one nine six O_ one four four nine five seven three seven six one four two O_ five two seven eight nine nine three six six three eight nine seven one seven eight three one nine three O_ one nine five seven five five one eight zero eight two nine eight four six one nine four eight one two Um. S- so um y- you do - I think you read some of the - the zeros as O_'s and some as zeros. Yeah. Is there a particular way we're supposed to read them? There are only zeros here. Well. No. "O_" - "O_" - "O_" and "zero" are two ways that we say that digit. Eee. Yeah. So it's - But - Ha! so it's - i- Perhaps in the sheets there should be another sign for the - if we want to - the - the guy to say "O_" or No. I mean. I think people will do what they say. It's O_K . It's - Yeah. O_K. Alright. I mean in digit recognition we've done before, you have - you have two pronunciations for that value, "O_" and "zero". O_K. But it's perhaps more difficult for the people to prepare the database then, if - because here you only have zeros and - and people pronounce "O_" or zero - No, they just write - they - they write down O_H. or they write down Z_E_R_O a- and they - and they each have their own pronunciation. Yeah but if the sh- the sheet was prepared with a different sign for the "O_". But people wouldn't know what that wa- I mean there is no convention for it. O_K. Yeah. O_K. See. I mean, you'd have to tell them "O_K when we write this, say it tha-", you know, and you just - They just want people to read the digits as you ordinarily would and - and people Mm-hmm. Yeah. Yep. say it different ways. O_K. Is this a change from the last batch of - of um forms? Because in the last batch it was spelled out which one you should read. Yeah, it was orthographic, so. Yes. That's right. It was - it was spelled out, and they decided they wanted to get at more the way people would really say things. That's also why they're - they're bunched together in these different groups. So - so it's - Yeah. So it's - it's - Everything's fine. Oh. O_K. O_K. O_K. O_K. Uh. Transcript L_ dash three nine. one three two six one zero one four two four seven five nine three eight seven two six two six two seven six seven three four two two two four two nine six four O_ four O_ eight eight two eight seven nine nine four O_ O_ eight two seven eight zero three nine five one two three eight four three five five nine eight one four two zero two zero nine two nine two six Actually, let me just s- since - since you brought it up, I was just - it was hard not to be self-conscious about that when it after we - since we just discussed it. But I realized that - that um when I'm talking on the phone, certainly, and - and saying these numbers, I almost always say zero. And uh - cuz - because uh i- it's two syllables. It's - it's more likely they'll understand what I said. So that - that - that's the habit I'm in, but some people say "O_" and - Yeah I normally say "O_" cuz it's easier to say. Yeah it's shorter. Yeah. So it's - So. So uh. Now, don't think about it. "O_" Oh, no! O_K. I'm reading transcript L_ thirty eight five four five O_ three two eight five eight three three eight nine O_ four one O_ nine eight five O_ seven one one one four O_ two one six one eight two five six seven eight five seven six eight two O_ O_ O_ four seven O_ O_ five eight seven seven seven five six five six one three seven one nine one three four three six O_ O_ nine nine two two O_ I'm reading transcript L_ dash thirty seven. O_ five one nine O_ three two seven one six six nine six two seven O_ two six four five one O_ five four two nine five O_ O_ one seven one one two seven one eight one two three four O_ eight four five seven six two two nine eight two three six seven two six seven six four nine two seven three one two five three nine three six eight six one nine one seven seven Transcript L_ dash thirty six O_ four four one six two nine O_ four seven three eight four five six five four six eight eight three one two five two five four five nine nine seven zero six nine eight five eight five one zero eight three two nine seven three one four five six four nine three eight four four two two three four five three O_ two four five four two two six eight two one eight nine eight one nine O_K. We're done. 