O_K. Mike. Mike-one? Ah. We're on? Have a good meeting. Do you want this closed? Yes, please. I mean, we're testing noise robustness but let's not get silly. O_K, so, uh, you've got some, uh, Xerox things to pass out? That are - Yeah. Yeah, um. Yeah. Yeah, I'm sorry for the table, but as it grows in size, uh, it. Uh, so for th- the last column we use our imagination. O_K. Ah, yeah. Ah. Uh , yeah. This one's nice, though. This has nice big font. Uh, do you want @@ . Yeah. @@ Let's see. Yeah. Yeah. Chop! When you get older you have these different perspectives. I mean, lowering the word hour rate is fine, but having big font! So I- That's what's - Next time we will put colors or something . Yeah. It's mostly big font. Uh. O_K. Uh - O_K, s- Go ahead. so there is kind of summary of what has been done - It's this. Summary of experiments since, well, since last week and also since the - Oh. O_K. we've started to run - work on this. Um. So since last week we've started to fill the column with um uh features w- with nets trained on P_L_P with on-line normalization but with delta also, because the column was not completely - well, it's still not completely filled, but Mm-hmm. Mm-hmm. we have more results to compare with network using without P_L_P and finally, hhh, um ehhh P_L- uh delta seems very important. Uh I don't know. If you take um, let's say, anyway Aurora-two-B_, so, the next - t- the second, uh, part of the table, Mm-hmm. uh when we use the large training set using French, Spanish, and English, you have one hundred and six Mm-hmm. without delta and eighty-nine with the delta. a- And again all of these numbers are with a hundred percent being, uh, the baseline performance, but with a mel cepstra system going straight into the H_T_K? Yes. Yeah, on the baseline, yeah. So - Yeah. Yeah. So now we see that the gap between the different training set is much uh uh much smaller It's out of the way. um - Right. But, actually, um, for English training on TIMIT is still better than the other languages. And Mmm, Yeah. And f- also for Italian, actually. If you take the second set of experiment for Italian, so, the mismatched condition, Mm-hmm. um when we use the training on TIMIT so, it's multi-English, we have a ninety-one number, Mm-hmm. and training with other languages is a little bit worse. Um - Oh, I see. Down near the bottom of this sheet. Uh, yes. So, yeah. O_K. And, yeah, and here the gap is still more important between using delta and not using delta. If y- if I take the training s- the large training set, it's - we have one hundred and seventy-two, Yes. Yeah. and one hundred and four when we use delta. Mm-hmm. Uh. Even if the contexts used is quite the same, because without delta we use seventeenths - seventeen frames. Uh. Yeah, um, so the second point is that we have no single cross-language experiments, uh, that we did not have last week. Uh, so this is training the net on French only, or on English only, and testing on Italian. Mm-hmm. And training the net on French only and Spanish only and testing on, uh T_I-digits. Mm-hmm. And, fff um, yeah. What we see is that these nets are not as good, except for the multi-English, which is always one of the best. Yeah, then we started to work on a large dat- database containing, uh, sentences from the French, from the Spanish, from the TIMIT, from SPINE, uh from uh English digits, and from Italian digits. So this is the - another line - another set of lines in the table. Ah, yes. Mm-hmm. Uh, @@ with SPINE and uh, actually we did this before knowing the result of all the data, uh, so we have to- to redo the uh - the experiment training the net with, uh P_L_P, but with delta. Mm-hmm. But um this - this net performed quite well. Well, it's - it's better than the net using French, Spanish, and English only. Uh. So, uh, yeah. We have also started feature combination experiments. Uh many experiments using features and net outputs together. And this is - The results are on the other document. Uh, we can discuss this after, perhaps - well, just, @@ . Yeah, so basically there are four - four kind of systems. The first one, yeah, is combining, um, two feature streams, uh using - and each feature stream has its own M_P_L. So it's the - kind of similar to the tandem that was proposed for the first. The multi-stream tandem for the first proposal. The second is using features and K_L_T transformed M_L_P outputs. And the third one is to u- use a single K_L_T trans- transform features as well as M_L_P outputs. Um, yeah. Mmm. You know you can - you can comment these results, or - Yes, I can s- I would like to say that, for example, um, mmm, if we doesn't use the delta-delta, uh we have an improve when we use s- some combination. But when w- Yeah, we- ju- just to be clear, the numbers here are Yeah, this - uh recognition accuracy. Yeah, this number recognition acc- So it's not the - Again we switch to another - Yes, and the baseline - the baseline have - i- is eighty-two. Mm-hmm. Baseline is eighty-two. Yeah So it's experiment only on the Italian mismatched for the moment for this. Uh, this is Italian mismatched. O_K. Um. Yeah, by the moment. Mm-hmm. And first in the experiment-one I - I do - I - I use different M_L_P, Mm-hmm. and is obviously that the multi-English M_L_P is the better. Um. for the ne - rest of experiment I use multi-English, only multi-English. And I try to combine different type of feature, but the result is that the M_S_G-three feature doesn't work for the Italian database because never help to increase the accuracy. Yeah, eh, actually, if w- we look at the table, the huge table, Mm-hmm. um, we see that for T_I-digits M_S_G perform as well as the P_L_P, but this is not the case for Italian what - where the error rate is c- is almost uh twice the error rate of P_L_P. Mm-hmm. So, um uh, well, I don't think this is a bug but this - this is something in - probably in the M_S_G um process that uh I don't know what exactly. Perhaps the fact that the - the - there's no low-pass filter, well, or no pre-emp- pre-emphasis filter and that there is some D_C offset in the Italian, or, well, something simple like that. But - that we need to sort out if want to Mm-hmm. uh get improvement by combining P_L_P and M_S_G because for the moment M_S_G do- doesn't bring much information. And Mm-hmm. I- as Carmen said, if we combine the two, we have the result, basically, of P_L_P. Um, the uh, baseline system - when you said the baseline system was uh, uh eighty-two percent, that was trained on what and tested on what? Mm-hmm. That was, uh Italian mismatched d- uh, uh, digits, uh, is the testing, and the training is Italian digits? Yeah. Yeah. So the "mismatch" just refers to the noise and - and, uh microphone and so forth, right? Yeah. Yeah. So, um did we have - So would that then correspond to the first line here of where the training is - is the uh Italian digits? The - 3x The train- the training of the H_T_K? Yes. Ah yes! This h- Yes. Th- Yes. Yes. Yes. Training of the net, yeah. Yeah. So, um - So what that says is that in a matched condition, we end up with a fair amount worse putting in the uh P_L_P. Now w- would - do we have a number, I suppose for the matched - I - I don't mean matched, but uh use of Italian - training in Italian digits for P_L_P only? Uh yes? Uh yeah, so this is - basically this is in the table. Uh so the number is fifty-two, Another table. uh - Fifty-two percent. Fift- So - No. No, fifty-two percent of eighty-two? No, it's - it's the - Of - of - of uh eighteen - of eighteen. Eighty. Eighty. So it's - it's error rate, basically. It's er- error rate ratio. So - It's plus six. Oh this is accuracy! Oy! O_K. Yeah. Uh, so we have nine - nine - let's say ninety percent. Ninety. Yeah. Um which is uh what we have also if use P_L_P and M_S_G together, eighty-nine point seven. Yeah. O_K, so even just P_L_P, uh, it is not, in the matched condition - Um I wonder if it's a difference between P_L_P and mel cepstra, or whether it's that the net half, for some reason, is not helping. Uh. P_- P_L_P and Mel cepstra give the same - Same result pretty much? same results. Well, we have these results. I don't know. It's not - So, s- Do you have this result with P_L_P alone, j- fee- feeding H_T_K? That - That's what you mean? Yeah, yeah yeah yeah yeah, at the first - Just P_L_P at the input of H_T_K. and the - Yeah. Yeah. So, P_L_P - Eighty-eight point six. Yeah. Um, so adding M_S_G Um - um - Well, but that's - yeah, that's without the neural net, right? Yeah, that's without the neural net and that's the result basically that O_G_I has also with the M_F_C_C with on-line normalization. But she had said eighty- two. Right? This is the - w- well, but this is without on-line normalization. Oh, this - Yeah. @@ the eighty- two. Eighty-two is the - it's the Aurora baseline, so M_F_C_C. Then we can use - well, O_G_I, they use M_F_C_C - th- the baseline M_F_C_C Oh, I'm sorry, I k- I keep getting confused because this is accuracy. plus on-line normalization @@ Yeah, sorry. Yeah. O_K. Yeah. Alright. Alright. So this is - I was thinking all this was worse. O_K so this is all better because eighty- nine is bigger than eighty-two. O_K. Yeah. Yes, better. Mm-hmm. Yeah. I'm - I'm all better now. O_K, go ahead. So what happ- what happens is that when we apply on-line normalization Yeah. we jump to almost ninety percent. Mm-hmm. Uh, when we apply a neural network, is the same. We j- jump to ninety percent. Yeah. Nnn, we don't know exactly. And - And um - whatever the normalization, actually. If we use n- neural network, even if the features are not correctly normalized, we jump to ninety percent. So we go from eighty-si- eighty-eight point six to - to ninety, or something. So - Well, ninety - No, I - I mean ninety- It's around eighty-nine, ninety, eighty-eight . Eighty-nine. Yeah. Well, there are minor - minor differences. And then adding the M_S_G does nothing, basically. No. Yeah. O_K. Uh For Italian, yeah. For this case, right? Mm-hmm. Um. Alright. So, um - So actually, the answer for experiments with one is that adding M_S_G, if you - uh does not help in that case. Mm-hmm. Um - The other ones, we'd have to look at it, but - But w- Yeah. And the multi-English, does uh - So if we think of this in error rates, we start off with, uh eighteen percent error rate, roughly. Mm-hmm. Um and we uh almost, uh cut that in half by um putting in the on-line normalization and the neural net. Yeah And the M_S_G doesn't however particularly affect things. No. And we cut off, I guess about twenty-five percent of the error. Uh no, not quite that, is it. Uh, two point six out of eighteen. About, um sixteen percent or something of the error, um, if we use multi-English instead of the matching condition. Mm-hmm. Not matching condition, but uh, the uh, Italian training. Yeah. Yeah. Mm-hmm. O_K. Mmm. We select these - these - these tasks because it's the more difficult. Yes, good. O_K? So then you're assuming multi-English is closer to the kind of thing that you could use since you're not gonna have matching, uh, data for the - uh for the new - for the other languages and so forth. Um, one qu- thing is that, uh - I think I asked you this before, but I wanna double check. When you say "M_E" in these other tests, that's the multi-English, but it is not all of the multi-English, right? It is some piece of - part of it. That's - it's a part - it's - Or, one million frames. And the multi-English is how much? You have here the information. It's one million and a half. Yeah. Oh, so you used almost all- You used two thirds of it, Yeah. you think. So, it- it's still - it hurts you - seems to hurt you a fair amount to add in this French and Spanish. Mmm. Yeah. I wonder why Yeah. Uh. Well Stephane was saying that they weren't hand-labeled, Yeah. Yeah, it's - Yeah. the French and the Spanish. The Spanish. Maybe for that. Yeah. Hmm. Mmm. It's still - O_K. Alright, go ahead. And then - then - Um. Mmm, with the experiment type-two, I - first I tried to- to combine, nnn, some feature from the M_L_P and other feature - another feature. Mm-hmm. And we s- we can - first the feature are without delta and delta-delta, and we can see that in the situation, uh, the M_S_G-three, the same help nothing. Mm-hmm. And then I do the same but with the delta and delta-delta - P_L_P delta and delta-delta. And they all p- but they all put off the M_L_P is it without delta and delta-delta. And we have a l- little bit less result than the - Mm-hmm. the - the baseline P_L_P with delta and delta-delta. Maybe if - when we have the new - the new neural network trained with P_L_P delta and delta-delta, maybe the final result must be better. I don't know. Uh - Actually, just to be some more - Do- This number, this eighty-seven point one number, has to be compared with the um - Which number? Yes, yeah, I mean it can't be compared with the other cuz this is, uh - with multi-English, uh, training. So you have to compare it with the one over that you've got in a box, which is that, uh the eighty-four point six. Mm-hmm. Mm-hmm. Right? Uh. So - Yeah, but I mean in this case for the eighty-seven point one we used M_L_P outputs for the P_L_P net Yeah. and straight features with delta-delta. Yeah. Mm-hmm. And straight features with delta-delta gives you what's on the first sheet. It's eight- eighty-eight point six. Not t- not tr- No. No. No. Not trained with multi- English. Yes. Uh, yeah, but th- this is the second configuration. So we use No, but they - they feature @@ without - feature out- uh, net outputs together with features. So yeah, this is not - perhaps not clear here but in this table, the first column is for M_L_P and the second for the features. Eh. Oh, I see. Ah. So you're saying w- so asking the question, "What - what has adding the M_L_P done to improve over the, uh - Yes. So, just - Yeah so, actually it - it - it decreased the - the accuracy. Yeah. Uh- huh. Because we have eighty-eight point six. And even the M_L_P alone - What gives the M_L_P alone? Multi-English P_L_P. Oh no, it gives eighty- three point six. But - So we have our eighty-three point six and now eighty-eighty point six, that gives eighty-seven point one. Mm-hmm. Eighty-s- I thought it was eighty- Oh, O_K, eighty-three point six and eighty - eighty- eight point six. Eighty-three point six. Eighty - O_K. Is th- is that right? Yeah? Yeah. But - I don't know - but maybe if we have the neural network trained with the P_L_P delta and delta-delta, maybe tha- this can help. Perhaps, yeah. Well, that's - that's one thing, but see the other thing is that, um, I mean it's good to take the difficult case, but let's - let's consider what that means. What - what we're saying is that one o- one of the things that - I mean my interpretation of your - your s- original suggestion is something like this, as motivation. When we train on data that is in one sense or another, similar to the testing data, Mm-hmm. then we get a win by having discriminant training. When we train on something that's quite different, Mm-hmm. we have a potential to have some problems. And, um, if we get something that helps us when it's somewhat similar, and doesn't hurt us too much when it - when it's quite different, Yeah. that's maybe not so bad. So the question is, if you took the same combination, Mmm. and you tried it out on, uh - on say digits, On T_I-digits? O_K. Yeah. you know, d- Was that experiment done? No, not yet. Yeah, O_K. Uh, then does that, eh - you know maybe with similar noise conditions and so forth, does it - does it then look much better? Mm-hmm. And so what is the range over these different kinds of uh - of tests? So, an- anyway. O_K, go ahead. Yeah. Mm-hmm. And, with this type of configuration which I do on experiment using the new neural net with name broad klatt s- twenty-seven, uh, d- I have found more or less the same result. Mm-hmm. So, it's Little bit better? slightly better, yeah. Slightly better. Yeah. Slightly bet- better. Yes, is better. And - and you know again maybe if you use the, uh, delta Yeah, maybe. Maybe. Maybe. there, uh, you would bring it up to where it was, uh you know at least about the same for a difficult case. Yeah. Oh, yeah. Yeah. Oh, yeah. So. Well, so perhaps let's - let's jump at the last experiment. It's Yeah. either less information from the neural network if we use only the silence output. i- Mm-hmm. It's again better. So it's eighty-nine point - point one. Mm-hmm. Yeah, and we have only forty - forty feature So. because in this situation we have one hundred and three feature. Yeah. Yeah. And then w- with the first configuration, I f- Yeah. I am found that work, uh, doesn't work - uh, well, work, but is better, the second configuration. Because I - for the del- Engli- P_L_P delta and delta-delta, here I have eighty-five point three accuracy, and with the second configuration I have eighty-seven point one. Um, by the way, there is a- another, uh, suggestion that would apply, uh, to the second configuration, um, which, uh, was made, uh, by, uh, Hari. And that was that, um, if you have - uh feed two streams into H_T_K, um, and you, uh, change the, uh variances - if you scale the variances associated with, uh these streams um, you can effectively scale the streams. Right? So, um, Mmm. you know, without changing the scripts for H_T_K, which is the rule here, Mm-hmm. uh, you can still change the variances which would effectively change the scale of these - these, uh, two streams that come in. Uh, yeah. And, um, so, um, if you do that, for instance it may be the case that, um, the M_L_P should not be considered as strongly, for instance. Mmm. And, um, so this is just setting them to be, excuse me, of equal - equal weight. Maybe it shouldn't be equal weight. Maybe. Right? You know, I- I'm sorry to say that gives more experiments if we wanted to look at that, but - but, uh, um, you know on the other hand it's just experiments at the level of the H_T_K recognition. It's not even the H_T_K, uh, Mmm. Yeah. Yeah. uh - Well, I guess you have to do the H_T_K training also. Uh, do you? Yeah. so this is what we decided to do. Let me think. Maybe you don't. Uh. Yeah, you have to change the - No, you can just do it in - as - once you've done the training - And then you can vary it. Yeah. Yeah, the training is just coming up with the variances so I guess you could - you could just scale them all. Scale the - ? Variances. Yeah. But - Is it - i- th- I mean the H_T_K models are diagonal covariances, so I d- That's uh, exactly the point, I think, that if you change - Is it - um, Hmm. change what they are - Mm-hmm. It's diagonal covariance matrices, but you say what those variances are. Mm-hmm. So, that - you know, it's diagonal, but the diagonal means th- that then you're gonna - it's gonna - it's gonna internally multiply it - and - and uh, uh, i- it im- uh implicitly exponentiated to get probabilities, and so it's - it's gonna - Mmm. it's - it's going to affect the range of things if you change the - change the variances of some of the features. Mmm. do? So, i- it's precisely given that model you can very simply affect, uh, the s- the strength that you apply the features. That was - that was, uh, Hari's suggestion. Yeah. Yeah. So, um - Yeah. Yeah. So. So it could just be that h- treating them equally, tea- treating two streams equally is just - just not the right thing to do. Of course it's potentially opening a can of worms because, you know, maybe it should be a different number for - for each kind of test set, or something, but - Mm-hmm. O_K. Yeah . So I guess the other thing is to take - you know - if one were to take, uh, you know, a couple of the most successful of these, Yeah, and test across everything. and uh - Yeah, try all these different tests. Mmm. Yeah. Yeah. Alright. Uh. So, the next point, yeah, we've had some discussion with Steve and Shawn, um, about their um, uh, articulatory stuff, um. So we'll perhaps start something next week. Mm-hmm. Um, discussion with Hynek, Sunil and Pratibha for trying to plug in their our - our networks with their - within their block diagram, uh, where to plug in the - the network, uh, after the - the feature, before as um a- as a plugin or as a- anoth- another path, discussion about multi-band and TRAPS, um, actually Hynek would like to see, perhaps if you remember the block diagram there is, uh, temporal L_D_A followed b- by a spectral L_D_A for each uh critical band. And he would like to replace these by a network which would, uh, make the system look like a TRAP. Well, basically, it would be a TRAP system. Basically, this is a TRAP system - kind of TRAP system, I mean, but where the neural network are replaced by L_D_A. Hmm. Um, yeah, and about multi-band, uh, I started multi-band M_L_P trainings, um mmh Actually, I w- I w- hhh prefer to do exactly what I did when I was in Belgium. So I take exactly the same configurations, seven bands with nine frames of context, and we just train on TIMIT, and on the large database, so, with SPINE and everything. And, mmm, I'm starting to train also, networks with larger contexts. So, this would - would be something between TRAPS and multi-band because we still have quite large bands, and - but with a lot of context also. So Um Yeah, we still have to work on Finnish, um, basically, to make a decision on which M_L_P can be the best across the different languages. For the moment it's the TIMIT network, and perhaps the network trained on everything. So. Now we can test these two networks on - with - with delta and large networks. Well, test them also on Finnish and see Mmm. which one is the - the - the best. Uh, well, the next part of the document is, well, basically, a kind of summary of what - everything that has been done. So. We have seventy-nine M_L_Ps trained on one, two, three, four, uh, three, four, five, six, seven ten - on ten different databases. Mm-hmm. Uh, the number of frames is bad also, so we have one million and a half for some, three million for other, and six million for the last one. Uh, yeah! As we mentioned, TIMIT is the only that's hand-labeled, and perhaps this is what makes the difference. Um. Yeah, the other are just Viterbi-aligned. So these seventy-nine M_L_P differ on different things. First, um with respect to the on-line normalization, there are - that use bad on-line normalization, and other good on-line normalization. Um. With respect to the features, with respect to the use of delta or no, uh with respect to the hidden layer size and to the targets. Uh, but of course we don't have all the combination of these different parameters Um. s- What's this? We only have two hundred eighty six different tests Ugh! And no- not two thousand. I was impressed boy, two thousand. O_K. Yeah. Ah, yes. I say this morning that @@ thought it was the - Alright, now I'm just slightly impressed, O_K. Um. Yeah, basically the observation is what we discussed already. The M_S_G problem, um, the fact that the M_L_P trained on target task decreased the error rate. but when the M_- M_L_P is trained on the um - is not trained on the target task, it increased the error rate compared to using straight features. Except if the features are bad - uh, actually except if the features are not correctly on-line normalized. In this case the tandem is still better even if it's trained on - not on the target digits. Yeah. So it sounds like yeah, the net corrects some of the problems with some poor normalization. Yeah. But if you can do good normalization it's - Yeah. Yeah. it's uh - Uh, so the fourth point is, yeah, O_K. the TIMIT plus noise seems to be the training set that gives better - So the best network. Mm-hmm. So- Let me - bef- before you go on to the possible issues. So, on the M_S_G uh problem um, I think that in - in the - um, in the short time solution um, that is, um, trying to figure out what we can proceed forward with to make the greatest progress, Mm-hmm. uh, much as I said with J_RASTA, even though I really like J_RASTA and I really like M_S_G, Mm-hmm. I think it's kind of in category that it's, it - it may be complicated. Yeah. And uh it might be - if someone's interested in it, uh, certainly encourage anybody to look into it in the longer term, once we get out of this particular rush uh for results. But in the short term, unless you have some - some s- strong idea of what's wrong, Mm-hmm. I don't know at all but uh - I've - perhaps - I have the feeling that it's something that's quite - quite simple or Yeah, probably. just like nnn, no high-pass filter or - Mmm. Yeah. My - But I don't know. There's supposed to - well M_S_G is supposed to have a- an on-line normalization though, right? It's - There is, yeah, an A_G_C- kind of A_G_C. Yeah. Yeah, but also there's an on-line norm- besides the A_G_C, there's an on-line normalization that's supposed to be uh, Yeah. Yeah. yeah, Mmm. taking out means and variances and so forth. So. Yeah. In fac- in fact the on-line normalization that we're using came from the M_S_G design, so it's - Um. Yeah, but - Yeah. But this was the bad on-line normalization. Actually. Uh. Are your results are still with the bad - the bad - Maybe, may - No? With the better - No? With the O_- O_L_N-two? Yes. Ah yeah, you have - Oh! Yeah, yeah, yeah! With "two", with "on-line-two". Yeah, yeah, yeah. you have O_L_N-two, yeah. "On-line-two" is good. Yep, So it's, is the good yeah. "Two" is good? it's a good. And - No, "two" is bad. Yeah. O_K. Well, actually, it's good with the ch- with the good. Yeah. So - Yeah, I - I agree. It's probably something simple uh, i- if - if uh someone, you know, uh, wants to play with it for a little bit. I mean, you're gonna do what you're gonna do but - Mmm. but my - my guess would be But - that it's something that is a simple thing that could take a while to find. Yeah. Mmm. I see, yeah. Yeah. And - Uh. And the other - the results uh, observations two and three, Mmm. Um, is uh - Yeah, that's pretty much what we've seen. That's - that - what we were concerned about is that if it's not on the target task - If it's on the target task then it - it - it helps to have the M_L_P transforming it. Mmm. If it uh - if it's not on the target task, then, depending on how different it is, uh you can get uh, a reduction in performance. Mmm. And the question is now how to - how to get one and not the other? Or how to - how to ameliorate the - the problems. Mmm. Um, because it - it certainly does - is nice to have in there, when it - when there is something like the Mm-hmm. training data. Um. Yeah. So, the - the reason - Yeah, the reason is that the - perhaps the target - the - the task dependency - the language dependency, So that's what you say th- there. I see. and the noise dependency - Well, the e- e- But this is still not clear because, um, I - I - I don't think we have enough result to talk about the - the language dependency. Well, the TIMIT network is still the best but there is also an- the other difference, the fact that it's - it's hand-labeled. Hey! Sorry, I'm very late, uh, Am I still accommodated, or - ? Um, just - you can just sit here. Uh, I d- I don't think we want to mess with the microphones but it's uh - Just uh, have a seat. Um. s- Summary of the first uh, uh forty-five minutes is that some stuff work and - works, and some stuff doesn't O_K, We still have uh this - One of these perhaps? Mm-hmm. Yeah. Yeah, I guess we can do a little better than that but - I think if you - if you start off with the other one, actually, that sort of has it in words and then th- that has it the associated results. O_K. Um. So you're saying that um, um, although from what we see, yes there's what you would expect in terms of a language dependency and a noise dependency. That is, uh, when the neural net is trained on one of those and tested on something different, we don't do as well as in the target thing. But you're saying Mm-hmm. that uh, it is - Although that general thing is observable so far, there's something you're not completely convinced about. And - and what is that? I mean, you say "not clear yet". What - what do you mean? Uh, mmm, uh, I mean, that the - the fact that s- Well, for - for T_I-digits the TIMIT net is the best, which is the English net. Mm-hmm. But the other are slightly worse. But you have two - two effects, the effect of changing language and the effect of training on something that's Viterbi-aligned instead of hand - hand-labeled. Yeah. So. Um. Yeah. Do you think the alignments are bad? I mean, have you looked at the alignments at all? What the Viterbi alignment's doing? Mmm. I don't - I don't know. Did- did you look at the Spanish alignments Carmen? Mmm, no. Might be interesting to look at it. @@ Because, I mean, that is just looking but um, um - It's not clear to me you necessarily would do so badly from a Viterbi alignment. It depends how good the recognizer is that's - Mm-hmm. that - the - the engine is that's doing the alignment. Yeah. But - Yeah. But, perhaps it's not really the - the alignment that's bad but the - just the ph- phoneme string that's used for the alignment or - Aha! Mmm. I mean for - Yeah. @@ The pronunciation models and so forth We - It's single pronunciation, uh - Aha. I see. French - French s- uh, phoneme strings were corrected manually so we asked people to listen to the um - the sentence and we gave the phoneme string and they kind of correct them. But still, @@ there - there might be errors just in the - in - in the ph- string of phonemes. Mmm. Um. Yeah, so this is not really the Viterbi alignment, in fact, yeah. Um, the third - The third uh issue is the noise dependency perhaps but, well, this is not clear yet because all our nets are trained on the same noises and - Mmm. I thought some of the nets were trained with SPINE and so forth. So it - And that has other noise. Yeah. So - Yeah. But - Yeah. Results are only coming for - for this net. Mmm. O_K, yeah, just don't - just need more - more results there with that @@ . Yeah. Um. So. Uh, from these results we have some questions with answers. What should be the network input? Um, P_L_P work as well as M_F_C_C, I mean. Um. But it seems impor- important to use the delta. Uh, with respect to the network size, there's one experiment that's still running and we should have the result today, comparing network with five hundred and one thousand units. So, nnn, still no answer actually. Hm-hmm. Uh, the training set, well, some kind of answer. We can, we can tell which training set gives the best result, but we don't know exactly why. Uh. Uh, so. Right, I mean the multi-English so far is - is the best. Yeah. "Multi- multi-English" just means "TIMIT", right? Yeah. Yeah. So uh That's - Yeah. So. And - and when you add other things in to - to broaden it, it gets worse uh typically. Yeah. Mmm. Mm-hmm. Then uh O_K. some questions without answers. Uh, training set, um, Uh-huh. uh, training targets - I like that. The training set is both questions, with answers and without answers. It's sort of, yes - it's mul- it's multi-uh-purpose. O_K. It's - Yeah. Yeah. Yeah. Uh, training s- Right . So - Yeah, the training targets actually, the two of the main issues perhaps are still the language dependency and the noise dependency. And perhaps to try to reduce the language dependency, we should focus on finding some other kind of training targets. Mm-hmm. And labeling s- labeling seems important uh, because of TIMIT results. Mm-hmm. Uh. For moment you use - we use phonetic targets but we could also use articulatory targets, soft targets, and perhaps even, um use networks that doesn't do classification but just regression so uh, train to have neural networks that um, um, Mm-hmm. uh, does a regression and well, basically com- com- compute features and noit- not, nnn, features without noise. I mean uh, transform the fea- noisy features in other features that are not noisy. But continuous features. Not uh Mm-hmm. uh, hard targets. Mm-hmm. Uh - Yeah, that seems like a good thing to do, probably, uh, not uh again a short-term Yeah. sort of thing. I mean one of the things about that is that um it's - e- u- the ri- I guess the major risk you have there of being - is being dependent on - very dependent on the kind of noise and - and so forth. Yeah. f- Uh. But, yeah. So, this is w- w- But it's another thing to try. i- wa- wa- this is one thing, this - this could be - could help - could help perhaps to reduce language dependency and for the noise part um we could combine this with other approaches, like, well, the Kleinschmidt approach. So the d- the idea of putting all the noise that we can find inside a database. Mm-hmm. I think Kleinschmidt was using more than fifty different noises to train his network, Yeah. and - So this is one approach Mm-hmm. and the other is multi-band Mm-hmm. uh, that I think is more robust to the noisy changes. So perhaps, I think something like multi-band trained on a lot of noises with uh, features-based targets could - Yeah, if you - i- i- It's interesting thought maybe if you just trained up - could - could help. I mean w- yeah, one - one fantasy would be you have something like articulatory targets and you have um some reasonable database, um but then - which is um copied over many times with a range of different noises, Mm-hmm. And uh - If - Cuz what you're trying to do is come up with a - a core, reasonable feature set which is then gonna be used uh, by the - the uh H_M_M system. So. Mm-hmm. Yeah, O_K. So, um, yeah. The future work is, well, try to connect to the - to make - to plug in the system to the O_G_I system. Um, there are still open questions there, where to put the M_L_P Mm-hmm. basically. Um. And I guess, you know, the - the - the real open question, I mean, e- u- there's lots of open questions, but one of the core quote "open questions" for that is um, um, if we take the uh - you know, the best ones here, maybe not just the best one, but the best few or something - Mm-hmm. You want the most promising group from these other experiments. Um, how well do they do over a range of these different tests, not just the Italian? Mmm, Yeah, yeah. Um. And y- Right? And then um - then see, again, how - We know that there's a mis- there's a uh - a - a loss in performance when the neural net is trained on conditions that are different than - than, uh we're gonna test on, but well, if you look over a range of these different tests um, how well do these different ways of combining the straight features with the M_L_P features, uh stand up over that range? Mm-hmm. That's - that - that seems like the - the - the real question. And if you know that - So if you just take P_L_P with uh, the double-deltas. Assume that's the p- the feature. look at these different ways of combining it. And uh, take - let's say, just take uh multi-English cause that works pretty well for the training. Mm-hmm. And just look - take that case and then look over all the different things. How does that - How does that compare between the - So all the - all the test sets you mean, yeah. Yeah. All the different test sets, and for - and for the couple different ways that you have of - of - of combining them. And - Yeah. Um. How well do they stand up, over the - Mmm. Mm-hmm. And perhaps doing this for - cha- changing the variance of the streams and so on getting different scaling - That's another possibility if you have time, yeah. Yeah. O_K. Um. @@ Yeah, so thi- this sh- would be more working on the M_L_P as an additional path instead of an insert to the - to their diagram. Cuz - Yeah. Perhaps the insert idea is kind of strange because nnn, they - they make L_D_A and then we will again add a network does discriminate anal- nnn, Yeah. It's a little strange but on the other hand they that discriminates, or - ? Mmm? did it before. Mmm. And - and - and yeah. And because also perhaps we know that Um the- the - when we have very good features the M_L_P doesn't help. So. I don't know. Um, the other thing, though, is that um - So. Uh, we - we wanna get their path running here, right? If so, we can add this other stuff. Um. as an additional path right? Yeah, the - the way we want to do - Cuz they're doing L_D_A RASTA. The d- What? They're doing L_D_A RASTA, yeah? Yeah, the way we want to do it perhaps is to - just to get the V_A_D labels and the final features. So they will send us the - Well, I see. provide us with the feature files, I see. and with V_A_D uh, binary labels so that we can uh, get our M_L_P features and filter them with the V_A_D and then combine them with their f- feature stream. I see. So we - So. First thing of course we'd wanna do there is to make sure that when we get those labels of final features is that we get the same results as them. So. @@ Without putting in a second path. Uh. You mean - Oh, yeah! Just re- re- retraining r- Yeah just th- w- i- i- retraining the H_T_K? Just to make sure that we have - we understand properly what things are, our very first thing to do is to - is to double check that we get the exact same results as them on H_T_K. Oh yeah. @@ Yeah, O_K. Mmm. Uh, I mean, I don't know that we need to r- Yeah. Yeah. Um Do we need to retrain I mean we can just take the re- their training files also. But. But, uh just for the testing, jus- just make sure that we get the same results so we can duplicate it before we add in another - Mmm. O_K. Cuz otherwise, you know, we won't know what things mean. Oh, yeah. O_K. And um. Yeah, so fff, LogRASTA, I don't know if we want to - We can try networks with LogRASTA filtered features. Maybe. Mmm. Would you be using on-line normalization with that? I'm sorry? Would you be using on-line normalization with LogRASTA-P_L_P? Yeah. Well - Yeah. Oh! You know, the other thing is when you say comb- But - I'm - I'm sorry, I'm interrupting. that u- Um, uh, when you're talking about combining multiple features, um - Suppose we said, "O_K, we've got these different features and so forth, but P_L_P seems pretty good." If we take the approach that Mike did and have - I mean, one of the situations we have is we have these different conditions. We have different languages, we have different - different noises, Um If we have some drastically different conditions and we just train up different M_L_ Ps with them. Mm-hmm. And put - put them together. What - what - What Mike found, for the reverberation case at least, I mean - I mean, who knows if it'll work for these other ones. That you did have nice interpolative effects. That is, that yes, if you knew what the reverberation condition was gonna be and you trained for that, then you got the best results. But if you had, say, a heavily-reverberation ca- heavy-reverberation case and a no-reverberation case, Mm-hmm. uh, and then you fed the thing, uh something that was a modest amount of reverberation then you'd get some result in between the two. So it was sort of - behaved reasonably. Is tha- that a fair - Yeah. Yeah. Um. It also seems like whe- if you try to train, like, a single M_L_P with too much noise, um, you'll get some nice interval of power for unseen cases but um but any unmatched cases it'll start, um, interfering. Yeah. So you - you think it's perhaps better to have several M_L_Ps? Well, it's easier. Um, that way you can turn things off @@ turn things on. Um. But you then - Yeah but - Mmm. A single M_L_P of course will work a little bit better because uh it'll have uh - It's a nonlinear kind of merging of the features. It works better if what? Yea- Uh, well, in general nonlinear mergings seems to work a little better then just the straight linear coefficients , but um it just means it's - you have to have bigger nets and more training time, and if you want to turn things off um that's harder to do. I see. Well, see, i- oc- You were doing some- something that was - So maybe the analogy isn't quite right. You were doing something that was in way a little better behaved. You had reverb- for a single variable which was re- uh, uh, reverberation. Here the problem seems to be is that we don't have a hug- a really huge net with a really huge amount of training data. But we have s- f- for this kind of task, I would think, sort of a modest amount. I mean, a million frames actually isn't that much. We have a modest amount of - of uh training data from a couple different conditions, and then uh - in - yeah, that - and the real situation is that there's enormous variability that we anticipate in the test set in terms of language, and noise type uh, and uh, uh, channel characteristic, sort of all over the map. A bunch of different dimensions. And so, I'm just concerned that we don't really have um, the data to train up - I mean one of the things that we were seeing is that when we added in - we still don't have a good explanation for this, but we are seeing that we're adding in uh, a fe- few different databases and uh the performance is getting worse and uh, when we just take one of those databases that's a pretty good one, it actually is - is - is - is - is better. And uh that says to me, yes, that, you know, there might be some problems with the pronunciation models that some of the databases we're adding in or something like that. But one way or another we don't have uh, seemingly, the ability to represent, in the neural net of the size that we have, um, all of the variability that we're gonna be covering. So that I'm - I'm - I'm hoping that um, this is another take on the efficiency argument you're making, which is I'm hoping that with moderate size neural nets, uh, that uh if we - if they look at more constrained conditions they - they'll have enough parameters to really represent them. I think the way that Hynek or - or Malik had - had told me was that if you try to train a classifier on too much - too many conditions then it'll do good on none of them, but it'll start doing something else. Mm-hmm. Which means, if you have something Mm-hmm. else in there it'll be nicer @@ I'm not sure @@ Mm-hmm. I also have some - some - a new theory on why um LogRASTA-P_L_P - uh P_L_P with on-line normalization might be a little bit better than LogRASTA-P_L_P with on-line normalization. It has to do with certain distribution characteristics. But if you take away the on-line normalization, LogRASTA seems to do better than P_L_P but not in all cases. Yeah. So doing both is - is not - is not right, you mean, or - ? Um. not so much not right, but it if you throw in the on-line normalization then it might not be necessary to use the LogRASTA-P_L_P. Yeah. Yeah. I - I just sort of have a feeling - But - Yeah. Mm-hmm. Yeah. I mean - i- i- e- The um - I think it's true that the O_G_I folk found that using L_D_A RASTA, which is a kind of LogRASTA, it's just that they have the - I mean it's done in the log domain, as I recall, and it's - it uh - it's just that they d- it's trained up, right? Mm-hmm. That that um benefitted from on-line normalization. So they did - At least in their case, it did seem to be somewhat complimentary. So will it be in our case, where we're using the neural net? I mean they - they were not - not using the neural net. Uh I don't know. O_K, so the other things you have here are uh, trying to improve results from a single - Yeah. Make stuff better. O_K. Uh. Yeah. And C_P_U memory issues. Yeah. We've been sort of ignoring that, haven't we? Yeah, so I don't know. But - But we have to address the problem of C_P_U and memory we - Yeah, but I li- Well, I think - My impression - You - you folks have been looking at this more than me. But my impression was that uh, there was a - a - a - a strict constraint on the delay, Yeah. but beyond that it was kind of that uh using less memory was better, and using less C_P_U was better. Something like that, right? Yeah, but - Yeah. So, yeah, but we've - I don't know. We have to get some reference point to where we - Well, what's a reasonable number? Perhaps be- because if it's - if it's too large or - large or @@ - Um, well I don't think we're um completely off the wall. I mean I think that if we - if we have - Uh, I mean the ultimate fall back that we could do - If we find uh - I mean we may find that we - we're not really gonna worry about the M_L_ P. You know, if the M_L_P ultimately, after all is said and done, doesn't really help then we won't have it in. Mmm. If the M_L_P does, we find, help us enough in some conditions, uh, we might even have more than one M_L_P. We could simply say that is uh, done on the uh, server. Mmm. And it's uh - We do the other manipulations that we're doing before that. So, I - I - I think - I think that's - that's O_K. And - Yeah. So I think the key thing was um, this plug into O_G_I. Um, what - what are they - What are they gonna be working - Do we know what they're gonna be working on while we take their features, and - ? They're - They're starting to wor- work on some kind of multi-band. So. Um - This - that was Pratibha. Sunil, what was he doing, do you remember? Sunil? Yeah. He was doing something new or - ? I - I don't re- I didn't remember. Maybe he's working with I don't think so. Trying to tune wha- networks? neural network. Yeah, I think so. I think they were also mainly, well, working a little bit of new things, like networks and multi-band, but mainly trying to tune their - their system as it is now to - just Yeah. trying to get the best from this - this architecture. Mmm. O_K. So I guess the way it would work is that you'd get - There'd be some point where you say, "O_K, this is their version-one" or whatever, and we get these V_A_D labels and features and so forth for all these test sets from them, Mm-hmm. and then um, uh, that's what we work with. We have a certain level we try to improve it with this other path and then um, uh, when it gets to be uh, January some point uh, we say, "O_K we - we have shown that we can improve this, in this way. So now uh um what's your newest version?" And then maybe they'll have something that's better and then we - we'd combine it. This is always hard. I mean I - I - I used to work with uh folks who were trying to improve a good uh, H_M_M system with uh - with a neural net system and uh, it was a common problem that you'd - Oh, and this - Actually, this is true not just for neural nets but just for - in general if people were working with uh, rescoring uh, N_best lists or lattices that come - came from uh, a mainstream recognizer. Uh, You get something from the - the other site at one point and you work really hard on making it better with rescoring. But they're working really hard, too. So by the time you have uh, improved their score, Mmm. they have also improved their score and now there isn't any difference, because the other - Yeah. Yeah. So, um, I guess at some point we'll have to uh - So it's - Uh, I - I don't know. I think we're - we're integrated a little more tightly than happens in a lot of those cases. I think at the moment they - they say that they have a better thing we can - we - e- e- Mmm. What takes all the time here is that th- we're trying so many things, presumably uh, in a - in a day we could turn around uh, taking a new set of things from them and - and rescoring it, right? So. Mmm. Yeah. Yeah, perhaps we could. Yeah. Well, O_K. No, this is - I think this is good. I think that the most wide open thing is the issues about the uh, you know, different trainings. You know, da- training targets and Mmm. noises and so forth. That's sort of wide open. So we - we can for - we c- we can forget combining multiple features and M_L_G perhaps, or focus more on the targets and on the training data and - ? Yeah, I think for right now um, I th- I - I really liked M_S_G. And I think that, you know, one of the things I liked about it is has such different temporal properties. And um, I think that there is ultimately a really good uh, potential for, you know, bringing in things with different temporal properties. Um, but um, uh, we only have limited time and there's a lot of other things we have to look at. And it seems like much more core questions are issues about the training set Mmm. and the training targets, and fitting in uh what we're doing with what they're doing, and, you know, with limited time. Yeah. I think we have to start cutting down. So uh - Mmm. I think so, yeah. And then, you know, once we - Um, having gone through this process and trying many different things, I would imagine that certain things uh, come up that you are curious about uh, that you'd not getting to and so when the dust settles from the evaluation uh, I think that would time to go back and take whatever intrigued you most, you know, got you most interested uh and uh - and - and work with it, you know, for the next round. @@ Uh, as you can tell from these numbers uh, nothing that any of us is gonna do is actually gonna completely solve the problem. So. Mmm. So, there'll still be plenty to do. Barry, you've been pretty quiet. @@ Just listening. Well I figured that, but - That - what - what - what were you involved in in this primarily? Um, helping out uh, preparing - Well, they've been kind of running all the experiments and stuff and I've been uh, uh w- doing some work on the - on the - preparing all - all the data for them to - to um, train and to test on. Um Yeah. Right now, I'm - I'm focusing mainly on this final project I'm working on in Jordan's class. Ah! I see. Right. What's - what's that? Yeah. Um, I'm trying to um - So there was a paper in I_C_S_L_P about um this - this multi-band um, belief-net structure. Mm-hmm. This guy did - uh basically it was two H_M_Ms with - with a - with a dependency arrow between the two H_M_Ms Uh-huh. And so I wanna try - try coupling them instead of t- having an arrow that - that flows from one sub-band to another sub-band. I wanna try having the arrows go both ways. And um, I'm just gonna see if - if that - that better models um, uh asynchrony in any way or um - Yeah. Oh! O_K. Well, that sounds interesting. Yeah. O_K. Alright. Anything to - you wanted to - No. O_K. Silent partner in the - in the meeting. Oh, we got a laugh out of him, that's good. O_K, everyone h- must contribute to the - our - our sound - sound files here. O_K, so speaking of which, if we don't have anything else that we need - You happy with where we are? Know - know wher- know where we're going? Mmm. Uh - I think so, yeah. Yeah, yeah. You - you happy? Mmm. You're happy. O_K everyone should be happy. O_K. You don't have to be happy. You're almost done. @@ . Yeah, yeah. O_K. Al- actually I should mention - So if - um, about the Linux machine "Swede." So it looks like the um, neural net tools are installed there. And um Yeah. Mmm. Dan Ellis I believe knows something about using that machine so Mmm. If people are interested in - in getting jobs running on that maybe I could help with that. Yeah, but I don't know if we really need now a lot of machines. Well. we could start computing another huge table but - yeah, we - Well. Yeah, I think we want a different table, at least Yeah, sure. Right? I mean there's - there's some different things that we're But - trying to get at now. But - Yeah. Mmm. So. Yeah, as far as you can tell, you're actually O_K on C_- on C_P_U uh, for training and so on? Yeah. Ah yeah. I think so. Well, more is always better, but mmm, I don't think we have to train a lot of networks, now that we know - We just select what works fine and O_K. O_K. Yeah. And we're O_K on - to work try to improve this and - And we're O_K on disk? It's O_K, yeah. Well sometimes we have some problems. Some problems with the - You know. But they're correctable, uh problems. Yeah, restarting the script basically and - Yes. Yeah, I'm familiar with that one, O_K. Alright, so uh, since uh, we didn't ha- get a channel on for you, you don't have to read any digits but the rest of us will. Light's on here. @@ Yeah. Uh, is it on? Well. We didn't uh - I think I won't touch anything cuz I'm afraid of making the driver crash which it seems to do, pretty easily. O_K, thanks. O_K, so we'll uh - I'll start off the uh um connect the - My battery is low. Well, let's hope it works. Maybe you should go first and see so that you're - O_K. I'm reading transcript two five seven one, two five nine O_. @@ batteries? one nine four three Yeah, your battery's going down too. two six three four five seven one eight three zero six seven four four nine three O_ four nine O_ O_ O_ nine nine eight four zero one two O_ two eight six nine one four one five six nine zero seven five four six six seven eight nine O_ O_ O_ one two seven three O_ seven three Transcript uh two - Carmen's battery is d- going down too. Oh, O_K. Yeah. Why don't you go next then. Uh, transcript number two five one one dash two five three zero channel one. nine zero five O_ O_ four seven one three zero zero six three seven two five five four four five four three three one four seven O_ five six seven zero seven nine one O_ four zero four seven one seven five two O_ four O_ two nine three four zero five five two six eight six three eight nine zero nine zero seven six four seven eight six one nine O_K. Um, transcript two five three one dash two five five zero O_ zero zero one O_ three five two one seven three one one zero six five six four three three six four six three five eight one one two four four six nine nine seven eight O_ one eight O_ O_ nine zero one six zero one two three eight one two six zero four three nine four nine five five six zero four eight three eight two four two nine three three three O_ five I'm reading transcript two five five one dash two five seven O_ zero six six nine five four seven one two three O_ O_ five one six two five seven seven five eight nine O_ zero zero five zero eight nine six two one three O_ five three five seven two three six zero four three five six nine nine six seven seven O_ six eight zero six five zero O_ three eight five four zero two I'm reading transcript two four nine one dash two five one zero on channel two. eight nine zero seven nine zero two one four O_ six two six three one three eight two O_ five eight four four five six O_ eight eight one two zero six nine six two zero four four three O_ seven three zero seven one two O_ five four one five one five six six nine seven five nine one three eight seven two nine seven two six Guess we're done. O_K, uh so. Just finished digits. O_K. I'll be right up. O_K. Yeah, so. Uh Well, it's good. I think - I guess we can turn off our microphones now. Just pull the batteries out. 