And we already got the crash out of the way. It did crash, so I feel much better, earlier. @@ Yeah. Interesting. Hmm. Will you get the door, and - ? @@ O_K. You collected an agenda, huh? O_K, so um. I did collect an agenda. So I'm gonna go first. Mwa-ha-ha! It shouldn't take too long. Yeah. Um, so we're pretty much out of digits. We've gone once through the set. Um, so the only thing I have to do No there's only ten. Yeah, that's right. so I - I just have to go through them and uh Well, O_K. pick out the ones that have problems, and either correct them or have them re-read. So we probably have like four or five more forms to be read, to be once through the set. I've also extracted out about an hour's worth. We have about two hours worth. I extracted out about an hour's worth which are the f- digits with - for which whose speaker have speaker forms, have filled out speaker forms. Not everyone's filled out a speaker form. So I extracted one for speakers who have speaker forms and for meetings in which the "key" file and the transcript files are parsable. Some of the early key files, it looks like, were done by hand, and so they're not automatically parsable and I have to go back and fix those. So what that means is we have about an hour of transcribed digits that we can play with. Um, So you think two - you think two hours is the - is the total that we have? Liz - Yep, yeah. And you think we- th- uh, I - I didn't quite catch all these different things that are not quite right, but you think we'll be able to retrieve the other hour, reasonably? Yes, absolutely. O_K. So it's just a question of a little hand-editing of some files and then waiting for more people to turn in their speaker forms. I have this web-based speaker form, and I sent mail to everyone who hadn't filled out a speaker form, and they're slowly s- trickling in. So the relevance of the speaker form here, s- It's for labeling the extracted audio files. Oh, O_K. By speaker I_D and microphone type. Wasn't like whether they were giving us permission to use their digits or something. No, I spoke with Jane about that and we sort of decided that it's probably not an issue that - We edit out any of the errors anyway. Yeah. Right? So the- there are no errors in the digits, you'll always read the string correctly. So I can't imagine why anyone would care. So the other topic with digits is uh, Liz would like to elicit different prosodics, and so we tried last week with them written out in English. And it just didn't work at all because no one grouped them together. So it just sounded like many many more lines instead of anything else. So in conversations with Liz and uh Jane we decided that if you wrote them out as numbers instead of words it would elicit more phone number, social security number-like readings. The problem with that is it becomes numbers instead of digits. When I look at this, that first line is "sixty one, sixty two, eighteen, eighty six, ten." Um, and so the question is does anyone care? Um, I've already spoken with Liz and she feels that, Mm-hmm. correct me if I'm wrong, that for her, connected numbers is fine, as opposed to connected digits. Um, I think two hours is probably fine for a test set, but it may be a little short if we actually wanna do training and adaptation and all that other stuff. Yeah Um, do um you want different prosodics, so if you always had the same groupings you wouldn't like that? Is that correct? Well, we actually figured out a way to - the - the groupings are randomly generated. Yeah, the - the - No but, I was asking if that was something you really cared about because if it wasn't, it seems to me if you made it really specifically telephone groupings that maybe people wouldn't, uh, go and do numbers so much. You know if it- if it's - Uh - I think they may still do it, um, Maybe some, but I- probably not so much. What about putting a hyphen between the numbers in the group? And - Right? So if you - if - if you have uh Six dash one, you mean? if you go six six six uh dash uh two nine three one. I - well O_K - I - it might help, I would like to g- get away from having only one specific grouping. Um, so if that's your question, but I mean it seems to me that, at least for us, we can learn to read them as digits if that's what people want. I - I'm That's what I was asking, yeah. Yeah. Yeah. Yeah. don't think that'd be that hard to read them as single digits. Um, I agree. and it seems like that might be better for you guys since then you'll have just more digit data, and that's always a good thing. Right. It's a little bit better for me too because the digits are easier to recognize. They're better trained than the numbers. Yep. Right. So we could just, uh, put in the instructions "read them as digits". Right. Right, read them as single digits, so sixty-one w- is read as six one, and if people make a mistake we - Mm-hmm . How about "O_" versus "zero"? I mean, the other thing is we could just bag it because it's - it's - it's- I'm not worrying about it I mean, because we do have digits training data that we have from uh from O_G_I. I'm sorry, digits - numbers training that we have from O_G_I, we've done lots and lots of studies with that. And um. But it's nice to get it in this room with the acous- I mean - for - it's - Yeah. No, no, I guess what I'm saying is that Just let them read it how they read it. to some extent maybe we could just read them - have them read how - how they read it and it just means that we have to expand our - our vocabulary out to stuff that we already have. Yeah. Right. Well that's fine with me as long as - It's just that I didn't want to cause the people who would have been collecting digits the other way to not have the digits. So - We can go back to the other thing later. I mean we s- we - we've - O_K. We can do this for awhile and then go back to digits for awhile, or um. Do yo- I mean, do you want - do you want this - O_K. Do you need training data or adaptation data out of this? How much of this do you need? with uh the - It's actually unclear right now. I just thought well we're - if we're collec- collecting digits, and Adam had said we were running out of the T_I forms, I thought it'd be nice to have them in groups, and probably, all else being equal, it'd be better for me to just have single digits since it's, O_K. you know, a recognizer's gonna do better on those anyway, um, and it's more predictable. So we can know from the transcript what the person said and the transcriber, in general. But if they make mistakes, it's no big deal if the people say a hundred instead of "one O_O". O_K, well if you pre- and also w- maybe we can just let them choose "zero" versus "O_" as they - as they like because even the same person c- sometimes says "O_" and sometimes says "zero" in different context, and that's sort of interesting. Yeah. So I don't have a Specific need cuz if I did I'd probably try to collect it, you know, without bothering this group, but If we can try it - O_K so - so I can just add to the instructions to read it as digits not as connected numbers. Right, and you can give an example like, Mm-hmm. you know, "six - sixty-one would be read as six one". And I think people will get it. Right. Mm-hmm. And i- actually it's no more artificial than what we've been doing with words. I'm sure people can adapt to this, Right, right. It's just easier to read. read it single. The spaces already bias it toward being separated. Right. And I know I'm gonna find this easier than words. Oh yeah, absolutely, cognitively it's much easier. O_K- I also had a hard - hard time with the words, but then we went back and forth on that. O_K, so let's give that a try and - Yeah. O_K. And is the spacing alright or do you think there should be more space between digits and groups? O_K. I mean what do other people think cuz you guys are reading them. Or is that alright? I think that i- it's fine. I- it - it - to me it looks like you've got the func- the idea of grouping and you have the grou- the idea of separation and, you know, it's just a matter of u- i- the instructions, that's all. O_K. O_K. Great. O_K. Well let's give it a try. And I think there are about ten different gouping patterns isn't that right, Liz? Let's try it. Righ- right, and you just - they're randomly generated and randomly assigned to digits. That we did. I did - Mm-hmm. Go ahead. So we have - Sorry, I - I was just gonna say, so we have in the vicinity of forty hours of - of recordings now. And you're saying two hours, uh, is digits, so that's roughly the ratio then, something like twenty - twenty to one. Which I guess makes - Yep. makes sense. So if we did another forty hours of recordings then we could get another couple hours of this. Right. Um, yeah like you say, I think a couple hours for a - for a - for a test - test set's O_K. It'd be nice to get, you know, more later because we'll - we might use - use this up, uh, in some sense, but - but uh - Mm-hmm. Right. Yeah, I also would like to argue for that cuz it - it seems to me that, um, there's a real strength in having the same test replicated in - a whole bunch of times and adding to that basic test bank. Hmm? Cuz then you have, you know, more and more, Right. u- chances to get away from random errors. And I think, um, the other thing too is that right now we have sort of a stratified sample with reference to dialect groups, and it might be - there might be an argument to be made for having uh f- for replicating all of the digits that we've done, which were done by non-native speakers so that we have a core that totally replicates the original data set, which is totally American speakers, and then we have these stratified additional language groups overlapping certain aspects of the database. Right. I think that uh trying to duplicate, spending too much effort trying to duplicate the existing T_I-digits probably isn't too worthwhile because the recording situation is so different. It's gonna be very hard to be comparable. Yeah. Except that if you have the stimuli comparable, then it says something about the - the contribution of setting and - No it's - it's not the same. A little bit, but the other differences are so major. O_K. They're such major sources of variance that it's - it's - it's uh - Yeah I mean read versus not. What's an example of a - of m- some of the other differences? Any other a- difference? Well i- i- individual human glottis is going to be different for each one, you know, it's just - There's so many things. O_K. O_K. it's - it - and - and enunciation. Well, and not just that, I mean the uh the corpus itself. I mean, we're collecting it in a read digit in a particular list, and I'm sure that they're doing more specific stuff. I mean if I remember correctly it was like postman reading zipcodes and things like that. T_I-digits was? I thought - I thought it was read. I thought so. Was it read? Yeah, I think the reading zipcode stuff you're thinking of would be O_G_I. Oh, I may well be. Yeah, no T_I-digits was read in th- in read in the studio I believe. I haven't ever listened to T_I-digits. So I don't really know how it compares. Yeah. Yeah. But it - but - But - but regardless it's gonna - it's hard to compare cross-corpus. It- it's different people is the - is the core thing. And they're different circumstances with different recording environment and so forth, so it's - it's - it's really pretty different. But I think So. O_K, fine. the idea of using a set thing was just to give you some sort of framework, so that even though you couldn't do exact comparisons, it wouldn't be s- valid scientifically at least it'd give you some kind of uh frame of reference. Uh, you know it's not - O_K. Hey Liz, What - what do the groupings represent? You said there's like ten different groupings? Right, just groupings in terms of number of groups in a line, and number of digits in a group, and the pattern of groupings. Mm-hmm. Are the patterns - like are they based on anything or Um, I - I just roughly looked at what kinds of digit strings are out there, and they're usually grouped into either two, three, or four, Oh. four digits at a time. And they can have, I mean, actually, things are getting longer and longer. In the old days you probably only had three sequences, and telephone numbers were less, and so forth. So, there's between, um - Well if you look at it, there are between like three and five groups, and each one has between two and four groupings and - I purposely didn't want them to look like they were in any kind of pattern. So Mmm. And which group appears is picked randomly, and what the numbers are are picked randomly. Right. Mm-hmm. So unlike the previous one, which I d- simply replicated T_I-digits, this is generated randomly. Mmm, oh, O_K. Oh O_K. But I think it'd be great i- to be able to compare digits, whether it's these digits or T_I-digits, to speakers, um, and compare that to their spontaneous speech, and then we do need you know a fair amount of - of digit data because you might be wearing a different microphone and, I mean - so it's - it's nice to have the digits Mm-hmm. you know, replicated many times. Especially for speakers that don't talk a lot. So um, for adaptation. No, I'm serious, so Yeah. Yeah. Yeah all we have for some people is digits. we have a problem with acoustic adaptation, and we're not using the digit data now, but you know - Yeah. Oh, you're not. Not for adaptation, nope. v- W- we're not - we were running adaptation only on the data that we ran recognition on and I'd - As soon as someone started to read transcript number, that's read speech and I thought "well, we're gonna do better on that, Oh I see. that's not fair to use ". But, it might be fair to use the data for adaptation, so. Oh yeah that's true, absolutely. O_K. So those speakers who are very quiet, shy - r- Right - That would be interesting to see whether that helps. Do you think that would help adapting on - Yeah. Yeah, I have a real problem with that. Like Adam? Yeah. Well, it sh- I mean it's the same micropho- see the nice thing is we have that in the - in the same meeting, Right. Same - same acoustics, same microphone, same channel. Yeah. and so you don't get - Yeah. Right, and so I still like the idea of having some kind of O_K. Good. digit data . Yeah I mean, for the - for the um acoustic research, for the signal-processing, far-field stuff, I see it as - as - as the place that we start. But, th- I mean, it'd be nice to have twenty hours of digits data, but - but uh the truth is I'm hoping that we - we through the - the stuff that - that you guys have been doing as you continue that, we get, uh, the best we can do on the spontaneous stuff uh, uh near-field, and then um, we do a lot of the testing of the algorithms on the digits for the far-field, and at some point when we feel it's mature and we understand what's going on with it then we - we have to move on to the spontaneous data with the far-field. So. Great. The only thing that we don't have, I know this sounds weird, and maybe it's completely stupid, but we don't have any overlapping digits. Yeah, we talked about that a couple times. An- yea- I know it's weird, but um - Overlapping digits! The - the problem I see with trying to do overlapping digits is the cognitive load. Alright everybody's laughing. O_K. Dueling digits. No it's - it's not stupid, it's just - I mean, try to do it. I'm just talkin- for the stuff that like Dan Ellis is gonna try, you know, cross-talk cancellation. O_K. I mean, here, let's try it. You read the last line, I'll read the first line. Let's try it. Oh! Wait - oh it - these are all the same forms. O_K So but - Sixty-one. So - so you read the last line, I'll read the first line. So you plu- you plug your ears. No, I'll p- Oh I guess if you plug you're ears you could do it, but then you don't get the - the same effects. Well, what I mean is actually no- Yeah. not the overlaps that are well-governed linguistically, but the actual fact that there is speech coming from two people and the beam-forming stuf- all the acoustic stuff that like Dan Ellis and - and company want to do. Yeah. Oh I see. Digits are nice and well behaved, I mean Anyway, it's just a thought. It - it would go faster. I guess we could try. We could try doing some. Parallel. It's the P_make of digit reading. It would take one around amount of ti- That's right. Well - Well O_K. Well let's try it. I - I mea- I'm - I was sort of serious, but I really, I mean, I'm - I don't feel strongly enough that it's a good idea, so. See, y- You do the last line, I'll do the first line. O_K. Six one, six two, one eight, eight six, one O_. Zero zero nine, six six three, nine one nine. That's not bad. No, I can do it. A- and that prosody was great, by the way. I couldn't understand a single thing you guys were saying. I think it was numbers, but I'm not sure. It - it sort of sounded like a duet, or something. Yeah. Performance art. Alright , let's try three at once you - you pick one in the middle. The Aurora theater. O_K. Go. Six one, six two, one eight, eight six, one O_. Zero zero nine, six six three, nine one nine. Five, six O_ six, five five I'm sorry. I'm mean I think it's doable, I'm just - The poor transcribers they're gonna hate us. So, we - we could have a round like where you do two at a time, and then the next person picks up when the first guy's done, or something. Like a, So pairwise. Oh like a round, yeah, like in a - a - yeah. Yeah, just pairwise, or yeah. what do you call it? Li- a r- like - yeah, like that. Row, row, row your boat. Yeah. A round. Round. Mm-hmm. O_K. It's gonna require some coordination. Then it would go like h- twice as fast, or a third as fast. Anyway, it's just a thought. I'm actually sort of serious if it would help people do that kind o- but the people who wanna work on it we should talk to them. So. Yeah. You have to have a similar pace. I don't think we're gonna collect vast amounts of data that way, but I think having a little bit might at least be fun for somebody like Dan to play around with, yeah. Mmm. O_K. I think maybe if we wanted to do that we would do it as a separate session, something like that rather than Yeah. doing it during a real meeting and you know, do two people at a time then three people at a time and things like that. So. Can try it out. If we have nothing - if we have no agenda we could do it some week. O_K. See - see what Dan thinks. Yeah, right. Yeah, yeah. Spend the whole time reading digits with different qu- quantities. c- c- Can I- can I have an- another - another question w- about this? So, um, there are these digits, which are detached digits, but there are other words that contain I thought this was gonna be fast. Oh well. the same general phon- phoneme sequences. Like "wonderful" has "one" in it and - and Victor Borge had a - had a piece on this where he inflated the digits. Well, I wonder if there's, um, an- if there would be a value in having digits that are in essence embedded in real words to compare in terms of like the articulation of "one" in "wonderful" versus "one" as a digit being read. That's "two" bad. Yeah. I'm all "four" it. There you go. Not after I "eight" though. Uh, they don't all work as well, do they? Hmm. What does nine work in? Uh, Uh. Nein! You scream it. Nein! You have to be German, yeah. Oh. In German, yeah. That's right! Oh, oh! It's great for the Germans. That's German, yeah. Nein. Yeah. Oh! It only sounds w- good when you scream it, though. I think everybody's a little punchy here today. Yes. So. Well, I mean, I just wanted to offer that as a possible task because, you know, if we were to each read his embedded numbers words in sent- in sentences cuz it's like an entire sketch he does and I wouldn't take the inflated version. So he talks about the woman being "two-derful", and - and - a- But, you know, if it were to be deflated, just the normal word, it would be like a little story that we could read. Mm-hmm. I don't know if it would be useful for comparison, but it's embedded numbers. Well I don't know. I think for something like that we'd be better off doing like uh TIMIT. Well I think the question is what the research is, so I mean, I presume that the reason that you wanted to have these digits this way is because you wanted to actually do some research Hmm. looking at the prosodic form here. Right, yeah. Yeah O_K. So if somebody wanted to do that, if they wanted to look at the - the - the difference of the uh phones in the digits in the context of a word versus uh the digits - a - a non-digit word versus in digit word, uh that would be a good thing to do, but I think someone would have to express interest in that. I see. O_K. I think, to - I mean if you were interested in it then we could do it, for instance. O_K, thank you. Huh. O_K, are we done with digits? Um, We have A_S_R results from Liz, transcript status from Jane, and disk space and storage formats from Don. Does - do we have any prefer- preference on which way we wanna - we wanna go? Well I was actually gonna skip the A_S_R results part, in favor of getting the transcription stuff Mm-hmm. talked about since I think that's more important to moving forward, but I mean Morgan has this paper copy and if people have questions, um, it's pretty preliminary in terms of A_S_R results because we didn't do anything fancy, but I think e- just having the results there, and pointing out some main conclusions like it's not the speaking style that differs, it's the fact that there's overlap that causes recognition errors. And then, the fact that it's almost all insertion errors, which you would expect but you might also think that in the overlapped regions you would get substitutions and so forth, um, leads us to believe that doing a better segmentation, like your channel-based segmentation, or some kind of uh, echo cancellation to get basically back down to the individual speaker utterances would be probably all that we would need to be able to do good recognition on the - on the close-talking mikes. Um, why don't you, if you have a hard copy, why don't you email it So these - So, that's about the summary - to the list. But this is - Morgan has this paper. I mean he - he - it - it's that paper. Yeah, yeah. Yeah, yeah. Yeah, so it's the same thing? It's the same thing I mailed to every- Oh it's in the paper. O_K. everybody that w- where it was, yeah. So, we basically, um, O_K then, it's already been mailed. did a lot of work on that and it's - Let's see, th- I guess the other neat thing is it shows for sure w- that the lapel, you know within speaker is Horrible? bad. And it's bad because it picks up the overlapping speech. So, your - your A_S_R results were run on the channels synchronized, O_K. Yes, cuz that's all that w- had been transcribed at the time, um O_K. O_K. but as we - I mean I wanted to here more about the transcription. If we can get the channel asynchronous or the - the closer t- that would be very interesting for us because we - Yeah. So if - Yeah, that's - that's why I only Yeah. used the part from use- which we had uh about uh about the alt- over all the channels or mixed channel rather mixed signal. Right. That's - Yeah. Yeah sure. Yeah. Yeah. cuz - So if there was a segment of speech this long Yeah. And someone said "oh" in the front - in the middle. and oh and someone said "oh," the whole thing was passed to the recognizer? That's why there's so many insertion errors? There were several speakers in it, yeah. That's right. In fact I - I pulled out a couple classic examples in case you wanna u- use them in your talk of Mm-hmm. Chuck on the lapel, so Chuck wore the lapel three out of four times. Mmm. I noticed that Chuck was wearing the lapel a lot. Um, yeah, and I wore the lapel once, and for me the lapel was O_K . I mean I still - Early on, yeah. and I don't know why. I'm - But um, for you it was - Or who was next to me or something like that. Probably how you wear it - wore it I would guess. Yeah, where you were sitting probably affected it. Yeah. Right, but when Chuck wore the lapel and Morgan was talking there're a couple really long utterances where Chuck is saying a few things inside, and it's picking up all of Morgan's words pretty well and so the rec- you know, there're error rates because of insertion - Insertions aren't bounded, so with a one-word utterance and ten insertions you know you got huge error rate. Uh-huh. Yeah. And that's - that's where the problems come in. So I- this is sort of what we expected, but it's nice to be able to - to show it. Right. And also I just wanted to mention briefly that, um, uh Andreas and I called up Dan Ellis who's still stuck in Switzerland, and we were gonna ask him if - if there're - you know, what's out there in terms of echo cancellation and things like that. Not that we were gonna do it, but we wanted to know And he said, "Lots lots lots lots." what would need to be done. And he - We've given him the data we have so far, so these sychronous cases where there are overlap. Yep. And he's gonna look into trying to run some things that are out there and see how well it can do because right now we're not able to actually report on recognition in a real paper, like a Eurospeech paper, because it would look sort of premature. So - So - So the idea is that you would take this big hunk where somebody's only speaking a small amount in it, and then try to figure out where they're speaking based on Right. Or who's - At any point in time who's the foreground speaker, who's the background speaker. the other peopl- I thought we were just gonna move the boundaries in. So yeah - So. Yeah, should it - Well that's with the hand stuff. So there's like - But how would you do that automatically? Right. Uh, I've actually done some experiments with cross-correlation and it seems to work pretty well to - to get rid of those - those overlaps, yeah. Well ther- there's - Mm-hmm. I mean that- that's the sort of thing that you would do. So. Yeah. Yeah. Exactly, so it's - it's a - So why do you want to do echo cancellation? Um, it would be techniques used from adaptive - adaptive echo cancellation which I don't know enough about to talk about. Um. Uh-huh. It - just - it just to r- to remove cross-talk. Yeah. Yeah. But, right, um, and that would be similar to what you're also trying to do, but using um, you know, more than energy - I - I don't know Yeah. what exactly would go into it. So the idea is to basically run this on the whole meeting. Yeah, sure. So it would be - and get the locations, which gives you also the time boundaries O_K. So do sort of what he's already - what he's trying to do. of the individual speak- Right. Except that there are many techniques for the kinds of cues, um, that you can use to do that. O_K, I s- I see. Yeah, in another way, yeah. Yeah. Yeah. I see. Yeah, Dave - Dave uh is, um, also gonna be doin- usin- playing around with echo cancellation for the near-field far-field stuff, so we'll be - So. And I guess Espen? This - is - uh - is he here too? May also be working - So it would just be ver- that's really the next step because we can't Yeah. do too much, you know, on term- in terms of recognition results knowing that this is a big problem Mm-hmm. um, until we can do that kind of processing. And so, once we have some - O_K. Yeah I'm working on it. some of yours, and @@ we'll move on. I think this also ties into one of the things that Jane is gonna talk about too. Um, O_K. Mm-hmm. Mm-hmm. I also wanted to say I have done all this chopping up of digits, so I have some naming conventions that we should try to agree on. Oh right. Yeah. Right. Definitely - So let's do that off-line, we don't need to do it during the meeting. O_K. Uh, and Don should - And - and I have scripts that will extract it out from "key" files and - and do all the naming automatically, so you don't have to do it by hand. O_K. Alright. Great. So that- that's it for the - You've compiled the list of, uh, speaker names? Speakers and - O_K. Mm-hmm. Not names, but Yep. Yeah, names - names in the - names to I_Ds, so you I_Ds. O_K. Great. and it does all sorts of matches because the way people filled out names is different on every single file so it does a very fuzzy sort of match. Right. Cool. So at this point we can sort of finalize the naming, and so forth, and we're gonna basically re- Yep. Mm-hmm. rewrite out these waveforms that we did because as you notice in the paper your "M_O_-four" in one meeting and "M_O_-two" in another meeting and it's - we just need to standardize the Yeah. That was my fault. um, no it's - it's - No, I didn't notice that actually. @@ um, that's why those comments are s- are in there. So - Yeah. Then disregard it then. Yep. So th- I now have a script that you can just say basically Right. Yeah. O_K. look up Morgan, and it will give you his I_D. So. Great, great. Terrific. O_K . Um, alright. Do we - Don, you had disk space and storage formats. Is that something we need to talk about at the meeting, or should you just talk with Chuck Um, at some other time? I had some general questions just about the compression algorithms of shortening waveforms and I don't know exactly who to ask. I thought that maybe you would be the - the person to talk to. So, is it a lossless compression when you compress, so - Mm-hmm. Entropy coding. So. It just uses entropy coding? O_K. So, I mean, I guess my question would be is I just got this new eighteen gig drive installed. Um, yeah, which is - And I assume half of it is scratch and half of it is - ? I'm not exactly sure how they partitioned it. But um, Probably, yeah. That's typical, huh. yeah, I don't know what's typical here, but um, it's local though, so - That doesn't matter. But - You can access it from anywhere in ICSI. O_K. In fact, this is an eighteen gig drive, or is it a thirty six gig drive with eighteen - Alright. How do you do that? N_ - Eighteen. Eigh- eighteen. It was a spare that Dave had around - Oh O_K. Slash N_ slash machine name, slash X_A_ in all likelihood. Oh I see. O_K. Alright, I did know that. Um, so the - the only question is how much of it - The distinction between scratch and non-scratch is whether it's backed up or not. Mm-hmm. Right. So what you wanna do is use the scratch for stuff that you can regenerate. O_K. So, the stuff that isn't backed up is not a big deal because disks don't crash very frequently, as long as you can regenerate it. Right. Right. I mean all of this stuff can be regenerated, it's just a question - Yeah it's - Well the - Then put it all on scratch because we're - ICSI is - is bottlenecked by backup. Yeah. Mm-hmm, very good point. O_K. Well I'd leave all the - All the transcript stuff shouldn't - should be backed up, but all the waveform - So we wanna put - Mm-hmm. Sound files should not be backed up, the ones that you write out. Yeah, I guess - Right. O_K. So, I mean, I guess th- the other question was then, should we shorten them, downsample them, or keep them in their original form? Um - It just depends on your tools. I mean, because it's not backed up and it's just on scratch, if your sc- tools can't take shortened format, I would leave them expanded, Right. so you don't have to unshorten them every single time you wanna do anything. O_K. We can downsample them, Do you think that'd be O_K? so. Yeah. To downsample them? Yeah, we get the same performance. I mean the r- the front-end on the S_R_I recognizer just downsamples them on the fly, so - O_K. Yeah, I guess the only argument against downsampling is to preserve just the original files in case we want to experiment with different filtering techniques. So that's - I - I - I'm sorry - Yeah, l- I mean over all our data, we - we want to not downsample. Yeah, if fe- You'd - you wanna not. O_K. So we're - what we're doing is we're writing out - Yeah. I mean, this is just a question. We're writing out these individual segments, that wherever there's a time boundary from Thilo, or - or Jane's transcribers, you know, we - we chop it there. Yeah. Mm-hmm. And the reason is so that we can feed it to the recognizer, and throw out ones that we're not using and so forth. Mm-hmm. Yeah. And those are the ones that we're storing. Yeah, as I said, since that's - it's regeneratable, what I would do is take - So - Yeah. downsample it, and compress it however you're e- the S_R_I recognizer wants to take it in. Yeah. So we can't shorten them, but we can downsample them. So. ye- Right. Yeah, I mean - yeah, I'm sorry. As - yeah, as long as there is a - a form that we can come from again, r- Yeah. that is not downsampled, then, Oh yeah th- Yeah those are gonna be kept. Yeah. Yeah. That - that's why we need more disk space cuz we're basically duplicating the originals, um - uuu Yeah. Then it's fine. But for - for - fu- future research we'll be doing it with different microphone positions and so on we would like to - Right. Oh yeah. No. We always have the original long ones. Yep. Right. Yeah. So the S_R_I front-end won't take a uh - an - an - a large audio file name and then a - a list of segments to chop out from that large audio file? They actually have to be chopped out already? Um, it's better if they're chopped out, and - and it - it will be - Uh-huh. yeah, y- we could probably write something to do that, but it's actually convenient to have them chopped out cuz you can run them, you know, in different orders. You c- you can actually move them around. And that's the whole point about the naming conventions is that you could Uh, you can get rid of- Yeah, it- it's a lot faster. run all the English speaking, all the native speakers, and all the non-native speakers, and all the men, and all the women. Yeah. Right. You can grab everything with the word "the" in it, and it's - That's a lot quicker than actually trying to access the wavefile each time, find the time boundaries and - So in principle, yeah, you could do that, but it's - I don't - I don't think that's really right. but it's um - "That's just not right, man." These are long - These are long - You know. This is an hour of speech. The - the point - So - so s- For example, what if you wanted to run - run all the native speakers. Right, so if - if you did it that way you would have to generate a program that looks in the database somewhere, extracts out the language, finds the time-marks for that particular one, do it that way. The way they're doing it, you have that already extracted and it's embedded in the file name. And so, you know, you just say - We- yeah that's - so that's part of it is - y- so you just say you know "asterisk E_ asterisk dot wave", and you get what you want. Right. And the other part is just that once they're written out it - it is a lot faster to - to process them. Rather than doing seeks So. through the file. Otherwise, you're just accessing - This is all just temporary access, so I don't - I think - it's all just - It's fine. You know. Fine to do it however is convenient. Right. I mean it just depends how big the file is. If the file sits in memory you can do extremely fast seeks but. Right. The other thing is that, believe it or not - Yeah and they don't. I mean, we have some - Two gig? So we're also looking at these in Waves like for the alignments and so forth. You can't load an hour of speech into X_Waves . Yeah. You need to s- have these small files, and in fact, even for the Transcriber program Yes you can. Um - Yeah, you - you can give Waves a start and an end time. And middle. Yeah, if you try to load s- really long waveform into X_Waves, you'll be waiting there for - No, I - I'm not suggesting you load a long wave file, I'm just saying you give it a start and an end time. And it'll just Oh- I th- go and pull out that section. w- The transcribers didn't have any problem with that did they Jane? What's th- u- w- in what respect? Loading the long - They loaded - they loaded the long No, with the Transcriber tool, it's no problem. long files into X_Waves. It takes a very long ti- In the - in- Yeah just to load a transcription Mm-hmm. @@ Right. It takes a l- very long time. takes a long time, but not for the wavefile. The wavefile is there immediately. Mm-hmm. Yeah. Huh. Are you talking about Transcriber or X_Waves ? Yeah. Oh, I'm tr- talking about Transcriber. Actually, you're talking about Transcriber, right? Yeah. It was also true of the digits task which was X_Waves. Because - because i- we used X_Waves to do the digits. Yeah. And they were loading the full mixed files then, and it didn't seem to be any problem. Very quickly. I agree. Huh. Well we - we have a problem with that, you know, time-wise on a - It- it's a lot slower to load in a long file, and also to check the file, so if you have a Hmm. Seemed really fast. transcript, um, Well regardless, it's - I mean it's - Yeah. I - I think overall you could get everything to work by accessing the same waveform and trying to find two - you know, the begin and end times. Um, but I think it's more efficient, if we have the storage space, to have the small ones. and, it's no problem, right? Because it's not backed up. Yeah, it's - Yeah. It's - it's just - So we just - If we don't have a spare disk sitting around we go out and we buy ourselves an eighty gigabyte drive and make it all scratch space. You know, it's not a big deal. You're right about the backup being a bottleneck. It's good to Right. Yeah, so these wouldn't be backed up, the - think towards scratch. Yeah. Yep. Right. So remind me afterward and I'll - And - and we'll look at your disk and see where to put stuff. O_K. Alright. I mean, I could just u- do a D_U on it right? And just see which - how much is on each - Yep. So. Each partition. And you wanna use, either X_A or scratch. O_K. Well X_ question mark, anything starting with X_ is scratch. O_K. With two - two digits. Two digits, right, X_A, X_B, X_C. O_K? Jane? So, @@ . O_K. So I got a little print-out here. So three on this side, three on this side. And I stapled them. O_K. Alright so, first of all, um, there was a - an interest in the transcribe- transcription, uh, checking procedures and - and I can tell you first, uh, to go through the steps although you've probably seen them. Um, as you might imagine, when you're dealing with, um, r- really c- a fair number of words, and uh, @@ natural speech which means s- self-repairs and all these other factors, that there're lots of things to be, um, s- standardized and streamlined and checked on. And, um, so, I did a bunch of checks, and the first thing I did was obviously a spell-check. And at that point I discovered certain things like, um, "accommodate" with one "M_", that kind of thing. And then, in addition to that, I did an exhaustive listing of the forms in the data file, which included n- detecting things like f- faulty punctuation and things - Yeah? I'm - I'm sorry to interrupt you could - could I just back up a little bit and - Sure, please, yeah, please, please. Yeah, yeah, yeah. So you're doing these - So the whole process is that the transcribers get the conversation and they do their pass over it. Yes. And then when they're finished with it, it comes to you, and you begin these sanit- these quality checks. O_K. O_K. That's right. Exactly. I do these checks. Uh-huh. Exactly. Yeah. Thank you. And so, uh, I do a - an exhaustive listing of the forms - Actually, I will go through this in - in order, so if - if we could maybe wait and stick keep that for a second cuz we're not ready for that. So on the fifth page, seven down - Yeah, yeah, yeah, yeah. Exactly! Exactly! Alright so, a spelling check first then an exhaustive listing of the, uh - all the forms in the data with the punctuation attached and at that point I pick up things like, oh, you know, word followed by two commas. And th- and then another check involves, uh, being sure that every utterance has an identifiable speaker. And if not, then that gets checked. Then there's this issue of glossing s- w- so-called "spoken-forms". So there - mo- for the most part, we're keeping it standard wo- word level transcription. But there's - w- And that- that's done with the assumption that pronunciation variants can be handled. So for things like "and", the fact that someone doesn't say the "D_", uh that's not important enough to capture in the transcription because a - a good pronunciation, uh, you know, model would be able to handle that. However, things like "cuz" where you're lacking an entire very prominent first syllable, and furthermore, it's a form that's specific to spoken language, those are r- reasons - f- for those reasons I - I kept that separate, and used the convention of using "C_U_Z" for that form, however, glossing it so that it's possible with the script to plug in the full orthographic form for that one, and a couple of others, not many. So "wanna" is another one, "going -" uh, "gonna" is another one, with just the assumption, again, that this - th- these are things which it's not really fair to a- c- consider - expect that - a pronunciation model, to handle. And Chuck, you in- you indicated that "cuz" is - is one of those that's handled in a different way also, didn't you? Did I - I don't remember. O_K. So - so- it might not have been - It might not have been you, but someone told me that in fact "cuz" is treated differently Hmm. in, um, i- u- in this context because of that r- reason that, um, it's a little bit farther than a pronunciation variant. O_K, so after that, let's see, um. So that was part of the spell-check, or was that - that was after the spell-check? Well so when I get the exhau- So the spell-check picks up those words because they're not in the dictionary. So it gets "cuz" and "wanna" and that - Uh-huh. And then you gloss them? Yeah, mm-hmm. Run it through - I have a sed - You know, so I do sed script saying whenever you see "gonna" you know, "convert it to gonna", you know, "gloss equals quote going-to quote", you know. And with all these things being in curly brackets so they're always distinctive. O_K, I also wrote a script which will, Mm-hmm. um, retrieve anything in curly brackets, or anything which I've classified as an acronym, and - a pronounced acronym. And the way I tag ac- pronounced acronyms is that I have underscores between the components. So if it's "A_C_L" then it's "A_" underscore "C_" underscore "L_". And the th- And so - so your list here, are these ones that actually occurred in the meetings? Yes. Uh-huh, yeah. Whew! O_K, so now. Uh and - a- We are acronym- loaded. Um, can I ask a question about the glossing, uh before we go on? So, Yeah. for a word like "because" is it that it's always predictably "because"? I mean, is "C_U_Z" always meaning "because"? Yes, but not the reverse. So sometimes people will say "because" in the meeting, and if - if they actually said "because", then it's written as "because" with no - w- "cuz" doesn't even figure into the equation. Beca- because - But - but in our meetings people don't say "hey cuz how you doing?" Right. Right. Except right there. Yeah. Yeah. Um, so, I guess - So, from the point of view of - That's a good point. The - the only problem is that with - for the recognition we - we map it to "because", and so if we know that "C_U_Z" - Well, That's fine. Well Don has a script. but they have the gloss. You have the gloss form so you always replace it. Yeah. but, we don't - Exactly. If that's how - what you wanna do. Uh-huh. And Don knows this, and he's bee- he has a glo- he has a script that - Yeah. I replace the "cuz" with "because" if it's glossed. S- Right. But, if it's - O_K. And - But then there are other glosses that we don't replace, right? Because - Yes. And that's why there're different tags on the glosses, O_K. So, then it's fine. on the different - on the different types of comments, which we'll - which we'll see in just a second. Right. O_K. So the pronounceable acronyms get underscores, the things in curly brackets are viewed as comments. There're comments of four types. So this is a good time to introduce that. The four types. w- And maybe we'll expand that but the - but the comments are, um, of four types mainly right now. One of them is, um, Um - Can - ca- the gloss type we just mentioned. Another type is, um - So a- are we done with acronyms? Cuz I had a question on what - what this meant. I'm still doing the overview. I haven't actually gotten here yet. O_K so, gloss is things like replacing the full form Oh I'm sorry. u- with the, um, more abbreviated one to the left. Uh, then you have if it's - uh, there're a couple different types of elements that can happen that aren't really properly words, and wo- some of them are laughs and breathes, so we have - uh that's prepended with a v- a tag of "V_O_C". Whew! @@ And the non-vocal ones are like door-slams and tappings, and that's prepended with a no- non-vocalization. So then it - just an ending curly brace there, or is there something else in there. Oh yeah, so i- e- this would - Let's just take one example. A comment, basically. Oh, oh, oh. And then the no- non-vocalization would be something like a door-slam. They always end. So it's like they're paired curly brackets. And then the third type right now, uh, is m- things that fall in the category of comments about what's happening. So it could be something like, you know, "referring to so-and-so", "talking about such-and-such", uh, you know, "looking at so-and-so". Yeah. So on the m- on the middle t- So, in the first case that gloss applies to the word to the left. But in the middle two - Yeah, and this gets substituted here. They're impulsive. Th- it's not applying to anything, right? O_K. Huh-uh. No, they're events. They're actually - They have the status of events. O_K. Well the "QUAL" can be - The "QUAL" is applying to the left. Right, I just meant the middle two ones, yeah. Yep. Well, and actually, um, it is true that, with respect to "laugh", there's another one which is "while laughing", and that is, uh, i- i- An argument could be made for this - "While laughing". tur- turning that into a qualitative statement because it's talking about the thing that preceded it, but at present we haven't been, um, uh, coding the exact scope of laughing, you know, and so to have "while laughing", you know that it happened somewhere in there which could well mean that it occurred separately and following, or, you know, including some of the utterances to the left. Haven't been awfully precise about that, but I have here, now we're about to get to the - to this now, I have frequencies. So you'll see how often these different things occur. But, um, uh, the very front page deals with this, uh, final c- pa- uh, uh, aspect of the standardization which has to do with the spoken forms like "mm-hmm" and "mm-hmm" and "ha" and "uh-uh" and all these different types. And, um, uh, someone pointed out to me, this might have been Chuck, about, um - about how a recognizer, if it's looking for "mm-hmmm" with three M_'s, and it's transcribed with two M_'s, that it might - uh, that it might increase the error rate which is - which would really be a shame because um, I p- I personally w- would not be able to make a claim that those are dr- dramatically different items. So, right now I've standardized across all the existing data with these spoken forms. I - I should say Oh good. So it's a small list. all existing data except thirty minutes which got found today. So, I'm gonna - I'm gonna - I'm gonna check - That - that's known as "found data". Yeah, yeah. Acsu- actually yeah. I got - It was stored in a place I didn't expect, It's like the z- Zapruder Film. so - and - and um, w- we, uh, sh- yea- reconstructed how that happened. I wanna work with lost data. Yeah. It's much easier. And this is - this'll be great. So I'll - I'll be able to get through that tonight, and then everyth- i- well, actually later today probably. Hmm. And so then we'll have everything following these conventions. But you notice it's really rather a small set of these kinds of things. And I made it so that these are, um, with a couple exceptions but, things that you wouldn't find in the spell-checker so that they'll show up really easily. Yeah. And, um - Jane, can I ask you a question? What's that very last one correspond to? I don't even know how to pronounce that. Sure. Yeah. Well, yeah. Now that - that s- only occurs once, and I'm thinking of changing that. Right. So- c- I haven't listened to it so I don't know. Uh, is that like someone's like burning or some such thing? Like their hair's on fire? I haven't heard it actually. I n- I need to listen to that one. Ah! Uh, it looks like that . Actually we - we gave this to our pronunciation person, she's like, "I don't know what that is either ". So. It's the Castle of Ah! Did she hear the th- did she actually hear it? Cuz I haven't heard it. No, we just gave her a list of words that, you know, weren't in our dictionary and so of course it picked up stuff like this, and she just didn't listen so she didn't know. We just - we're waiting on that just to do the alignments. Yeah. Yeah I'm curious to se- hear what it is, but I didn't know - wanna change it to something else until I knew. Maybe it's "argh"? Right. @@ Well, sss, you know - But that's not really like - Hhh. Yeah. No one really says "argh," you know, it's not - @@ Right, no one say- Well, you just did. Well, Yeah. That's right. @@ - there's another - there's another word error. Except for now! Yes, that's right. We're gonna have a big problem when we talk about that. Cha- ching. Ah. We're gonna never recognize this meeting. O_K. In Monty Python you say "argh" a lot. So. Well, or if you're a C_ programmer. Oh yeah? Mmm. Yeah, that's right. That's right. Yeah. You say arg-C_ and arg-V_ all the time. That's true. Yeah Yeah. But it has a different prosody. Arg. It does. Arg - arg-max, arg-min, yeah. Mm-hmm. Ah! Uh, So, Jane, what's the - d- I have one question about the Maybe he died while dictating. so. the "E_H" versus like the "A_H" and the "U_H". That's partly a nonnative-native thing, but I have found "E_H" in native speakers too. @@ O_K. But it's mostly non-native - S- O_K. H_ That's "eh" versus "ah"? Eh. Eh? "Eh," yeah right, cuz there were - were some speakers that did definite "eh's" but right now we - Mm-hmm. They were the Canadians, right? Canadians, yeah, yeah, yeah. That's right. So, it - it's actually probably good for us to know the difference between the real "eh" and the one that's just like " uh " or transcribed "aaa" cuz in - like in Switchboard, you would see Exactly. e- all of these forms, but they all were like "uh". You mean just the single letter "a" as in the particle? The transcription or - No, no, I mean like the - the "U_H", or - the "U_H", "E_H", "A_H" were all the same. And then, we have this additional non-native version of - Article. "U_H". Oh. uh, like "eeh". All the "E_H"'s I've seen have been like that. They've been like "eh" like that have bee- has been transcribed to "E_H". Mm-hmm, that's right. And sometimes it's stronger, like "eeh" which is like closer to "E_H". But. Mmm. Right. Yeah. I'm just - these poor transcribers, they're gonna hate this meeting. I know. We should go off-line. Well, we're not doing - We're not doing length. Quick Thilo, do a - do a filled pause for us. Yeah, that's right. Ooo no. But you're a native German speaker so it's not a - Yeah. not a issue for - It's only - @@ Them Canadians. Onl- yeah. No, only if you don't have lax vowels, I guess. Right. So it's - like Japanese and Spanish and - Oh. This makes sense. Yeah I - I think you've - uh-huh, yeah. Uh- huh. Oh I see. I didn't get that, O_K. That makes sense. Yeah, and so, you know, I mean, th- th- I have - there are some, um, Americans who - who are using this "eh" too, and I haven't listened to it systematically, maybe with some of them, uh, they'd end up being "uh's" but, uh, I- my spot-checking has made me think that we do have "eh" in also, um, American e- e- data represented here. But any case, that's the - this is reduced down from really quite a long- a much longer list, and this is Yeah this is great. This is really really helpful. Mm-hmm. Yeah, it's good, yeah. functionally pretty, you know, also - It was fascinating, I was listening to some of these, uh, I guess two nights ago, and it's just hilarious to liste- to - to do a search for the "mm- hmm's ". And you get "mm-hmm" and diff- everybody's doing it. And just listen to them? Yeah. Just - I wanted to say - I w- think it would be fun to make a montage of it because there's a "Mm-hmm. Mm-hmm. Mm-hmm." Performance art, just extract them all. Right. It's really - it's really fun to listen to. Morgan can make a song out of it. All these different vocal tracts, you know, but it's - it's the same item. It's very interesting. O_K. Uh, then the acronyms y- and the ones in parentheses are ones which the transcriber wasn't sure of, and I haven't been able to listen to to - to clarify, but you can see that Oh I see. the parenthesis convention makes it very easy to find them cuz it's the only place where - where they're used. o- How about question mark? The question marks, yeah. What are those? Question mark is punctuation. So it - they said that @@ - Oh. Mm-hmm. um, "D_C?" So they - so it's "P_L_P?" Ah. Exactly. Exactly. Yeah, so the only - Well, and I do have a stress marker here. Sometimes the contrastive stress is showing up, and, um - I'm sorry, I - I got lost here. What- w- what's the difference between the parenthesized acronym and the non-parenthesized? The parenthesized is something that the transcriber thought was A_N_N, but wasn't entirely sure. So I'd need to go back or someone needs to go back, and say, you know, yes or no, and then get rid of the parentheses. But the parentheses are used only in that context in the transcripts, of Ah. Right. of noti- noticing that there's something uncertain. Yeah, P_make is - That's a good one. That's correct. Yeah I mean cuz they - they have no idea, right. If you hear C_T_P_D, I mean, they do pretty well but it's - Yeah. Mm-hmm. I - I don't recognize a lot of these. I - you know how are - how are they gonna know? I know! I - I was saying that I think a lot of them are the Networks meeting. Yeah. I think that's true. Yeah, absolutely. N_S_A, a lot of these are - are coming from them. I listened to some of that. Maybe. Yeah. I see a few. Although I see - I see plenty of uh Yeah, we don't have that many acronyms comparatively in this meeting. It's not so bad. Yeah. Yeah. I agree. Right. And Robustness has a fair amount, but the N_S_A group is just very very many. Yeah. Mmm. The recognizer, it is funny. Kept getting P_T_A for P_D_A. That's not bad. This is close, right, and the P_T_A was in these, uh, topics about children, so, anyway. Yeah. Yeah, that's pretty close. Yeah. That's interesting. Is the P_- P_T_A working? Right and sometimes, I mean, you see a couple of these that are actually "O_K's" so it's - it's - may be that they got to the point where - I mean it was low enough understandable - understandability that they weren't entirely sure the person said "O_K." You know, so it isn't really necessarily a an undecipherable acronym, but just n- needs to be double checked. Now we get to the comments. This - There's a lot of "O_K's". The number to the left is the number of incidences? Uh-huh. Count. Yep. Number of times out of the entire database, w- except for that last thirty minutes I haven't checked yet. So C_T_S is really big here, yeah. Yeah, I wonder what it is. Yeah. So what is the difference between "papers rustling" and "rustling papers"? I_P, I know what I_P is. I'd have to listen. I - I- I agree. I w- I'd like to standardize these down farther but, um, uh, uh, to me that sounds equivalent. Yeah. But, I - I'm a little hesitant to - to collapse across categories unless I actually listen to them. Seems so. O_K. Oh I'm sure we've said X_M_L more than five times. Well, then, at least now. Yeah. Six. Now it's at least six times, yeah. S- s- six now, yeah. O_K well - I'm wai- Wh- the self-referential aspect of these - these p- Yes, it's very bad. Yeah. Well this is exactly how people will prove that these meetings do differ because we're recording, right? Yes. Y- no- normally you don't go around saying, "Now you've said it six times. Now you've said-" Yeah that's right. But did you notice that there were seven hundred and eighty five instances of "O_K"? And that's just without the - without Yep. No, I didn't. Yeah. Seven hundred eighty-five instances. Yeah. punc- punctuation. Extra forty one if it's questioned. And that's an underestimate cuz they're Where's that? So th- Yep. On the page two of acronyms. Yeah. Is this after - like did you do some uh replacements for all the different form of "O_K" to this? O_K. Seven hundred eighty. Yeah. Of "O_K", yes. Mm-hmm. So that's the single existing convention for "O_K". Wait a minute, w- s- So now we're up to seven hundred and eighty eight. Yeah that's - Although, what's - there's one with a slash after it. Yeah. That's - that's - I looked for that one. I actually explicitly looked for that one, and I think that, um, That's kind of disturbing. Yeah, we'll have to look at it you know. Yeah. Anyway. Mm-hmm. I - I'm not exactly sure about that. Was that somewhere where they were gonna say "new speaker" or something? No, I looked for that, but that doesn't actually exist. And it may be, I don't - I can't explain that. That's alright. I'm just pointing that out. There's - I- i- it's the only - it's the only pattern that has a slash after it, and I think it's - it's an epiphenomenon. Well there's not @@ . So I'll just - I was just looking at the bottom of page three there, is that "to be" or "not to be". Yeah. Oh that's cute. That's funny. There's no tilde in front of it, so. Yeah. O_K. O_K anyways, sorry. There is th- one - "Try to stay on topic, Adam." Y- well, no, that's r- that's legitimate. So now, uh, comments, you can see they're listed again, same deal, with exhaustive listing of everything found in everything except for these final th- O_K so, um, on some of these QUALs, thirty minutes. Yeah. are they really QUALs, or are they glosses? So like there's a "QUAL T_C_L". "T_C_L". Where do you see that? Uh Oh, oh. The reason is because w- it was said "tickle". What's a QUAL? Oh I see, I see. So it's not gloss. O_K, I see. Hmm. Yep. It wasn't said "T_C_L". Of course. Sh- shouldn't it be "QUAL T_I_C_K_L_E" or something? Like - it's not - On the - in the actual script - in the actual transcript, I s- I - So this - this happens in the very first one. I actually wrote it as "tickle". Mm-hmm. O_K. Because we - they didn't say "T_C_L", they said "tickle". Yeah. Right. And then, following that is "QUAL T_C_L". Oh I see. O_K. I f- I forget, what's QUAL? Qual- qualifier. It's just comment about what they said. Comment. Comment or contextual comment. Yeah. It's not something you wanna replace with but - So they didn't mean "tickle" as in Yeah. Elmo, they meant "tickle" as in - Tickle? Yeah. Huh. Right. But at some point - I mean, we probably shoul- We'll probably add it to the language model. But we should add it to the dictionar- No, to the pronunciation model. Yeah. What did I say? Language, uh - To the language model - model. Well both. We can go on lan- lan- add it to both dictionary and language model. Oh lan- Oh O_K- we- O_K - it's in the language model, Add what, Liz? Yeah. w- yeah, but it- so it's the pronunciation model that has to have a pronunciation of " tickle". Well "tickle" was pronounced "tickle". Right? It's pronounced the same - it's pronounced the same as the verb. So I think it's the language model that makes it different. What are you saying? "tickle" is pronounced "tickle"? I'm sorry! Oh, sorry. What I meant is that there should be a pronunciation "tickle" for T_C_L as a word. And that word in the - in, you know, it stays in the language model wherever it was. Oh I see. Yeah. Mm- hmm. Right. Right. Yeah you never would put "tickle" in the language model in that form, yeah. Right. @@ Right. Right. There's actually a bunch of cases like this with people's names and - So how w- there'd be a problem for doing the language modeling then with our transcripts the way they are. Yes. Yeah. Yeah so th- th- there- there's a few cases like that where the um, the word needs to be spelled out in - in a consistent way as it would appear in the language, but there's not very many of these. Tcl's one of them. And - and you'll ha- you'll have to do it sychronously. Um, y- yeah. Right, so y- so, whoever's creating the new It's just disturbing. models, will have to also go through the transcripts and change them synchronously. Right. Right. We have this - there is this Hmm. thing I was gonna talk to you about at some point about, you know, what do we do with the dictionary as we're up- updating the dictionary, these changes have to be consistent with what's in the - Like spelling people's names and so forth. If we make a spelling correction to their name, like someone had Deborah Tannen's name misspelled, and since we know who that is, you know, we could correct it, but - You can correct it. Yeah. but we need to make sure we have the misspel- If it doesn't get corrected we have to have a pronunciation as a mispelled word in the dictionary. Things like that. Mm-hmm. These are so funny to read. Well, of course now the - the Tannen corre- the spelling c- change. Uh, that's what gets - I - I picked those up in the frequency check. So. Right. Right. So if there's things that get corrected before we get them, it's - it's not an issue, but if there's things that Mm-hmm. um, we change later, then we always have to keep our - the dictionary up to date. And then, yeah, in the case of "tickle" I guess we would just have a, you know, word "T_C_L" which - Mm-hmm. You add it to the dictionary. which normally would be an acronym, you know, "T_C_L" Right. but just has another pronunciation. Yep. " ICSI " is - is one of those that sometimes people pronounce and sometimes they say "I_C_S_I." So, Mm-hmm. Oh yeah. those that are l- are listed in the acronyms, I actually know they were said as letters. The others, um, e- those really do need to be listened to cuz I haven't been able to go to all the IC- ICSI things, and - Right, exactly. and until they've been listened to they stay as "I_C_S_I". Mm-hmm. Right. Don and I were just noticing, love this one over on page three, "vocal - vocal gesture mimicking sound of screwing something into head to hold mike in place." It's this, "rrre-rrre-rrre". That's great. It was me. It was! In fact, it was! Yeah! A lot of these are me the - the "beep is said with a high pit- high pitch and lengthening." He - he s- he said - he said get - To head . Yeah, that's it. That was the - I was imitating uh, beeping out - Beep. Perfect. Yeah that's it. That's it. Oh there is something spelled out "B_E_E_E_E_E_E_P" Yeah. Um - Yeah, that's - that's been changed. Yeah. in the old - Thank you. Because he was saying, "How many E_'s do I have to allow for?" What I meant was "beep". You need a lot of - You need a lot of qualification Adam. That's been changed. So, exactly, that's where the lengthening comment c- came in. I guess so. Anyway. Right, thanks, yeah. s- chan- brought it down. Subtext. So they're vocalization, Right. And those of course get - get picked up in the frequency check because you see "beep" and you know - I mean it gets kicked out in the spelling, and it also gets kicked out in the, uh, freq- frequency listing. glosses. Right. Right. Right. I have the - there're various things like "breathe" versus "breath" versus "inhale" and, hhh, you know, I don't know. I - I think they don't have any implications for anything else so it's like I'm tempted to leave them for now an- and - It's easy enough to find them when they're in curly brackets. We can always get an exhaustive listing of these things and find them and change them. Yeah. "Sings finale-type song" that's - that's good. Yeah. Yeah, that was in the first meeting. Um, Yeah, but I don't actually remember what it was. But that was - Eric did that. Yeah. Yeah. So on - Tah-dah! I don't know. Something like that maybe, yeah. I think maybe something like that. Well, that'd qualify. On the glosses for numbers, Yeah. it seems like there are lots of different ways it's being done. There's a - O_K. Interesting question. Yes. O_K, now first of all - Ooo-ooo! Very important. Uh Chuck - Chuck led to a refinement here which is to add "NUMS" if these are parts of the read numbers. Now you already know i- "Ooo-ooo." that I had, uh, in places where they hadn't transcribed numbers, I put "numbers" in place of any kind of numbers, but there are places where they, um, it - th- this convention came later an- and at the very first digits task in some transcripts they actually transcribed numbers. And, um, d- Chuck pointed out that this is read speech, and it's nice to have the option of ignoring it for certain other prob- uh p- uh, things. And that's why there's this other tag here which occurs a hundred and five - or three hundred and five times right now which is just - well n- n- "NUMS" by itself which means this is part of the numbers task. I may change it to "digits". I mean, i- with the sed command you can really just change it however you want "NUMS", yeah. because it's systematically encoded, you know? Have to think about what's the best for - for the overall purposes, but in any case, Yep. um, "numbers" and "NUMS" are a part of this digits task thing. Um, now th- Then I have these numbers that have quotation marks around them. Um, I didn't want to put them in as gloss comments because then you get the substitution. And actually, th- um, the reason I b- did it this way was because I initially started out with the other version, you have the numbers and you have the full form and the parentheses, however sometimes people stumble over these numbers they're saying. So you say, "Seve- seventy eight point two", or whatever. And there's no way of capturing that if you're putting the numbers off to the side. You can't have the seven and - So what's to the left of these? The left is i- so example the very first one, it would be, spelled out in words, Mm-hmm. O_K, that's what I was asking. "point five". Right. Only it's spelled out in words. So i- this is also spelled out in - in words. "Point five." Point F_I_V_E, yeah. Good. And then, in here, "NUMS", so it's not going to be mistaken as a gloss. It comes out as "NUMS quote dot five". O_K now, the other example is, in the glosses right there, Thank you. "gloss one one one dash one three zero". What - what's to the left of that? Well now - Right. In that case it's people saying things like "one one one dash so-and-so" or they're saying uh "two - I mean zero" whatever. And in that case, it's part of the numbers task, and it's not gonna be included in the read digits anyway, so - I m- in the uh - O_K. So there will be a "NUMS" tag on those lines? There is. Yeah. I've added that all now too. Yeah. Good. There's a "numbers" tag - I'm sorry I'm - I didn't follow that last thing. Wait. So, so gloss - in the same line that would have "gloss quote one one one dash one thirty", you'd have a gloss at the end of the line saying, Right. uh, "curly bracket NUMS curly bracket". So if you - if you did a, uh, a "grep minus V_ nums" and you get rid of anything that was read. Oh, so you could do "grep minus V_ nums". So that's the - yeah. So there wouldn't be something like O_K. i- if somebody said something like, "Boy, I'm really tired, O_K." and then started reading that would be on a separate line? Yes. O_K great. Cuz I was doing the "grep minus V_" quick and dirty and looked like that was working O_K, but - Mm-hmm. Good. Great. Yep. Now why do we - what's the reason for having like the point five have the "NUMS" on it? Is that just like when they're talking about their data or something? Or - This is more because - Yeah. Oh these are all these, the "NUMS point", this all where they're saying "point" something or other. These are all like inside the spontaneous - And the other thing too is for readability of the transcript. I mean if you're trying to follow this while you're reading it it's really hard to read, you know - eh, "so in the data column five has", you know, "one point five compared to seventy nine point six", it's like when you see the words it's really hard to follow the argument. And this is just really a - a way of someone who would handle th- the data in a more discourse-y way to be able to follow what's being said. So this is where Chuck's, um, overall h- architecture comes in, where Oh O_K. Label it. I see. we're gonna have a master file of the channelized data. Um, there will be scripts that are written to convert it into these t- these main two uses and th- some scripts will take it down th- e- into a f- a for- ta- take it to a format that's usable for the recognizer an- uh, other scripts will take it to a form that's usable for the - for linguistics an- and discourse analysis. And, um, the implication that - that I have is that th- the master copy will stay unchanged. These will just be things that are generated, and Right O_K. e- by using scripts. Master copies of superset. When things change then the - the script will cham- change but the - but there won't be stored copies of - in different versions of things. Good. So, I guess I'd have one request here which is just, um, maybe to make it more robust, th- that the tag, whatever you would choose for this type of "NUMS" where it's inside the spontaneous speech, is different than the tag that you use for the read speech. Right. Right. That would argue for changing the other ones to be " digits " or something. Um, that way w- if we make a mistake parsing, or something, we don't see the "point five", or - or it's not there, then we Mm-hmm. a- Just - an- And actually for things like "seven eighths", or people do fractions too I guess, you - maybe you want one overall tag for sort of that would be similar to that, or - Except - As long as they're sep- as they're different strings that we - that'll make our p- sort of Well - processing more robust. Cuz we really will get rid of everything that has the "NUMS" string in it. I suppose what you could do is just make sure that you get rid of everything that has "curly brace NUMS curly brace". Well - Ex- exactly. Exactly. I mean that would be the - That was - that was my motivation. Yeah. And i- these can be changed, like I said. You know, I mean, as I said I was considering changing it to " digits ". And, it just - i- you know, it's just a matter of deciding on whatever it is, and being sure the scripts know. Right. It would probably be safer, if you're willing, to have a separate tag just because um, then we know for sure. And we can also do counts on them without having to do the processing. But you're right, we could do it this way, it - it should work. Um, Yeah, and it makes it - I guess the thing about - but it- it's probably not hard for a person to tell the difference because one's in the context of a - Yeah. you know, a transcribed word string, and - Right. The other thing is you can get really so minute with these things and increase the size of the files and the re- and decrease the readability to such an extent by So - simply something like " percent ". Now I - I could have adopted a similar convention for " percent ", but somehow percent is not so hard, you know? i- It's just Hmm. when you have these points and you're trying to figure out where the decimal places are - And we could always add it later. Percent's easy to detect. Point however is - is uh a word that has a couple different meanings. And you'll find both of those in one of these meetings, where he's saying "well the first point I wanna make is so-and-so" and he goes through four points, and also has all these decimals. So Liz, what does the recognizer do, So. uh, Hmm. what does the S_R_I recognizer output for things like that? "seven point five". Does it output the word - "Seven point five". Right, the word "seven"? The number "seven"? Well, the numbers? The word. The word "seven", O_K. Yeah. Yeah. So I'd - so "I'd like - I'd like to talk about point five". And - and actually, you know the language - it's the same point, actually, the - the p- you know, the word "to" and the word Yeah. y- th- "going to" and "to go to" those are two different " to's " and so there's no distinction there. Mm-hmm. It's just - just the word " point " has - Yeah, every word has only one, yeah e- one version even if - even if it's - A- actually even like the word "read" and "read" . Those are two different words. They're spelled the same way, right? And they're still gonna be transcribed as R_E_A_D. Mm-hmm. Right. Mm-hmm. So, yeah, I - I like the idea of having this in there, I just - I was a little bit worried that, um, the tag for removing the read speech - because i- What if we have like "read letters" or, I don't know, like "read something" like "read" yeah, basically. We might wanna - just a separate tag that says it's read. Mm-hmm. But other than that I- it sounds great. Yeah. O_K? Are we done? Well I wanted to say also regarding the channelized data, that, um, Thilo requested, um, that Oh, I guess we're not done. Yeah. we ge- get some segments done by hand to e- e- s- reduce the size of the time bins wh- like was Chuc- Chuck was mentioning earlier that, um, that, um, if you - if you said, "Oh" and it was in part of a really long, s- complex, overlapping segment, that the same start and end times would be held for that one as for the longer utterances, and - Well - We did that for one meeting, right, so you have that data don't you? Yeah, that's the training data. And he requested that there be, uh, similar, uh, samples done for five minute stretches c- involving a variety of speakers and overlapping secti- sections. He gave me - he did the - very nice, he - he did some shopping through the data and found segments that would be useful. Yeah. And at this point, all four of the ones that he specified have been done. In addition the I've - I have the transcribers expanding the amount that they're doing actually. So right now, um, Oh great. I know that as of today we got an extra fifteen minutes of that type, and I'm having them expand the realm on either side of these places where they've already started. Oh great. O_K. But if - if - you know, and I - and he's gonna give me some more sections that - that he thinks would be useful for this purpose. Yeah. Yeah. Because it's true, I mean, if we could do the - the more fine grained tuning of this, uh, using an algorithm, that would be so much more efficient. And, um. So this is gonna be useful to expand this. So I - I thought we - we sh- we sh- perhaps we should try to - to start with those channelized versions just to - just to try it. Give it - Give one tr- transcriber the - the channelized version of - of my speech-nonspeech detection and look if - if that's helpful for them, or just let them try if - if that's better or If they - if they can - You mean to start from scratch f- in a brand new transcript? That'd be excellent. Yeah, that'd be really great. Yeah. Yeah. Yeah. As it stands we're still in the phase of sort of, um, cleaning up the existing data getting things, uh, in i- m- more tight- tightly time - uh, aligned. I also wanna tell - um, I also wanted to r- raise the issue that - O_K so, there's this idea we're gonna have this master copy of the transcript, it's gonna be modified by scripts t- into these two different functions. And actually the master - Two or more. Two or more different functions. Two - two or more. And that the master is gonna be the channelized version. Right. So right now we've taken this i- initial one, it was a single channel basically the way it was input. And now, uh, thanks to the advances made in the interface, we can from now on use the channelized part, and, um, any changes that are made get made in the channelized version kind of thing. But I wanted to get all the finished - all the checks - Yeah, so that has implications for your script. Yeah. So, uh, have those - e- e- the vis- the ten hours that have been transcribed already, have those been channelized? Yes, they have. And I know - I've seen @@ - I've seen they've been channelized, but All ten hours? Except for the missing thirty minutes. Great. have they uh - have they been - has the time - have the time markings been adjusted, uh, p- on a per channel - Uh, for - for a total of like twenty m- f- for a total of - Let's see, four times - total of about an - thirty minutes. That's - that's been the case. And plus the training, whatever you have. So, I guess, I mean, I don't know if we should talk about this now, or not, but I- Well it's just we're missing tea. So. Yeah, I know. No, but I mean my question is like should I wait until all of those are processed, and channelized, like the time markings are adjusted before I do all the processing, and we start like branching off into the - into the - our layer of uh Well, you know the problem - the problem is that some - some of the adjustments that they're making are to bring - are to combine transcripts. bins that were - time bins which were previously separate. And the reason they do that is sometimes there's a word that's cut off. Right. And so, i- i- i- it's true that it's likely to be adjusted in the way that the words are more complete. And, O_K. No I know - I know that adjusting those things are gonna - is gonna make it better. so I - it's gonna be a more reliable thing and I'm not sure - Yeah. I mean I'm sure about that, but do you have like a time frame when you can expect like all of it to be done, or when you expect them to finish it, or - Well partly it depends on how - um, how e- effective it will be to apply an algorithm because Yeah. i- this takes time, you know, it takes a couple hours t- to do, uh, ten minutes. Yeah. Yeah, I don't doubt it. Um, so. So right now the - what you're doing is you're taking the - uh, the o- original version and you're sort of channelizing yourself, right? Yeah. I'm doing it myself. I mean i- if the time markings aren't different across channels, like the channelized version really doesn't have any more information. Mm-hmm. So, I was just - I mean, originally I had done before like the channelized versions were coming out. Um, Right. Right. and so it's a question of like what - So I - I th- I think probably the way it'll go is that, you know, when we make this first general version and then start working on the script, that script Mm-hmm. @@ that will be ma- you know primarily come from what you've done, um, we'll need to work on a channelized version of those originals. Mm-hmm. Mm-hmm. And so it should be pretty much identical to what you have t- except for the one that they've already tightened the boundaries on. Yep. Mm-hmm. Right. Um, So Yeah, I mean - yeah. uh, and then probably what will happen is as the transcribers finish tightening more and more, you know, that original version will get updated and then we'll rerun the script and produce better O_K. uh versions. But the - I guess the ef- the effect for you guys, because you're pulling out the little wave forms into separate ones, that would mean these boundaries are constantly changing you'd have to constantly re- rerun that, so, maybe - I know . Right. But that - Mm-hmm. But that - that's not hard. No. I- I think the harder part is making sure that the transc- the transcription - O_K. So if you b- merge two things, then you know that it's the sum of the transcripts, but if you split inside something, you don't where the word - which words moved. Mm-hmm. Mm-hmm. And that's wh- that's where it becomes a little bit - uh, having to rerun the processing. The cutting of the waveforms is pretty trivial. Mm-hmm. Yeah. I mean as long as it can all be done automatically, I mean, then that's not a concern. You know, if I just have to run three scripts to extract it all and let it run on my computer Right. Mm-hmm. Yeah. Uh-huh. for an hour and a half, or however long it takes to parse and create all the reference file, that's not a problem. Mm-hmm. Um, so yeah. As long as we're at that point. And I know exactly like what the steps will work - what's going on, in the editing process, so. Yeah. O_K. So that's - I- I mean I could - there were other checks that I did, but it's - I think that we've - unless you think there's anything else, I think that I've covered it. Yeah. I can't think of any of the - other ones. O_K. Great. O_K. Oop! Man! 