Hmm. Testing channel two. Two, two. Two. Two. Oh. Hello? Hmm? Yeah Thank You. O_K O_K. Well, so Ralf and Tilman are here. Great. Great. Made it safely. So the - what w- we h- have been doing i- they would like us all to read these digits. But we don't all read them but a couple people read them. O_K. Uh, wanna give them all with German accents today or - ? Sure. O_K. O_K and the way you do it is you just read the numbers not as uh each single, so just like I do it. Mm-hmm. O_K. First you read the transcript number. My transcript number is L_ ninety-five. three two three, O_ nine, seven seven three five two two one, four O_ eight, two one one five one six zero zero, eight, seven O_ nine six four four O_, four, five six two eight five O_, five nine three, five two six one three five eight, one O_ five, six two four four six eight four, eight five five one, four two two nine O_ five seven, five six, O_ seven three two. O_K, uh - What's - Turn. Uh, my transcript number is, um, L_ n- ninety-one one four one six, two, eight six one three w- one five seven, O_ three nine five, eight, w- uh, O_, six six two two, four two, O_ three, one six, one four three four one, six one seven, one three four O_ six five two, one O_ five, nine eight two one four O_, u- eight four, nine two, u- one two, s- six five eight six, six six, one three, one one, one O_ two O_, six six, six five, four one, five nine. O_K, my transcript number is L_ ninety-two. eight five O_, three four two, one three seven six. O_ six three two, four nine seven O_, six O_, six eight. six three six, five six four, nine three O_ six. six four one, eight seven, six O_ O_ six. eight O_ seven three, one seven seven zero, seven five five six. four four, five six, six O_, four five, one O_. eight four five, eight four one, one O_ three seven. one O_ seven two, six seven seven four, one seven O_ O_. O_K. Let's be done with this. O_K. O_K. this is Ami, who - And this is Tilman and Ralf. Hi. Uh-huh . Hi. Hi. Nice to meet you. O_K. So we're gonna try to finish by five so people who want to can go hear Nancy Chang's talk, uh downstairs. Hmm. And you guys are g- giving talks on tomorrow and Wednesday lunch times, right? That's great. Yes. Mmm. O_K so, do y- do you know what we're gonna do? I thought two things uh we'll introduce ourselves and what we do. And um we already talked with Andreas, Thilo and David and some lines of code were already written today and almost tested and just gonna say we have um again the recognizer to parser thing where we're working on and that should be no problem and then that can be sort of developed uh as needed when we get - enter the tourism domain. em we have talked this morning with the - with Tilman about the generator. S- and um There one of our diligent workers has to sort of volunteer to look over Tilman's shoulder while he is changing the grammars to English Mm-hmm. because w- we have - we face two ways. Either we do a syllable concatenating um grammar for the English generation which is sort of starting from scratch and doing it the easy way, or we simply adopt the ah um more in-depth um style that is implemented in the German system and um are then able not only to produce strings but also the syntactic parse uh not parse not the syntactic tree that is underneath in the syntactic structure which is the way we decided we were gonna go because A_, it's easier in the beginning Mm-hmm. and um it does require some - some knowledge of - of those grammars and - and - and some ling- linguistic background. But um it shouldn't be a problem for anyone. O_K So That sounds good. Johno, are you gonna have some time t- to do that uh w- with these guys? Sure. cuz y- you're the grammar maven. O_K. I mean it makes sense, doesn't it? Yeah. Yeah Good. O_K. So, I think that's probably the - the right way to do that. And an- Yeah, so I - I actually wanna f- to find out about it too, but I may not have time to get in. the - the ultimate goal is that before they leave we - we can run through the entire system input through output on at least one or two sample things. And um and by virtue of doing that then in this case Johno will have acquired the knowledge of how to extend it. Ad infinitum. When needed, if needed, when wanted and so forth. O_K that sounds great. And um also um Ralf has hooked up with David and you're gonna continue either all through tonight or tomorrow on whatever Mmm. to get the er parser interface working. They are thinning out and thickening out lattices and doing this kind of stuff to see what works best. Mmm, yep. Great. So, you guys enjoy your weekend? Yes, very much so. Yeah, very much O_K, before - before you got put to work? Yeah Great. O_K, so that's - Sort of one branch is to get us caught up on what's going on. Also of course it would be really nice to know what the plans are, in addition to what's sort of already in code. Yes. and we can d- I dunno w- w- was there uh a time when we were set up to do that? It probably will work better if we do it later in the week, after we actually understand Yes. Hmm. Yeah. uh better what's going on. So when do you guys leave? Um we're here through Sunday, so Oh Oh, O_K, so - All through Friday would be fine. O_K, So - so anyt- we'll find a time later in the week to uh get together and talk about your understanding of what SmartKom plans are. Mm-hmm. and how we can change them. Yes. Sure. Uh, Should we already set a date for that? Might be beneficial while we're all here. O_K? um What - what does not work for me is Thursday afternoon. I can do earlier in the day on Thursday, or um most of the time on Friday, not all. Wha- but, Johno, Thursday morning sounds fine? Mm-hmm. what are your constraints? um Thursday afternoon doesn't work for me, but - Neither does Thursday morning, no? Uh Thursday morning should be fine. Eleven? O_K. Eleven on Thursday? @@ I was just thinking I w- I will have leavened by Right. eleven. Right. This is then out of deference to our non-morning people. Mm-hmm. O_K. So at eleven? Hmm. Thursday around eleven? Yeah. O_K. And actually we can invite um Andreas as well. Uh he will be in Washington, though. Oh that's true. He's off - off on his trip already. but um David is here and Thilo. he's actually knows everything about the SmartKom recognizer. O_K well yeah maybe we'll see if David could make it. That would be good. O_K so facing to - to what we've sort of been doing here um well for one thing we're also using this room to collect data. Yeah obviously. um um Not this type of data, no not meeting data but sort of - sort ah our version of a wizard experiment such Oh, O_K. not like the ones in Munich but pretty close to it. Mm-hmm. The major difference to the Munich ones is that we do it via the telephone O_K. even though all the recording is done here and so it's a - sort of a computer call system Mm-hmm. that gives you tourist information tells you how to get places. And it breaks halfway through the experiment and a human operator comes on. and part of that is sort of trying to find out whether people change their linguistic verbal behavior when first thinking they speak to a machine and then to a human. Yeah. and we're setting it up so that we can - we hope to implant certain intentions in people. For example um we have first looked at a simple sentence that "How do I get to the Powder-Tower?" O_K so you have the - castle of Heidelberg O_K. and there is a tower and it's called Powder-Tower. Oh, O_K. Yeah. and um so What will you parse out of that sentence? Probably something that we specified in M_-three-L_, that is Mmm. @@ "action go to whatever domain, object whatever Powder-Tower". And maybe some model will tell us, some G_P_S module, in the mobile scenario where the person is at the moment. And um we've sort of gone through that once before in the Deep Mail project and we noticed that first of all what are - I should've brought some slides, but what our - So here's the tower. Think of this as a two-dimensional representation of the tower. And our system led people here, to a point where they were facing a wall in front of the tower. There is no entrance there, but it just happens to be the closest point of the road network to the geometric center Because that's how the algorithm works. So we took out that part of the road network as a hack and then it found actually the way to the entrance. which was now the closest point of the road network to Yeah. O_K, geometric center. But what we actually observed in Heidelberg is that most people when they want to go there they actually don't want to enter, because it's not really interesting. They wanna go to a completely different point where they can look at it and take a picture. Oh, O_K. Yeah. Hmm. And so what uh uh a s- you s- let's say a simple parse from a s- from an utterance won't really give us is what the person actually wants. Does he wanna go there to see it? Does he wanna go there now? Later? How does the person wanna go there? Is that person more likely to want to walk there? Walk a scenic route? and so forth. There are all kinds of decisions that we have identified in terms of getting to places and in terms of finding information about things. And we are constructing - and then we've identified more or less the extra-linguistic parameters that may f- play a role. Information related to the user and information related to the situation. And we also want to look closely on the linguistic information that what we can get from the utterance. That's part of why we implant these intentions in the data collection to see whether people actually phrase things differently whether they want to enter in order to buy something or whether they just wanna go there to look at it. And um so the idea is to construct uh um suitable interfaces and a belief-net for a module that actually tries to guess what the underlying intention was. And then enrich or augment the M_-three-L_ structures with what it thought what more it sort of got out of that utterance. So if it can make a good suggestion, "Hey!" you know, "that person doesn't wanna enter. That person just wants to take a picture," cuz he just bought film, or "that person wants to enter because he discussed the admission fee before". Or "that person wants to enter because he wants to buy something and that you usually do inside of buildings" and so forth. These ah these types of uh these bits of additional information are going to be embedded into the M_-three-L_ structure in an - sort of subfield that we have reserved. And if the action planner does something with it, great. If not you know, then that's also something um that we can't really - at least we want to offer the extra information. We don't really - Mm-hmm. Hmm. um we're not too worried. I mean - t- s- Ultimately if you have - if you can offer that information, somebody's gonna s- do something with it sooner or later. That's sort of part of our belief. What was he saying? Um, for example, right now I know the G_I_S from email is not able to calculate these viewpoints. So that's a functionality that doesn't exist yet Mm-hmm. to do that dynamically, but if we can offer it that distinction, maybe somebody will go ahead and implement it. Surely nobody's gonna go ahead and implement it if it's never gonna be used, so. What have I forgotten about? Oh yeah, how we do it, yeah that's the Well th- uh- No no. It's a good time to pause. I s- I see questions on peoples' faces, so why don't - let's - let's - Oh- Let's hear - Well the obvious one would be if - if you envision this as a module within SmartKom, where exactly would that Sit? um - so far I've thought of it as sort of adding it onto the modeler knowledge module. So this is one that already adds That's the d- Hmm. O_K, yeah. Makes perfect sense. Yes. Hmm, ah. additional information to the but it could sit anywhere in the attention-recognition I mean basically this is what attention-recognition literally sort of can - Well it's supposed to do. Mmm. Yeah That's what it should do. Right, yeah. Yeah. Yeah. Huh. Yeah. Well f- from my understanding of what the people at Phillips were originally trying to do doesn't seem to quite fit into SmartKom currently so what they're really doing right now is only selecting among the alternatives, the hypotheses that they're given enriched by the domain knowledge and Yeah. the um discourse modeler and so on. Yeah. So if - if this is additional information that could be merged in by them. And then it would be available to action planning and - and others. Yeah. the - let's - let's That w- O_K that was one question. Is there other - other things that cuz we wanna not Pa- pass over any you know, questions or concerns that you have. Well there're - there're Mmm. two levels of - of giving an answer and I guess on both levels I don't have any um Mmm. further questions. uh the - the two levels will be Mmm. as far as I'm concerned as uh standing here for the generation module and the other is - is my understanding of what SmartKom uh is supposed to be Right. and I - I think that fits in perfectly So - well, let me - Hmm. Let me s- expand on that a little bit from the point of view of the generation. Yeah. So the idea is that we've actually got this all laid out an- and we could show it to you ig- um Robert didn't bring it today but there's a - a belief-net which is - There's a first cut at a belief-net that - that doesn't - it - isn't fully uh instantiated, and in particular some of the - the combination rules and ways of getting the - the conditional probabilities aren't there. But we believe that we have laid out the fundamental decisions in this little space and the things that influence them. Mm-hmm. So one of the decisions is what we call this A_V_E thing. Do you want to um access, view or enter a thing. Hmm. So that's a- a discrete decision. There are only three possibilities and the uh - what one would like is for this uh, knowledge modeling module to Mm-hmm. add which of those it is and give it to the planner. Mm-hmm. But, uh th- the current design suggests that if it seems to be an important decision and if the belief-net is equivocal so that it doesn't say that one of these is much more probable than the other, then an option is to go back and ask Mm-hmm. for the information you want. Alright? Now there are two ways one can go - a- imagine doing that. For the debugging we'll probably just have a - a drop-down menu and the - while you're debugging you will just - O_K. But for a full system, then one might very well formulate a query, give it to the dialogue planner and say this, you know Mm-hmm. ar- are you know you - are you planning to enter? Or whatever it - whatever that might be. So that's - under that model then, There would be a - uh - um a loop in which this thing would formulate a query, presumably give it to you. Yes. That would get expressed and then hopefully you know, you'd get an answer back. Yep. And that would of course - the answer would have to be parsed. Mmm. right and - Yep. O_K so, th- that Yes. uh, We probably won't do this early on, because the current focus is more on the decision making and stuff like that. Yep. But While we're on the subject I just wanted to give you a sort of head's up Mm-hmm. that it could be that some months from now we said "O_K we're now ready to try to close that loop " Mm-hmm. Hmm. in terms of querying about some of these decisions. Yep. So - my suggestion then is that you um look into the currently ongoing discussion about how the action plans are supposed to look like. And they're currently um Agreeing or - or in the process of agreeing on an X_M_L_ification of um something like a state-transition network of how dialogues would proceed. and - The - these um transition networks uh will be what the action planner interprets in a sense. Hmm. D- did you know this Robert? uh Michael is doing that, right? Well uh Marcus Lerkult is actually implementing that stuff and Marcus and Michael together are um leading the discussion there, yeah. O_K. So we ha- we have to get in on that. Mm-hmm. Yep. because um Mmm. Definitely. partly those are like X_schemas. the transition diagrams. Hmm. And it may be that - that um we should early on make sure that they have the flexibility that we need. Hmm. But they uh Have I understood this right? They - they govern more or less the - the dialogue behavior or the action - Mm-hmm. It's not really what you do with the content of the dialogue but it's So, I mean there is this - this - this nice interf- i- uh, No, it's - it's also a quantrant uh uh - Is it - So there's ac- so there - th- the word "action", O_K, is - is what's ambiguous here. I think. Hmm. Yes. So, um one thing is there's an actual planner that tells the person in the tourist domain now, per- tells the person how to go, "First go here, first go there O_K. Mm-hmm. uh, you know, take a bus ", whatever it is. So that's that form of planning, and action, and a route planner and G_I_S, all sort of stuff. uh But I think that isn't what you mean. No. No, in SmartKom terminology that's um called a function that's modeled by a function modeler. And it's th- that's completely um encapsulated from th- the dialogue system. That's simply a functionality that you give data as in a query and then you get back from that mmm, a functioning model um which might be a planner or a V_C_R or whatever. um some result and that's then - then used. Well, O_K, so that's what I thought. So action he- action here means dia- uh speech ac- uh you know Yeah, yeah. Mmm. Yeah, in that - in that sense yes, dialogue act, yeah. dialogue act. Yeah. Um, I think tha- I think it's not going to - I think that's not going to be good enough. I- I don- what uh - what I meant by that. So I think the idea of having a, you know, transition diagram for the grammar of conversations is a good idea. Mm-hmm. O_K? And I think that we do hav- definitely have to get in on it and find out - O_K . But I think that um when - so, when you get to the tourist domain Mm-hmm. it's not just an information retrieval system. Right? So this i- this is where Clearly. Yes. I think this - people are gonna have to think this through a bit more carefully. Mm-hmm. So, if it's only like in - in the - in the film and T_ V thing, O_K, you can do this. And you just get information and give it to people. But what happens when you actually get them moving and so forth and so on Yep. Uh, y- y- your - I d- I think the notion of this as a self contained uh module you know th- the functional module that - that interacts with - with where the tourism g- stuff is going Yep. probably is too restrictive. Now I dunno how much people have thought ahead to the tourist domain in this Probably not enough, I mean an - another uh more basic point there is that the current um tasks and therefore th- the concepts in this ac- what's called the action plan and what's really the dialogue manager. Yeah um is based on slots that have to be filled and the um Mm-hmm. kind of values in these slots would be fixed things like the a time or a movie title or something like Right. this whereas in the a um tourist domain it might be an entire route. Set-based, or even Indeed. very complex structured information in these slots and Right. I'm not sure if - if complex slots of that type are really um being taken into consideration. O_K. Could you - could you put a message into the right place to see if we can at least ask that question? So that's - that's really something we Yep. Mm-hmm. rea- I mean nothing's being yep completely settled there so this is really an ongoing discussion and that's Mm-hmm yeah and um it might actually O_K ah also - because um again in- in Deep Map we have faced and implemented those problems once already maybe we can even shuffle some know how from there to Mm-hmm. Yes. to Markus and Michael. Mmm. Yep. And um mmm You don't know - O_K th- I'll - I'll talk to Michael it's what I do anyway. Who - How far is the uh the - the M_-three-L_ specification for - for the la- natural language input gone on the - the uh I haven't seen anything for the uh tourist path domain. Yeah, it's - it's not defined yet . And um you are probably also involved in that, right? Um - Yeah. uh together with the usual gang, um Petra and Jan Mmm. Yeah, there's a meeting next next week I think O_K because That's - Those are the - I think the - the true key issues is how does the whatever comes out of the language input pipeline look like and then what the action planner does with it - and how that is uh specified. I didn't think of the internal working of the uh the action planner and the language - uh the function model as sort of relevant. Because what - what they take is sort of this - this fixed representation of a - of an intention. And that can be as detailed or as crude as you want it to be. Mm-hmm. But um the internal workings of of the - whether you know there're dialogue - action planners that work with belief-nets that are action planners that work with you know state automata . So that shouldn't really matter too much. I mean it does matter because it does have to keep track of you - we are on part six of r- a route that consists of eight steps and so forth Yeah, th- there - there - I think there are a lot of reasons why it matters. Right. O_K, so that uh, for example, the i- it's the action planner is going to take some spec and s- make some suggestions about what the user should do. What the user says after that is going to be very much caught up with what Yes. the action planner told it. If the - If the parser and the language end doesn't know what the person's been told O_K th- it's you're making your life much more difficult than it has to be. Yeah. Right? So if someone says the best t- to uh go there is by taxi, let's say. Now the planner comes out and says you wanna get there fast, take a taxi. O_K. And the language end doesn't know that. O_K, there's all sorts of dialogues that won't make any sense which would be hmm just fine. Yeah. uh That would b- but that - I think that - that uh point has been realized and it's - it's not really um been defined yet but there's gonna be some kind of feedback and input from uh the action planner into all the analysis modules, telling them what to expect and what the current state of the discourse is. Mmm. Beyond what's currently being implemented which is just word lists. @@ Yeah, but this is not the st- this is not just the state of the discourse. Mm-hmm. Of - of special interest. This is actually the state of the plan. That's why Mm-hmm. Yes, Yes, Mm-hmm yeah. O_K so it - z- and s- uh, It's great if people are already taking that into account. But One would have t- have to see - see the details. The specifics aren't really there yet. Yes. Yeah. So, there's work to do there. So anyway, Robert, that's why I was thinking that Mm-hmm. um I think you're gonna need - We talked about this several times that - that - the - the input end is gonna need a fair amount of feedback hmm from the planning end. In - in one of these things which are - are much more continuous than the - just the dialogue over movies and stuff. Yeah. Mmm. And even on - on a more basic level the - the action planner actually needs to be able to have um an expressive power that can deal with these structures. Hmm? And not just um say um - um the dialogue um will consist of ten possible states and th- these states really are fixed in - in a certain sense. Would there be any chance You have to - of getting the terminology changed so that the dialogue planner was called a "dialogue planner"? Because there's this other thing- That'd be nice. The o- There's this other thing in - in the tourist domain which is gonna be a route planner or - It's really gonna be an action planner. And It oughta be called a - a dialogue manager. i- it - cuz that's what everybody else calls it. Yeah. I would think, yeah. Mmm. Huh? So, s- So what would happen if we sent a note saying "Gee we've talked about this and couldn't we change this uh th- the whole word?" I have no idea how complicated these things are. Probably close to impossible. Depends on who you talk to how. We'll see. I'll go check, cause I completely agree. Mmm. Yeah, and I think this is just for historical reasons within uh, the preparation phase of the project and not because somebody actually believes it ought to be action planner. So if there is resistance against changing it, that's just because "Oh, We don't want to change things." That - that not deep reason O_K, anyway. I- if - if that c- in- persists then we're gonna need another term. for the thing that actually does the planning of the uh routes and whatever we are doing for the tourist. That's external services. Yeah, but that's not g- eh tha- That ha- has all the wrong connotations. it's - it sounds like it's you know stand alone. It doesn't interact, it doesn't That's why I'm saying. I think you can't - it's fine for looking up when T- you know when the show's on T_V. You go to th- but I - I - I - I think it's really - really wrong headed for something that you - that has a lot of state, it's gonna interact co- in a complicated way with the uh understanding parts. Yeah. Yeah I think just the - the spatial planner and the route planner I showed you once the interac- action between them among them in the deep map system so - Right. a printout of the communication between those two fills up I don't know how many pages and that's just part of how do I get to one place. It's really insane. and uh Hmm but um so this is um definitely a good point to get uh Michael into the discussion. Or to enter his discussion, actually. That's the way around. Yeah, Marcus. Markus Is he new in the - in the? Wh- where's? Yeah, he's - he started um Yeah. I think January. And he's gonna be responsible for the implementation of this action planner. Dialogue manager. Is he gonna continue with the old - uh - thing? No, no he's completely gonna rewrite everything. O_K. In Java. O_K so that's interesting. Yes I was just - that's my next question whether we're - we're gonna stick to Prolog or not. hmm No. No, that's gonna be phased out. Yeah . O_K But I do think the - the function modeling concept has a certain - makes sense in a - in a certain light because Yeah. the action planner should not be - or the dialogue manager in that case should not um w- have to worry about whether it's interfacing with um something that does route planning in this way or that way huh, it j- Mm-hmm. I- I totally agree. Sure. Yeah I - I agree. There is - there's a logic to dialogue which - which is - is separable. I- Yeah. and it - cant - sort of formulate its- what it wants in a - in a rather a- abstract uh way, you know f- Mm-hmm. "Find me a good route for this." It doesn't really have to worry ab- how route planner A_ or how route planner B_ actually wants it. So this is - seemed like a good idea. In the beginning. It's tricky. It's tricky because one could well imagine - I think it will turn out to be the case that uh, this thing we're talking about, th- the extended n- uh knowledge modeler will fill in some parameters about what the person wants. One could well imagine that the next thing that's trying to fill out the detailed uh, route planning, let's say, will also have questions that it would like to ask the user. You could well imagine you get to a point where it's got a - a choice to make and it just doesn't know something. And so y- you would like it t- also be able to Mm-hmm. uh formulate a query. And to run that back through uh. the dialogue manager and to the output module and back around. hmm And a- I- a- a good design would - would a lot of, yeah allow that to happen. Mmm. If - if you know if - if you can't make it happen then you - you do your best. Yeah but that doesn't necessarily contradict um an architecture where there really is a pers- a def- well-defined interface. I totally agree. But - but what it nee- but th- what the point is the- in that case the dialogue manager is sort of event driven. and - and So the dialogue manager may think it's in a dialogue state of one sort, and this - Mm-hmm. one of these planning modules comes along and says "hey, right now we need to ask a question". So that forces the dialogue manager to change state. Yes O_K. It could be y- Sure, ye- yeah I - I think that's - that's the um Yeah, yeah it - it - concept that people have, yep. O_K. And - and the - the underlying idea of course is that there is something like kernel modules with kernel functionality that you can plug uh certain applications like tourist information or um the home scenario with uh controlling a V_C_R and so on. And then extend it to an arbitrary number of applications eventually. So - wouldn't That's an additional reason to have this well-defined interface and keep these things like uh tourist information external. Oh, yeah, yeah. And then call it external services. Hmm. But of course the - the more complex - yep. Yeah, there is another philosophical issue that I think you know you can - evade but, at- at least it makes sense to me that sooner or later uh - a service is gonna come and describe itself to you. and that's sort of what Srini is working on in - in - in the DAML Yeah. uh project where um you - you find a G_I_S about - that gives you information on Berkeley, and it's - it's gonna be there and tell you what it can do and how it wants to do things. and so you can actually interface to such a system without ever having met it before and Hmm. the function modeler and a self-description of the um external service haggle it out and you can use the same language core, understanding core to interface with planner-A_, planner-B_, planner-C_ and so forth. Hmm. Mmm. Which is, you know, uh - uh - utopian - completely utopian at the moment, but slowly, you know, getting into the realm of the uh contingent. Hmm. But we are facing of course much more um realistic problems. And language input for example, is of course uh crucial you know also when you do the sort of deep understanding analysis that we envision. um Then of course, the uh um, you know what is it - poverty of the stimulus, yet the m- uh the less we get of that the better. and um so we - we're thinking, for example how much syntactic analysis actually happens already in the parser. Hmm. and whether one could interface to that potentially Yeah, are there currently is uh no syntactic analysis but in the next release there will be some. Hmm. How's it - unless and it's um uh you can access this S- so uh y- we - we looked at the e- current pattern matching thing. Hmm. And as you say it's just a surface pattern matcher. Uh, So what are - what are the plans roughly? um it's to - to integrate and syntactic analysis. and um add some more features like segmentation. So then an utter- more than one utterance is - There um there's often uh pause between it and a segmentation occurs. So, the um - um So the idea is to uh - have a pa- y- y- a particular - Do you have a particular parser in mind? Is it yeah uh - partic- d- I mean have you thought through - ? Is it an H_P_S_G parser? Is it a whatever? No - no it's - uh I think it's it's totally complicated for O_K. it's just one - one person and so I have to keep the - Oh, you have to do it. You have to do it, yeah. Yeah, ah and so things must be simpler I see, so but uh, Miel syntactic analysis with um finite state transducers. But the people at D_F_- Yeah. People at D_F_K_I have written a fair number of parsers. Other - you know, people over the years. uh have written various parsers at D_F_K_I. None of them are suitable? I - I - I d- I'm asking. I don't know. Yeah, uh the problem is th- that it has to be very fast because um if you want to for more than one path anywhere O_K. what's in the latches from the Mm-hmm. speech recognizer so it's speed is crucial. uh And they are not fast enough. Mm-hmm. And they also have to be very robust. cuz of um speech recognition errors and O_K. So, um - So there was a chunk parser @@ in Verbmobil, that was one of the uh branchers. You know they - d- th- I c- There were these various uh, competing uh syntax modules. And I know one of them was a chunk parser and I don't remember who did that. I think it's A- Alan? that might, at Tuebingen I thought. Yeah I d- I don't remember. was - Do you know something about that? Tuebingen was at least involved in putting the chunks together I - In Tub- at - can't quite recall whether they actually produced the chunks in the first place. oh Uh. I see. Yeah, that's right. Or wh- There w- That's right. They w- They had - There were - This was done with a two phase thing, where Oh from - from Stuttgart, yeah, also the chunk parser itself was pretty stupid and then there was a kind of trying to fit them together that Right. h- used more context. Right? Yeah Well you s- and - and especially you did some - some um, l- um was a learning-based approach which learned from a big corpus of - of trees. Right. Right. Mm-hmm. And yes the - it - the chunk parser was a finite-state machine that um Mark Light originally w- worked on in - while he was in Tuebingen and then somebody else in Tuebingen picked that up. So it was done in Tuebingen, yeah. Definitely. But is that the kind of thing y- It sounds like the kind of thing that you were thinking of. yeah. yeah that's Yeah I guess it's similar. In this direction, yes What? Yeah, it's in - in this direction. Hmm . The - From Michael Strube, I've heard very good stuff about the chunk parser that is done by FORWISS, uh, which is in embassy doing the parsing. Mm-hmm. So this is sort of - came as a surprise to me that you know, embassy s- is featuring a nice parser but it's what I hear. One could also look at that and see Mm-hmm, yeah, it would be very interesting, Mm-hmm. whether there is some synergy Mmm, yeah. possible. And they're doing chunk parsing and it's uh - I - I can give you the names of the people who do it there. But um. Then there is of course more ways of parsing things. Of course. But - But uh given th- the constraints, that you want it to be small and fast and so forth, my guess is you're probably into some kind of chunk parsing. And uh I'm not a big believer in this um statistical you know, cleaning up uh It - That seems to me kind of a last resort if uh you can't do it any other way. uh but I dunno. It may - i- i- may be that's what you guys finally decide do. Hmm. Uh. And have you looked - uh just - again for context - Mm-hmm. There is this - this one that they did at S_R_I some years ago - Fastus ? a - um yeah, I've - I've looked at it but - but it's no - not much uh information available. ah! I found, but it's also finite-state transducers, I thought. It is. Yeah. I mean - it's - it was pretty ambitious. and And of course it was English oriented, um Yeah, and - and w- Purely finite-state transducers are not so good for German since there's um Right. Yeah, I guess that's the point is - is all the morphology and stuff. The word order is - is uh not fixed And English is all th- all word order. And it makes a lot more sense. And - Yeah. e- Yeah, O_K. Good point. So in - in - in German you've got uh most of this done with Mm-hmm. Also it's uh - it's um - Yes, uh the um choice between uh this processing and that processing and my template matcher. Right. Right. So what about @@ Um Did y- like Morfix? a- a- e- y- you've got stemmers? Or is that something that - Um, yeah but it's all in the - in the lexicon. But did you have that? So it's - Yeah th- the information is available. O_K. I see. So, but - So y- you just So - connect to the lexicon Yeah and uh at least for German you have all - all of the - uh the stemming information. Yeah, we can, oh yeah. We have knowledge bases from - from Verbmobil Yep. system we can use and so. Right. But it - it - it doesn't look like i- you're using it. I didn't n- see it being used in the current template uh parser. I - I didn't see any Uh - of course we l- actually only looked at the English. It - Did we look at the German? um I don't remember. So w- wha- Yeah, but - but it's used for - for stem forms. i- n- Well I think - I think there's some misunderstanding here it's - @@ Oh, O_K. Morphix is not used on-line. s- so the lexicon might be derived What? by Morphix but Right. What - what's happening on-line is just um um a - a retrieval from the lexicon which would Right. give all the stemming information so it would be a full foreign lexicon. Hmm. And that's what you have. Yeah Yep. O_K. What - uh I didn't reme- We threw out all the forms. Huh? We threw out all the forms because, you know, English, well - Oh O_K, so it - yeah, s- s- I thought I'd - Mm-hmm. So in German then you actually do case matching and things like in the - in the pattern matcher or not? um Not yet but it's planned to do that. O_K. Cuz I r- I didn't reme- I didn't think I saw it. Have we looked at the German? Yeah Oh, I haven- yeah that's - getting it from the lexicon is just fine. Yeah, yeah, yeah. No problem with that. Sure, right. Oh yes . um Yeah and here's the case where the English and the German might really be significantly different. In terms of if you're trying to build some fast parser and so forth and - You really might wanna do it in a significantly different way. I don't know. So you've - you guys have looked at this? also? in terms of You know, w- if you're doing this for English as well as German Um Do you think now that it would be this - doing it similarly? um Yeah, it's um I think it's um yes, it's - it's um possible to - to do list processing. and Maybe this is um more adequate for English and in German um Set. set processing is used. Maybe yeah. Some extensions uh have to be made. For - for a English version Mmm. O_K. Interesting. Not easy. Well there's m- I'm sure there's gonna be more discussion on that after your talk. Mm-hmm, yeah. Right. We're just gonna foreshadow what we saw that Right. and um Now actually, um Are you guys free at five? Or - Do you have to go somewhere at five o'clock tonight? W- in ten minutes? Ah - mmm. No. uh - uh - I think we're expect - Oder there was an - talk? uh Yeah, there - there's the um practice talk. Great. So you're going to that. @@ Yeah, that - that's what we were planning to do. Yeah. That's good, because that will Mmm, yeah. uh tell you a fair amount about The form of semantic construction grammar that we're using. so - Mm-hmm. Ah. So I th- I think that probably as good an introduction as you'll get. Uh to the form of - of uh - conceptual grammar that - that w- we have in mind for this. Mmm, ah. It won't talk particularly about how that relates to what uh Robert was saying at the beginning. But let me give you a very short version of this. So we talked about the fact that There're going to be a certain number of decisions That you want the knowledge modeler to make, that will be then fed to the function module, that does uh, route planning. It's called the "route planner" or something. Mm-hmm. So there are these decisions. And then one half of this we talked about at little bit is how if you had the right information, if you knew something about what was said and about th- the something about was the agent a tourist or a native or a business person or uh young or old, whatever. That information, and also about the Uh, what we're calling "the entity", Is it a castle, is it a bank? Is it a s- town square, is it a statue? Whatever. So all that kind of information could be combined into decision networks and give you decisions. But the other half of the problem is How would you get that kind of information from the parsed input? So, um So what you might try to do is just build more templates, saying uh we're trying to build a templ- you know build a template that w- uh somehow would capture the fact that Mmm. he wants to take a picture. O_K? And - and we could - you could do this. And it's a small enough domain that probably you, you know - Mmm. O_K . You could do this. But uh from our point of view this is also a research project and there are a couple of people not here for various reasons who are doing doctoral dissertations on this, Mm-hmm. and the idea that we're really after is a very deep semantics based on cognitive linguistics and the notion that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity. So a typical one in this formulation is a container. So this is a static thing. And the notion is that all sorts of physical situations are characterized in terms of containers. Going in and out the portals and con- O_K. Mmm. But also, importantly for Lakoff and these guys is all sorts of metaphorical things are also characterized this way. You get in trouble and you know et cetera and so - s- Mmm. So, what we're really trying to do is to map from the discourse to the conceptual semantics level. And from there to the appropriate decisions. So another one of these primitive, Mm-hmm. what are called " image schemas", is uh goal seeking. So this a notion of a source, Mm-hmm. path, goal, trajector, possibly obstacles. And the idea is this is another conceptual primitive. And that all sorts of things, particularly in the tourist domain, can be represented in terms of uh source, path and goal. So the idea would be could we build an analyzer that would take an utterance Mm-hmm. and say "Aha! th- this utterance is talking about an attempt to reach a goal. The goal is this, the pers- the, uh traveler is that, uh the sor- w- where we are at now is is this, they've mentioned possible obstacles, et cetera." So th- the - and this is an - again attempt to get very wide coverage. So if you can do this, then the notion would be that across a very large range of domains, you could use this deep conceptual basis as the interface. Mm-hmm. Mm-hmm. And then, uh The processing of that, both on the input end, recognizing that certain words in a language talk about containers or goals, et cetera, and on the output end, given this kind of information, you can then uh make decisions about what actions to take. Provides, they claim, a very powerful, general notion of deep semantics. So that's what we're really doing. Mm-hmm. And Nancy is going to - Her talk is going to be not about using this in applications, but about modeling how children might learn Mm-hmm. this kind of uh deep semantic grammar. Yep, yep. And how do you envision um the - the um this deep semantic to be worked with. Would it be highly ambiguous if and then there would be another module that takes that um highly underspecified deep semantic construction and map it onto the current context to find out what the person really was talking about in that context. or - Well that's - that's - that's where the belief-net comes in. So th- the idea is, or a - let's take this business about going to the Powder-Tower. Mm-hmm. So part of what you'll get out of this will be the fact tha- w- if it works right, O_K, that this is an agent that wants to go to this place and that's their goal and there will be additional situational information. Mm-hmm. Oh, O_K. Uh, O_K, part of it comes from the ontology. The tower is this kind of object. Part of it comes from the user model. th- Mm-hmm. Yeah, O_K. Mm-hmm. And the idea of the belief-net is it combines the information from the dialogue which comes across in this general way, Mm-hmm. you know this is a - this is a goal seeking behavior, along with specific information from the ontology about the kinds of objects involved and about the situation Yeah O_K, Yeah, yep yep yep yep about "Is it raining?" I don't know. Whatever it is. And so that's the belief-net that we've laid out. Mm-hmm. And so th- the coupling to the situation comes in this model from, at th- at th- at the belief-net, combining evidence from the dialogue with the ontology with the situation. Yeah. Hmm. But Nancy isn't gonna talk about that, just about the Yeah, oh yeah, I see, yeah yeah, really. um First steps. Right. The - the construction grammar. And she's gonna start in a minute. In a minute. Ah, O_K. O_K. Is it i- in, then, your place, in five - five-A_? Alright. 