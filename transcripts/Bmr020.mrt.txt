O_K, we're recording. We can say the word "zero" all we want, but just - I'm doing some square brackets, coffee sipping, square brackets. That's not allowed, I think. Curly brackets. Oops. Cur- curly brackets. Mmm! Is that voiced or unvoiced? Curly brackets. Well , correction for transcribers. Yeah. Curly brackets. Right. Gar- darn! Channel two. Yeah. Do we use square brackets for anything? u- These poor transcribers. Uh - Not ri- not right now. I mean - No. u- There's gonna be some zeros from this morning's meeting because I noticed that Barry, I think maybe you turned your mike off before the digits were - Oh, was it during digits? Oh, so it doesn't matter. Yeah. So it's not - it's not that bad if it's at the end, but it's - in the beginning, it's bad. It's still not a good idea. Yeah. Yeah. Yeah, you wanna - you wanna keep them on so you get good noise - noise floors, That's interesting. through the whole meeting. Uh, I probably just should have left it on. Yeah I did have to run, but - Hmm. Is there any way to change that in the software? Change what in the software? Where like you just don't - like if you - if it starts catching zeros, like in the driver or something - in the card, or somewhere in the hardware - Where if you start seeing zeros on w- across one channel, you just add some random, @@ noise floor - like a small noise floor. I mean certainly we could do that, but I don't think that's a good idea. We can do that in post-processing if - if the application needs it. Yeah. Well, I - u- I actually don't know what the default is anymore as to how we're using the - the front-end stuff but - Manual post-processing. for - for - when we use the ICSI front-end, but um, As an argument. there is an - there is an o- an option in - in RASTA, which, um, in- when I first put it in, uh, back in the days when I actually wrote things, uh, I did actually put in a random bit or so that was in it , but O_K. then I realized that putting in a random bit was equivalent to adding uh - adding flat spectrum, Right. and it was a lot faster to just add a constant to the - to the spectrum. So then I just started doing that instead of calling "rand" or something, so. Mmm. O_K. Right. So it d- it does that. Gee! Here we all are! Uh, so the only agenda items were Jane - was Jane wanted to talk about some of the I_B_M There's an agenda? transcription process. I sort of condensed the three things you said into that. And then just - I only have like, this afternoon and maybe tomorrow morning to get anything done before I go to Japan for ten days. So if there's anything that n- absolutely, desperately needs to be done, you should let me know now. Uh, and you just sent off a Eurospeech paper, so. Right. I hope they accept it. I mean, I - Right. both actu- as - as a submission and - you know, as a paper. Um - but - Yeah, I guess you - first you have to do the first one, and then - Yeah. but - Well yeah, you sent it in late. Yeah. We actually exceeded the delayed deadline by o- another day, so. Oops. Oh they - they had some extension that they announced or something? Well yeah. Liz had sent them a note saying "could we please have another" I don't know, "three days" or something, and they said yes. And then she said "Did I say three? I meant four." Oh, that was the other thing uh, But u- uh, Dave Gelbart sent me email, I think he sent it to you too, that um, there's a special topic, section in si- in Eurospeech on new, corp- corpors- corpora. And it's not due until like May fifteenth. Oh this isn't the Aurora one? It's another one? No. It's a different one. No it's - Yeah. Huh! Yeah. And uh, Oh! I got this mail from - I s- forwarded it to Jane as I thought being the most relevant person. Um - So, I thought it was highly relevant - have you - did you look at the U_R_L? That's - Yeah I'm - Yeah. I think so too. Um, I haven't gotten over to there yet, but what - our discussion yesterday, I really - I - I wanna submit one. Mm-hmm. Was this SmartKom message? Yeah. I think Christoph Draxler sent this, yeah. And, you offered to - to join me, if you want me to. Yeah. I'll help, but obviously I can't, I think several people - sent this, yeah. Yeah, that's right. really do, most of it, so. Yeah. Uh-huh. Yeah. But any - any help you need I can certainly provide. Well, that's - that's a great idea. Well - there - there were some interesting results in this paper, though. For instance that Morgan - uh, accounted for fifty-six percent of the Robustness meetings in terms of number of words. Wow. In - in terms of what? In term- Number of words. One? Wow! O_K. That's just cuz he talks really fast. Do you mean, n- No. Oh. Short words . because - I know- is it partly, eh, c- correctly identified words? Or is it - No. Well, according to the transcripts. or just overall volume? Yeah. But re- well regardless. Oh. O_K. I think it's - he's - he's in all of them, I mean, we didn't mention Morgan by name we just - and he talks a lot. Well - we have now, but - One participant. We - we - we - something about - Did you identify him as a senior member? No, we as- identify him as the person dominating the conversation. Well. Yeah. I mean I get these A_A_R_P things, but I'm not se- really senior yet, but - O_K. Right Hmm. Um, but uh, other than that delightful result, what was the rest of the paper about? Um, well it was about - it had three sections uh - three kinds of uh You sent it to me but I haven't seen it yet. results, if you will. Uh, the one was that the - just the - the amount of overlap um, The good, the bad, and the ugly. s- in terms of - in terms of number of words and also we computed something called a "spurt", which is essentially a stretch of speech with uh, no pauses exceeding five hundred milliseconds. Um, and we computed how many overlapped i- uh spurts there were and how many overlapped words there were. Um, for four different corpora, the Meeting Recorder meetings, the Robustness meetings Switchboard and CallHome, and, found - and sort of compared the numbers. Um, and found that the, uh, you know, as you might expect the Meeting Recorder meetings had the most overlap uh, but next were Switchboard and CallHome, which both had roughly the same, almost identical in fact, and the Robustness meetings were - had the least, so - One sort of unexpected result there is that uh I'm surprised. two-party telephone conversations have about the same amount of overlap, sort of in gen- you know - order of magnitude-wise as, uh - as face-to-face meetings with multiple - I have - I had better start changing all my slides! Yeah. Also, I - in the Levinson, the pragmatics book, in you know, uh, textbook, there's - I found this great quote where he says Mm-hmm. Yeah. Yeah. you know - you know, how people - it talks about how uh - how - how people are so good at turn taking, and so - they're so good that generally, u- the overlapped speech does not - is less than five percent. So, Oh, that's interesting. Yeah. this is way more than five percent. Um. Did he mean face - like face-to-face? Or - ? Well, in real conversations, everyday conversations. Hmm. It's s- what these conversation analysts have been studying for years and years there . Mm-hmm. Mm-hmm. Well, of course, no, it doesn't necessarily go against what he said, cuz he said "generally speaking ". In order to - But - Hmm. to go against that kind of a claim you'd have to big canvassing. And in f- Well, he - he made a claim - Well - Well - Yeah, we - we have pretty limited sample here. all So - But - Five percent of time or five percent of what? @@ Yeah. Yeah, I was gonna ask that too. Well it's time. So - but still - but still - u- Yeah. Exactly. It's - i- it's not against his conclusion, it just says that it's a bi- bell curve, and that, Yeah, so - you have something that has a nice range, in your sampling. Yeah. So there are slight - There are differences in how you measure it, but still it's - You know, the difference between um - between that number and what we have in meetings, which is more like, Mm-hmm. you know, close to - in meetings like these, uh - you know, close to twenty percent. But what was it like, say, in the Robustness meeting, for instance? Mm-hmm. That - But - @@ Robustness meeting? It was about half of the r- So, in terms of number of words, it's like seventeen or eigh- eighteen percent for the Meeting Recorder meetings and about half that for, Maybe ten percent? uh, the Robustness. But I don't know if that's really a fair way of comparing between, multi-party, conversations and two-party conversations. Then - then - then you have to - Yeah. I - I - I don't know. I mean that's just something - Yeah, I just wonder if you have to normalize by the numbers of speakers or something. Yeah. Then - Yeah, then normalize by - by something like that, yeah. Well, we didn't get to look at that, but this obvious thing to see if - if there's a dependence on the number of uh - participants. Yeah, that's a good point. Yeah. Good idea. I mean - I bet there's a weak dependence. I'm sure it's - it's not a real strong one. Yeah. Right. Right? Because you- Cuz not everybody talks. Yeah. Right. Right. You have a lot of - a lot of two-party, Right. subsets within the meeting. Well regardless - it's an interesting result regardless. Uh-huh. So - Right. And - and - and then - and we also d- computed this both with and without backchannels, so you might think that backchannels have a special status because they're essentially just - Yes, that's right. Mm-hmm. Uh-huh. So, did - we all said "uh-huh" and nodded at the same time, so. R- right. But, even if you take out all the backchannels - so basically you treat backchannels l- as nonspeech, as pauses, you still have significant overlap. You know, it goes down from maybe - Mm-hmm. Mm-hmm. For Switchboard it goes down from - I don't know - f- um - I don't know - f- fourteen percent of the words to maybe uh I don't know, eleven percent or something - it's - it's not a dramatic change, so it's - Mm-hmm. Anyway, so it's uh - That was - that was one set of results, and then the second one was just basically the - Hmm. the stuff we had in the - in the H_L_T paper on how overlaps effect the recognition performance. Nope . Right. Mm-hmm. And we rescored things um, a little bit more carefully. We also fixed the transcripts in - in numerous ways. Uh, but mostly we added one - one number, which was what if you uh, basically score ignoring all - So - so the - the conjecture from the H_L_T results was that most of the added recognition error is from insertions due to background speech. So, we scored all the recognition results, uh, in such a way that the uh - Oh by the way, who's on channel four? You're getting a lot of breath. Yeah. That's - I j- was just wondering. Yeah. That's me. uh, well Don's been working hard. @@ That's right. O_K, so - so if you have the foreground speaker speaking here, and then there's some background speech, may be overlapping it somehow, um, and this is the time bin that we used, then of course you're gonna get insertion errors here and here. Right? So we scored everything, and I must say the NIST scoring tools are pretty nice for this, Right. where you just basically ignore everything outside of the, uh, region that was deemed to be foreground speech. And where that was we had to use the t- forced alignment, uh, results from s- for - so - That's somewhat - that's somewhat subject to error, but still we - we - Uh, Don did some ha- hand-checking and - and we think that - based on that, we think that the results are you know, valid, although of course, some error is gonna be in there. But basically what we found is after we take out these regions - so we only score the regions that were certified as foreground speech, the recognition error went down to almost uh, the level of the non-overlapped speech. So that means that even if you do have background speech, if you can somehow separate out or find where it is, That's great. uh, the recognizer does a good job, Yeah. even though there is this back- Yeah, I guess that doesn't surprise me, because, with the close-talking mikes, the - the signal will be so much stronger. Right. Right. Mm-hmm. Mm-hmm. Um, so - What - what sort of normalization do you do? Uh, well, we just - @@ we do - u- you know, vit- I mean in you recognizer, in the S_R_I recognizer. Well, we do uh, V_T_L - vocal tract length normalization, w- and we uh - you know, we - we uh, make all the features have zero mean and unit variance. And - Over an entire utterance? Over - over the entire c- over the entire channel. Over the - but you know. Or windowed? Don't train - Hmm. Um, now we didn't re-align the recognizer for this. We just took the old - So this is actually a sub-optimal way of doing it, right? So we took the old recognition output and we just scored it differently. Right. Right. So the recognizer didn't have the benefit of knowing where the foreground speech - a- start- Were you including the - the lapel in this? Yes. And did the - did - did the la- did the - the problems with the lapel go away also? Or - Um, it - Yeah. It u- not per - I mean, not completely, but yes, dramatically. fray- for - for insertions? Less so. So we have to um - I mean, you still - Well I should bring the - should bring the table with results. Maybe we can look at it Monday . I would presume that you still would have somewhat higher error with the lapel for insertions than - Yeah. Yes. It's - It's - Yes. Yeah. Cuz again, looking forward to the non-close miked case, I think that we s- still - Mm-hmm. I'm not looking forward to it. i- it's the high signal-to-noise ratio Right. here that - that helps you. u- s- Right. So - so that was number - that was the second set of - uh, the second section. And then, the third thing was, we looked at, uh, what we call "interrupts", although that's - that may be a misnomer, but basically we looked at cases where - Uh, so we - we used the punctuation from the original transcripts and we inferred the beginnings and ends of sentences. So, you know - Di- did you use upper-lower case also, or not? Um - Hmm? U- upper lower case or no? O_K. No, we only used, you know, uh periods, uh, question marks and exclamation. And we know that there's th- that's not a very g- I mean, we miss a lot of them, but - but it's f- i- i- Yeah. That's O_K but - Comma also or not? No commas. No. O_K. And then we looked at locations where, uh, if you have overlapping speech and someone else starts a sentence, you know, where do these - where do other people start their turns - not turns really, but you know, sentences, um - Ah. So we only looked at cases where there was a foreground speaker and then at the to- at the - so the - the foreground speaker started into their sentence and then someone else started later. O_K? Somewhere in between the start and the end? O_K. And so what - Sorry? Somewhere in between the start and the end of the foreground? Yes. Uh, so that such that there was overlap between the two sentences. Yeah. So, the - the question was how can we - what can we say about the places where the second or - or actually, several second speakers, um start their "interrupts", as we call them. Three words from the end. w- At pause boundaries. And we looked at this in terms of um - On T_closures, only. So - so we had - we had um u- to - for - for the purposes of this analysis, we tagged the word sequences, and - and we time-aligned them. Um, and we considered it interrupt - if it occurred in the middle of a word, we basically - you know, considered that to be a interrupt as if it were at - at the beginning of the word. So that, if any part of the word was overlapped, it was considered an interrupted word. Mm-hmm. And then we looked at the - the locatio- the, um, you know, the features that - the tags because we had tagged these word strings, um, that - that occurred right before these - these uh, interrupt locations. Tag by uh- And the tags we looked at are the spurt tag, which basically says - or actually - Sorry. End of spurt. So - whether there was a pause essentially here, because spurts are a - defined as being you know, five hundred milliseconds or longer pauses, and then we had things like discourse markers, uh, backchannels, uh, disfluencies. um, uh, filled pauses - So disfluen- the D_'s are for, um, the interruption points of a disfluency, so, where you hesitate, or where you start the repair there. Uh, what else do we had. Uh, repeated - you know, repeated words is another of that kind of disfluencies and so forth. So we had both the beginnings and ends of these - uh so, the end of a filled pause and the end of a discourse marker. And we just eyeballed - I mean we didn't really hand-tag all of these things. We just looked at the distribution of words, and so every "so yeah", and "O_K", uh, and "uh-huh" were - were the - were deemed to be backchannels and "wow" and "so" and uh "right", uh were um - Not "right". "Right" is a backchannel. But so, we sort of - just based on the lexical - um, identity of the words, we - we tagged them as one of these things. And of course the d- the interruption points we got from the original transcripts. So, and then we looked at the disti- so we looked at the distribution of these different kinds of tags, overall uh, and - and - and particularly at the interruption points. And uh, we found that there is a marked difference so that for instance after - so at the end after a discourse marker or after backchannel or after filled pause, you're much more likely to be interrupted than before. O_K? And also of course after spurt ends, which means basically in p- inside pauses. So pauses are always an opportunity for - So we have this little histogram which shows these distributions and, um, I wonder - you know, it's - it's - it's not - No big surprises, but it is sort of interesting from - It's nice to actually measure it though. Yeah. I wonder about the cause and effect there. In other words uh if you weren't going to pause you - you will because you're g- being interrupted. Well we're ne- Uh - Right. There's no statement about cause and effect. This is just a statistical correlation, yeah. Yeah, right. No, no, no. Right, I - I see. Yeah. But he - yeah, he's - he's right, y- I mean maybe you weren't intending to pause at all, but - You were intending to stop for fifty-seven milliseconds, but then Chuck came in and so you paused for a second Right. @@ Right. Yeah. Right. Anyway. So, or more. uh, and that was basically it. And - and we - so we wrote this and then, we found we were at six pages, and then we started Oops. cutting furiously and threw out half of the material again, and uh played with the LaTeX stuff and - uh, and - until it fi- Made the font smaller and the narrows longer. Font smaller, yeah. No, no. W- well, d- you couldn't really make everything smaller but we s- we put - Oh, I - I - Put the abstract end . you know the - the gap between the two columns is like ten millimeters, so I d- Took out white space. Yeah. shrunk it to eight millimeters and that helped some. And stuff like that. Wasn't there - wasn't there some result, Andreas - I - I thought maybe Liz presented this at some conference a while ago about uh, backchannels uh, Yeah - Mm-hmm. Mm-hmm. and that they tend to happen when uh the pitch drops. You know you get a falling pitch. Yeah. Well - And so that's when people tend to backchannel. Uh- i- i- do you rem- y- We didn't talk about, uh, prosodic, uh, properties at all, although that's - I - I take it that's something that uh Don will - will look at now that we have the data and we have the alignment, so. Right. Right. But - Yeah, we're gonna be looking at that. This is purely based on you know the words and - Mm-hmm. I have a reference for that though. Oh you do. Yeah. Uh-huh. So am I recalling correctly? About - Anyway , so. Well, I didn't know about Liz's finding on that, Uh-huh. but I know of another paper that talks about something Hmm. that - I'd like to see that reference too. It made me think about a cool little device that could be built O_K. to uh - to handle those people that call you on the phone and just like to talk and talk and talk. And you just have this little detector that listens for these drops in pitch and gives them the backchannel. And so then you hook that to the phone and go off and do the - do whatever you r- wanna do, while that thing keeps them busy. Yeah. Uh-huh. Oh yeah. Well - There's actually - uh there's this a former student of here from Berkeley, Nigel - Nigel Ward. Do you know him? Uh-huh. Sure. Yeah. He did a system uh, in - he - he lives in Japan now, and he did this backchanneling, automatic backchanneling system. It's a very - Right. Oh! So, exactly what you describe, but for Japanese. And it's apparently - for Japa- in Japanese it's really important that you backchannel. Huh. It's really impolite if you don't, and - So. Huh. Actually for a lot of these people I think you could just sort of backchannel continuously and it would pretty much be fine. It wouldn't matter? Yeah. Random intervals. Yeah. That's w- That's what I do. There was - there was of course a Monty Python sketch with that. Where the barber who was afraid of scissors was playing a - a tape of clipping sounds, and saying "uh-huh", "yeah", "how about them sports teams?" Anyway. So the paper's on-line and y- I - I think I uh - I C_C'ed a message to Meeting Recorder with the U_R_L so you can Yep. Yeah. get it. Printed it out, haven't read it yet. Um, uh one more thing. So I - I'm actually - Yeah. about to send Brian Kingsbury an email saying where he can find the - the s- the m- the material he wanted for the s- for the speech recognition experiment, so - but I haven't sent it out yet because actually my desktop locked up, like I can't type anything. Uh b- so if there's any suggestions you have for that I was just gonna Is it the same directory that you had suggested? send him the - I made a directory. I called it um - Well this isn't - He still has his Unix account here, you know. He does? Yeah. Yeah but - but - but he has to - And he - and he's - I'd hafta add him to Meeting Recorder, I guess, but - he prefe- he said he would prefer F_T_P O_K. and also, um, the other person that wants it - There is one person at S_R_I who wants to look at the um, you know, the uh - the data we have so far, O_K. and so I figured that F_T_P is the best approach. So what I did is I um - @@ I made a n- new directory after Chuck said that would c- that was gonna be a good thing. Uh, so it's "F_T_P pub real" - Exactly. Pub real. M_T_G_C - What is it again? C_R - Ask Dan Ellis. u- R_D_ - R_D_R, yeah. Or - Yeah. Right? The same - the same as the mailing list, and - Yeah. Yeah, the - No vowels. Yeah Um, and then under there - Um actually - Oh and this directory, is not readable. It's only uh, accessible. So, in other words, to access anything under there, you have to be told what the name is. So that's sort of a g- quick and dirty way of doing access control. So - Right. Mm-hmm. uh, and the directory for this I call it I- "A_S_R zero point one" because it's sort of meant for recognition. So anyone who hears this meeting now knows the - Beta? And then - then in there I have a file that lists all the other files, so that someone can get that file and then know the file names and therefore download them. If you don't know the file names you can't - I mean you can - Is that a dash or a dot in there? Don't - don't - don't say. Dash. @@ Anyway. So all I - all I was gonna do there was stick the - the transcripts after we - the way that we munged them for scoring, because that's what he cares about, and - um, and also - and then the - the waveforms that Don segmented. I mean, just basically tar them all up f- I mean - w- for each meeting I tar them all into one tar file and G_zip them and stick them there. I uh, And so. put digits in my own home directory - home F_T_P directory, but I'll probably move them there as well. Oh, O_K. O_K. So we could point Mari to this also for her Yeah. March O_one request? March O_one. Oh! Or - You n- Remember she was - Oh she wanted that also? Well she was saying that it would be nice if we had - they had a - Or was she talking - Yeah. She was saying it would be nice if they had eh the same set, so that when they did experiments they could compare. Right, but they don't have a recognizer even. Yeah. Um - But yeah, we can send - I can C_C Mari on this so that she knows - I- Yeah. So, for the thing that - We need to give Brian the beeps file, so I was gonna probably put it - That's good. Right. We can put it in the same place. Just put in another directory. Yeah, it- Well, make ano- make another directory. You don't n- m- Yeah. I'll make another directory. Yeah. Exactly. Yeah. And, Andreas, um, Yeah. sampled? They are? I think so. Yeah. O_K. Um, so either we should regenerate the original versions, or um, we should just make a note of it. Oh. Beca- Well - O_K, because in one directory there's two versions. Yeah, that's the first meeting I cut both versions. Just to check which w- if there is a significant difference. O_K. And so I - but - O_K so - but for the other meetings it's the downsampled version that you have. They're all downsampled, yeah. Oh, O_K. Oh that's th- important to know, O_K so we should probably - uh give them the non-downsampled versions. Yeah. So - O_K. Alright, then I'll hold off on that and I'll wait for you um - Probably by tomorrow I can - gen- O_K. I'll send you an email. Alright. O_K. Yeah, definitely they should have the full bandwidth version, yeah. Right. O_K. Yeah, because I mean - I- I think Liz decided to go ahead with the downsampled versions cuz we can - There was no s- like, r- significant difference. Well, it takes - it takes up less disk space, for one thing. It does take up less disk space, and apparently it did even better than the original - than the original versions, which Yeah. Yeah. Right. you know, is just, probably random. Yeah, it was a small difference but yeah. But, um they probably w- want the originals. Yeah. O_K. O_K, good. Good that - Well, it's a good thing that - O_K , I think we're losing, Don and Andreas at three-thirty, right? O_K. Yeah. Hey mon hafta booga. So, that's why it was good to have Andreas, say these things but - So, we should probably talk about the I_B_M transcription process stuff that - O_K. Hmm. So, um you know that Adam created um, a b- a script to generate the beep file? To then create something to send to I_B_M. And, um, you - you should probably talk about that. But - but you were gonna to use the originally transcribed file because I tightened the time bins and that's also the one that they had already in trying to debug the first stage of this. And uh, my understanding was that, um - I haven't - I haven't listened to it yet, but it sounded very good and - and I understand that you guys were going to have a meeting today, before this meeting. Mm-hmm. It was just to talk about how to generate it. Um, just so that while I'm gone, you can regenerate it if you decide to do it a different way. Excellent. O_K. So uh, Chuck and Thilo should, now more or less know how to generate the file and, the other thing Chuck pointed out is that, um, since this one is hand-marked, there are discourse boundaries. Mm-hmm. O_K. Right? So - so when one person is speaking, there's breaks. Whereas Thilo's won't have that. Mm-hmm . Oh! O_K. Ah, interesting. Yeah. Yeah. So what - what we're probably gonna do is just write a script, that if two, chunks are very close to each other on the same channel we'll just merge them. Oh, sure. Yeah, sure. Makes sense. So, uh, and that will get around the problem of, the, you know "one word beep, one word beep, one word beep, one word beep". Yeah. Ah! Clever. Yes. Clever. And - And it will be more - more close - close to - to the version they will get afterwards - after @@ . Yeah. Excellent. Yeah, in fact after our meeting uh, this morning Thilo came in and said that And that's the purpose. um, there could be other differences between the uh already transcribed meeting with the beeps in it and one that has just r- been run through his process. So tomorrow, Yeah. Yeah. when we go to make the um uh, chunked file for I_B_M, we're going to actually compare the two. So he's gonna run his process on that same meeting, Great idea! and then we're gonna do the beep-ify on both, and listen to them and see if we notice any real differences. Beep-ify! Yeah. O_K, now one thing that prevented us from apply- you - you from applying - Exactly. The training - So that is the training meeting. Yeah, it's the training meeting, but - Yeah. Yeah, w- and we know that. Wel- uh we just wanna if - if there're any major differences between O_K. But, yeah - Uh-huh. I only used the first twenty minutes for training, so we can use the @@ doing it on the hand- Oh, interesting. Ah! O_K. Interesting idea. But it's the same speakers and the same channels @@ Hmm. So this training meeting, uh w- Great. un- is that uh some data where we have uh very um, you know, accurate time marks? for - I went back and hand-marked the ba- the bins, I ment- I mentioned that last week. O_K, yeah. Because - But the - but there's - yeah, but there is this one issue with them in that there're - there are time boundaries in there that occur in the middle of speech. So - Like when we went t- to um - When I was listening to the original file that Adam had, it's like you - you hear a word then you hear a beep and then you hear the continuation of what is the same sentence. That's on the other channel. That's because of channel overlap. Well, and - and so the - th- Hmm. So there are these chunks that look like uh - It's - i- that have uh - I mean that's not gonna be true of the foreground speaker. That'll only be if it's the background speaker. Right. So you'll - you'll have a chunk of, you know, channel A_ which starts at zero and ends at ten, and then the same channel starting at eleven, ending at fifteen, and then again, starting at sixteen, ending at twenty. Right, so that's three chunks where actually we w- can just make one chunk out of that Mm-hmm. which is A_, zero, twenty. Yeah. Sure. That's what I just said, yeah. Sure. Yeah. So I just wanted to make sure that it was clear. So if you were to use these, you have to be careful not to pull out these individual - Yeah, I thought that was - Yeah. Oh! I mean it - Right, I mean w- I mean what I would - I was interested in is having - a se- having time marks for the beginnings and ends of speech by each speaker. Well, that's definitely a problem. Uh, because we could use that to fine tune our alignment process to make it more accurate. Yeah . Battery. Battery? Mm-hmm. So - uh, it - I don't care that you know, there's actually abutting segments that we have to join together. That's fine. But what we do care about is that O_K. the beginnings and ends um are actually close to the speech inside of that uh - Yeah, I think Jane tightened these up by hand. O_K, so what is the - sort of how tight are they? O_K. Yeah. Uh, it looks much better. Yeah. Looks good. They were, um, reasonably tight, but not excruciatingly tight. That would've taken more time. Oh. No, no! I don- actually I - I - I - it's f- I just wanted to get it so tha- So that if you have like "yeah" Let me make a note on yours. Yeah. in a - swimming in a big bin, then it's - That's fine because we don't want to - th- that's perfectly fine. In fact it's good. You always want to have a little bit of pause or nonspeech around the speech, say for recognition purposes. Uh, but just - just u- w- you know get an id- I just wanted to have an idea of the - of how much extra you allowed um - so that I can interpret the numbers if I compared that with a forced alignment segmentation. I can't answer that, but - but my main goal was um, in these areas where you have a three-way overlap and one of the overlaps involves "yeah", So. Mm-hmm. and it's swimming in this huge bin, I wanted to get it so that it was clo- more closely localized. Mm-hmm. Right. But are we talking about, I don't know, a tenth of a second? a - ? You know? How - how much - how much extra would you allow at most - I - I wanted to - I wanted it to be able to - l- he- be heard normally, Mm-hmm. so that if you - if you play back that bin and have it in the mode where it stops at the boundary, O_K. it sounds like a normal word. It doesn't sound like the person - i- it sounds normal. It's as if the person could've stopped there. Mm-hmm. O_K. And it wouldn't have been an awkward place to stop. Now sometimes you know, it's - these are involved in places where there was no time. And so, Mm-hmm. there wouldn't be a gap afterwards because - I mean some cases, there're some people um, who - O_K. who have very long segments of discourse where, you know, they'll - they'll breath and then I put a break. Mm-hmm. But other than that, it's really pretty continuous and this includes things like going from one sentence into the - u- one utterance into the next, one sentence into the next, um, w- without really stopping. I mean - i- they, i- you know in writing you have this two spaces and a big gap you know. But - but uh i- some people are planning and, you know, I mean, a lot - we always are planning what we're going to say next. But uh, in which case, Mm-hmm. Right. O_K. the gap between these two complete syntactic units, um, which of course n- spoken things are not always complete syntactically, but - but it would be a shorter p- shorter break than maybe you might like. But the goal there was to not have the text be Mm-hmm. so - so crudely parsed in a time bin. I mean, because from a discourse m- purpose it's - it's more - it's more useful to be able to see - and also you know, from a speech recognition purpose my impression is that if you have too long a unit, it's - it doesn't help you very much either, cuz of the memory. Well, yeah. That's fine. So, that means that the amount of time after something is variable depending partly on context, but my general goal when there was sufficient space, room, pause after it to have it be kind of a natural feeling gap. O_K. Which I c- I don't know what it would be quantified as. You know, Wally Chafe says that um, in producing narratives, the spurts that people use tend to be, uh, that the - the - what would be a pause might be something like two - two seconds. Mmm. And um, that would be, you know one speaker. The discourse - the people who look at turn taking often do use - I was interested that you chose uh, Mm-hmm. you know um, the - you know that you use cuz I think that's a unit that would be more consistent with sociolinguistics. Well we chose um, Yeah. you know, half a second because if - if you go much larger, you have a - y- you know, your - your statement about how much overlap there is becomes less, um, precise, because you include more of actual pause time into what you consider overlap speech. Mm-hmm. Um, so, it's sort of a compromise, and - it's also based - I mean Liz suggested that value based on Yeah. the distribution of pause times that you see in Switchboard and - Mm-hmm. and other corpora. Um - So - Yeah, I also used I think something around zero point five seconds for the speech-nonspeech detector - for the minimum silence length. Mm-hmm. I see. Yeah. So. Mm-hmm. O_K. In any case, this - this uh, meeting that I hand - I - I hand-adjusted two of them I mentioned before, and I sent - I sent email, so - Mm-hmm. O_K, So - so at some point we will try to fine-tune our forced alignment maybe using those as references And I sent the path. because you know, what you would do is you would play with different parameters. And to get an object- You need an objective measure of how closely you can align the models to the actual speech. And that's where your your data would be very important to have. So, I will - Um - Yeah and hopefully the new meetings which will start from the channelized version will - will have better time boundaries and alignments. Mm-hmm. Right. But I like this idea of - uh, for our purposes for the - for the I_B_M preparation, uh, n- Yeah. having these joined together, and uh - Yeah. It makes a lot of sense. And in terms of transcription, it would be easy to do it that way. The way that they have Yeah. Yeah . with the longer units, not having to fuss with adding these units at this time. Yeah. Right. Whi- which could have one drawback. If there is uh a backchannel in between those three things, Mm-hmm. the - the n- the backchannel will - will occur at the end of - of those three. And - Yes. and in - in the - in the previous version where in the n- which is used now, there, the backchannel would - would be in- between there somewhere, so. I see. Yeah. Well, that's - that's right, but you know, thi- this brings me to the other f- stage of this which I discussed with you earlier today, which is the second stage is um, That would be more natural but - Yeah. w- what to do in terms of the transcribers adjustment of these data. I discussed this with you too. Um, the tr- so the idea initially was, we would get uh, for the new meetings, so the e- E_D_U meetings, that Thilo ha- has now presegmented all of them for us, on a channel by channel basis. And um, so, I've assigned - I've - I've assigned them to our transcribers and um, so far I've discussed it with one, with uh - And I had a about an hour discussion with her about this yesterday, we went through uh E_D_U- one, at some extent. And it occurred to me that um - that basically what we have in this kind of a format is - you could consider it as a staggered mixed file, we had some discussion over the weekend a- about - at - at this other meeting that we were all a- at - um, about whether the tran- the I_B_M transcribers should hear a single channel audio, or a mixed channel audio. And um, in - in a way, by - by having this - this chunk and then the backchannel after it, it's like a stagal- staggered mixed channel. And um, it occurred to me in my discussion with her yesterday that um, um, the - the - the maximal gain, it's - from the I_B_M people, may be in long stretches of connected speech. So it's basically a whole bunch of words which they can really do, because of the continuity within that person's turn. So, what I'm thinking, and it may be that not all meetings will be good for this, but - but what I'm thinking is that in the E_D_U meetings, they tend to be driven by a couple of dominant speakers. And, if the chunked files focused on the dominant speakers, then, when - when it got s- patched together when it comes back from I_B_M, we can add the backchannels. It seems to me that um, you know, the backchannels per- se wouldn't be so hard, but then there's this question of the time @@ uh, marking, and whether the beeps would be uh y- y- y- And I'm not exactly sure how that - how that would work with the - with the backchannels. And, so um - And certainly things that are intrusions of multiple words, taken out of context and displaced in time from where they occurred, that would be hard. So, m- my thought is i- I'm having this transcriber go through the E_D_U- one meeting, and indicate a start time f- for each dominant speaker, endpoi- end time for each dominant speaker, and the idea that these units would be generated for the dominant speakers, and maybe not for the other channels. Yeah the only, um, disadvantage of that is, then it's hard to use an automatic method to do that. The advantage is that it's probably faster to do that than it is to use the automated method and correct it. So. Well, it - O_K. I think - I - I think um, you know, the original plan was that the transcriber would adjust the t- the boundaries, and all that for all the channels but, We'll just have to see. you know, that is so time-consuming, and since we have a bottleneck here, we want to get I_B_M things that are usable s- as soon as possible, then this seemed to me it'd be a way of gett- to get them a flood of data, which would be useful when it comes back to us. And um - Yeah. Oh also, at the same time she - when she goes through this, she'll be uh - If there's anything that was encoded as a pause, but really has something transcribable in it, then she's going to uh, make a mark - w- uh, so you know, so that - that bin would be marked as it - as double dots and she'll just add an S_. And in the other - in the other case, if it's marked as speech, and really there's nothing transcribable in it, then she's going to put a s- dash, and I'll go through and it - and um, you know, with a - with a substitution command, get it so that it's clear that those are the other category. I'll just, you know, recode them. But um, um, the transcribable events that um, I'm considering in this, uh, continue to be laugh, as well as speech, and cough and things like that, so I'm not stripping out anything, just - just you know, being very lenient in what's considered speech. Jane? In terms of the - this new procedure you're suggesting, um, Yeah? u- what is the - It's not that different. So I'm a little confused, because how do we know where to put beeps? Is it - i- d- y- is it - Oh, O_K. So what it - what it - what it involves is - is really a s- uh, Transcriber will do it. uh, the original pr- procedure, but only applied to uh, a certain strategically chosen s- aspect of the data. So - We pick the easy parts of the data basically, and transcriber marks it by hand. You got it. And because - But after we've done Thilo's thing. No. Yes! Yes! Oh yeah! Oh, after. Oh, O_K, I didn't - I didn't understand that. O_K. So, I'm @@ - now I'm confused. O_K. We start with your presegmented version - O_K, and I'm leaving. So, um - Yeah, I have to go as well. O_K, leave the mikes on, and just put them on the table. O_K. Thanks. We start with the presegmented version - You start with the presegmentation, r- yeah? Let me mark you as no digits. Yeah. And then um, the transcriber, instead of going painstakingly through all the channels and moving the boundaries around, and deciding if it's speech or not, but not transcribing anything. O_K? Instead of doing that, which was our original plan, Mm-hmm. the tra- They focus on the dominant speaker - They just do that on the main channels. Yeah. So what they do is they identify who's the di- dominant speaker, and when the speaker starts. O_K. Yeah? O_K. So I mean, you're still gonna - So we're - It's based on your se- presegmentation, that's the basic thing. And you just - and you just use the s- the segments of the dominant speaker then? For - for sending to - to I_B_M or - ? Yeah. Exactly. So, now Jane, my question is when they're all done adjusting the w- time boundaries for the dominant speaker, Mm-hmm. have they then also erased the time boundaries for the other ones? Uh No. No, no. So how will we know who - Huh-uh. S- Yeah. That's - that's why she's notating the start and end points of the dominant speakers. So, on a - you know, so i- in E_D_U- one, i- as far as I listened to it, you start off with a - a s- section by Jerry. So Jerry starts at minute so-and-so, and goes until minute so-and-so. And then Mark Paskin comes in. And he starts at minute such-and-such, and goes on till minute so-and-so. O_K. And then meanwhile, she's listening to both of these guys' channels, determining if there're any cases of misclassification of speech as nothing, and nothing as speech, Mm-hmm. O_K. and a- and adding a tag if that happens. So she does the adjustments on those guys? But you know, I wanted to say, his segmentation is so good, that um, the part that I listened to with her yesterday On that meeting. Mm-hmm. didn't need any adjustments of the bins. So far we haven't. So this is not gonna be a major part of the process, at least - least not in - not on ones that - that really - So if you don't have to adjust the bins, Mm-hmm? why not just do what it - for all the channels? Why not just throw all the channels to I_B_M? Well there's the question o- of whether - Well, O_K. She i- It's a question of how much time we want our transcriber to invest here when she's gonna have to invest that when it comes back from I_B_M anyway. Mm-hmm. Mm-hmm. So if it's only inserting "mm-hmm"s here and there, Right. then, wouldn't that be something that would be just as efficient to do at this end, instead of having it go through I_B_ M, then be patched together, then be double checked here. Yeah. But - But then we could just use the - the output of the detector, and do the beeping on it, and send it to I_B_ M. Without having her check anything. Well, I guess - Right. Yeah. I think we just - we just have to listen to it and see how good they are. For some meetings, I'm - I'm sure it - i- n- I'm - I'm open to that, it was - @@ Yeah, if it's working well, that sounds like a good idea since as you say you have to do stuff with the other end anyway. That's - And some - on some meetings it's good. Yeah. Well yea- O_K, good. I mean the detector, this - Now, you were saying that they - they differ in how well they work depending on channel s- sys- systems and stuff. Yeah, I mean we have to fix it when it comes back anyhow. Yeah. Yeah. So we should perhaps just select meetings on which the speech-nonspeech detection works well, and just use, But E_D_U is great. those meetings to - to - to send to I_B_M and, Release to begin with. How interesting. You know - What's the problem - the l- I forget. Is the problem the lapel, or - or - do the other ones. Uh, it really depends. Um, my - my - my impression is that it's better for meetings with fewer speakers, and it's better for - for meetings where nobody is breathing. Oh, the dead meetings. Yeah, get - That's it. So in fact this might suggest an alternative sort of a - a c- a hybrid between these two things. So the - the one suggestion is you know we - No, the undead meeting, yeah. Yeah. Yeah? we run Thilo's thing and then we have somebody go and adjust all the time boundaries and we send it to I_B_M. The other one is Yeah? Yeah. we just run his thing and send it to I_B_M. There's a - a- another possibility if we find that there are some problems, and that is Yeah. Yeah. Yeah. if we go ahead and we just run his, and we generate the beeps file, then we have somebody listen beeps file. Yeah. And they listen to each section and say "yes, no" whether that section is And erase - Yeah. Is intelligible. i- i- intelligible or not. And it just - You know, there's a little interface which will - for all the "yes"-es it - then that will be the final Yeah. Blech. That's interesting! Cuz that's - that's directly related to the e- end task. beep file. Stress test. Mm-hmm. How interesting! Yeah. I mean it wouldn't be that much fun for a transcriber to sit there, hear it, beep, yes or no. But it would be quick. Nope . I - I - I don't know. It would be - kind of quick but they're still listening to everything. But there's no adjusting. And that's what's slow. There's no adjusting of time boundaries. Well, eh, listening does take time too. Yeah. I don't know, I - I think I'm - I'm really tending towards - I mean, what's the worst that happens? Do the transcribers - I mean as long as th- on the other end they can say there's - Yeah. One and a half times real time. there's something - conventions so that they say "huh?" Yeah. Right. and then we can flag those later. i- i- It - i- They - they - Yeah. That's true. We can just catch it at the - catch everything at this side. Well maybe that's the best way to go, just - Yeah. How interesting! Well E_D_U - I mean it just depends on how - Yeah, u- u- u- Sorry, go ahead. So I was gonna say, E_D_U- one is good enough, maybe we could include it in this - in this set of uh, this stuff we send. Yeah. Yeah there's - I - I think there are some meetings where it would - would - Yeah I - I think, It's possible like this. we won't know until we generate a bunch of beep files automatically, listen to them and see how bad they are. Yeah. Yeah. Yeah. We won't be able to s- include it with this first thing, Mm-hmm. Hmm. If - Oh, O_K. because there's a part of the process of the beep file which requires knowing the normalization coefficients. Oh, I see. And - So a- That's not hard to do. O_K- Just - it takes - you know, it just takes five minutes rather than, Yeah. taking a second. Right, except I don't think that - the c- the instructions for doing that was in that directory, right? I - I didn't see where you had gener- So. I just hand - hard-coded it. No, but it's easy enough to do. What - @@ But I - but I have a - Doing the gain? It's no problem. n- Doing th- Adjusting the gain? No, getting the coefficients, for each channel. Know what numbers. Yeah, that's no problem. O_K. So we just run that one - We can do that. There are lots of ways to do it. I have one program that'll do it. You can find other programs. Yeah. I - I used it, so. We just run that J_sound-stat? Yep. Yeah. Yeah. O_K. O_K. But - Minus D_ , capital D_ . Yeah. but - but I - I - I have another suggestion on that, which is, since, really what this is, is - is - is trying to in the large, send the right thing to them and there is gonna be this - this post-processing step, um, why don't we check through a bunch of things by sampling it? Mm-hmm. Right? In other words, rather than, um, uh, saying we're gonna listen to everything - I didn't mean listen to everything, I meant, Yeah. So y- you do a bunch of meetings, you listen to - to a little bit here and there, if it sounds like it's almost always right and there's not any big problem you send it to them. just see if they're any good. Yeah. Send it to them. O_K. Yeah. And, you know, then they'll send us back what we - w- what - what they send back to us, and we'll - we'll fix things up and Oh, that'd be great. some meetings will cost more time to fix up than others. We should - Yeah. Yeah. And we should just double-check with Brian on a few simple conventions on how they should mark things. O_K. Sure. When they - when there's either no speech in there, or Yeah. Yeah. something they don't understand, things like that. Yeah. Mm-hmm. Yeah, cuz @@ uh- what I had originally said to Brian was well they'll have to mark, Yeah. when they can't distinguish between the foreground and background, because I thought that was gonna be the most prevalent. Mm-hmm. But if we send them without editing, then we're also gonna hafta have m- uh, notations for words that are cut off, Yeah. Mm-hmm. Yeah. and other sorts of, uh, acoustic problems. And they may just guess at what those cut-off words are, but w- I mean we're gonna adjust - everything when we come back - They do already. Yeah. But what - what we would like them to do is be conservative so that they should only write down the transcript if they're sure. And otherwise they should mark it so that we can check. Yeah. Mark it. Sure. Yeah. Yeah. Mm-hmm. Well, we have the unintelligibility convention. And actually they have one also, which - Mm-hmm. Right. i- Can I maybe have - have an order of - it's probably in your paper that I haven't looked at lately, but - Uh, an order of magnitude notion of - of how - Certainty. on a good meeting, how often uh, do you get segments that come in the middle of words and so forth, and uh - in a bad meeting how often? Uh. Was is it in a - in a - what - what is the t- Well he's saying, you know, that the - the E_D_U meeting was a good - good meeting, right? Uh, and so - so - so it was almost - it was almost always doing the right thing. In a good meeting, what? Yeah. Yeah. Oh I see, the characteristics. So I wanted to get some sense of what - what almost always meant. And then, uh in a bad meeting, or p- some meetings where he said oh he's had some problems, what does that mean? Uh-huh. So I mean does one of the- does it mean one percent and ten percent? Or does it mean five percent and fifty percent? O_K. O_K. Uh - So - Or - Maybe percentage isn't the right word, but you know how many - how many per minute, or - You know. Just @@ Yeah th- Yeah, the - the problem is that, nnn, the numbers Ian gave in the paper is just uh, some frame error rate. So that's - that's not really - What will be effective for - for the transcribers, is - They have to - yeah, in- in- they have to insure that that's a real s- spurt or something. And - but, the numbers - Oops. Um - Hmm! Let me think. So the speech - the amount of speech that is missed by the detector, for a good meeting, I th- is around or under one percent, I would say. But there can be - Yeah. For - yeah, but there can be more - There's - There's more amount speech - uh, more amount of - Yeah well, the detector says there is speech, but there is none. So that - that can be a lot when - when it's really a breathy channel. But I think that's less of a problem. They'll just listen. It's just wasted time. Yeah. Yeah. And th- and that's for a good meeting. Now what about in a meeting that you said we've - you've had some more trouble with? I can't really - hhh, Tsk. I don't have really representative numbers, I think. That's really - I - I did this on - on four meetings and only five minutes of - of every meet- of - of these meetings so, it's not - not that representative, but, it's perhaps, Fff. Um - Yeah, it's perhaps then - it's perhaps five percent of something, which s- uh the - the frames - speech frames which are - which are missed, but um, I can't - can't really tell. Right. So I - So i- Sometime, we might wanna go back and look at it more in terms of Yeah. how many times is there a spurt that's - that's uh, interrupted? Yeah. Yeah. Something like that? The other problem is, that when it - when it uh d- i- on the breathy ones, where you get And - So - breathing, uh, inti- indicated as speech. And I guess we could just indicate to the transcribers not to encode that if they - We could still do the beep file. Yeah again I - I think that that is probably less of a problem because if you're - if there's - O_K. If - if a - if a word is - is split, then they might have to listen to it a few times to really understand that they can't quite get it. O_K. O_K. Whereas if they listen to it and there's - don't hear any speech I think they'd probably just listen to it once. So there'd - you'd think there'd be a - But - Yeah. a factor of three or four in - in, uh, cost function, you know, between them or something. O_K. Yeah, so - but I think that's - n- that really doesn't happen very often that - that - that a word is cut in the middle or something. That's - that's really not - not normal. So - so what you're saying is that nearly always what happens when there's a problem is that - is that uh, there's some uh, uh nonspeech that uh - that is b- interpreted as speech. That is marked as speech. Yeah. Yeah. Well then, we really should just send the stuff. That would be great. Right? Because that doesn't do any harm. Yeah, it's - You know, if they - they hear you know, a dog bark and they say what was the word, they you know, they - Yeah, I als- I - Ruff ruff! Yeah I also thought of - there - there are really some channels where it is almost um, only bre- breathing in it. Yeah? And to - to re-run's Eh, um. Yeah. I've got a - a P_- a method with loops into the cross-correlation with the P_Z_M mike, Uh-huh. and then to reject everything which - which seems to be breath. So, I could run this on those breathy channels, and perhaps throw out - That's a good idea. Wow, that's a great idea. Yeah. But I think - I th- Again, I think that sort of - that that would be good, and what that'll do is just cut the time a little further. Yeah. Mm-hmm. Yeah. But I think none of this is stuff that really needs somebody doing these - these uh, uh, Yeah. Excellent. explicit markings. Oh, I'd be delighted with that, I - I was very impressed with the - with the result. Yeah. Yeah, cuz the other thing that was concerning me about it was that it seemed kind of specialized to the E_D_U meeting, and - and that then when you get a meeting like this or something, and - and you have a b- a bunch of different dominant speakers you know, how are you gonna handle it. Whereas this sounds like a more general solution is - Yeah. Oh yeah, interesting. Oh yeah. Oh yeah, I pr- I much prefer this, I was just trying to find a way - Cuz I - I don't think the staggered mixed channel is awfully good as a way of handling overlaps. Yeah. Uh-huh. But - but uh - Well good. That - that really simplifies thing then. And we can just, you know, get the meeting, process it, Yeah. put the beeps file, send it off to I_B_M. You know? Mm-hmm. With very little work on our side. Yeah. Process it, hear into it. I would - Do what? Um, listen to it, and then - Or at least sample it. Well, sample it. Sample it. Yeah. I - I would just use some samples, make sure you don't Yeah. Yeah. Yeah. Yeah. send them three hours of "bzzz" or something. Yeah. No. Yeah. Right. That won't be good. Yeah. Yeah that would be very good. Yeah. Yeah. And then we can you know - That'll oughta be a good way to get the pipeline Oh, I'd be delighted. Yeah. going. And there's - there's one point which I uh - Great. yeah, which - which I r- we covered when I - when I r- listened to one of the E_D_U meetings, and that's that somebody is playing sound from his laptop. Uh-huh And i- the speech-nonspeech detector just assigns randomly the speech to - to one of the channels, so. Uh- I haven't- I didn't think of - of s- of What can you do? this before, but what - what shall we do about s- things like this? Well you were suggesting - You suggested maybe just not sending that part of the meeting. But - Yep. Mmm. But, sometimes the - the - the laptop is in the background and some - somebody is - is talking, and, that's really a little bit confusing, but - That's life. It's a little bit confusing. I mean, what're we gonna do? Yeah. Yeah. O_K. Yeah. Even a hand-transcription would - Do you - a hand-transcriber would have trouble with that. So. Yeah, that's - that's a second question, "what - what will different transcribers do with - with the laptop sound?" Would you - would - Yeah, go ahead. What was the l- what was the laptop sound? I mean was it speech, or was it - Yeah. It's speech. Great. Well, so - I mean - So my standard approach has been if it's not someone close-miked, then, they don't end up on one of the close-miked channels. They end up on a different channel. And we have any number of channels available, I mean it's an infinite number of channels. So just put them on some other channel. Uh-huh. Yeah. But, when thi- when this is sent to - to the I_M_- eh, I_B_ M transcribers, I don't know if - if they can tell that's really - Yeah, that's right. Yeah cuz there will be no channel on which it is foreground. Yeah. Yeah. Well, they have a convention, in their own procedures, which is for a background sound. Uh - Right, but, uh, in general I don't think we want them transcribing the background, cuz that would be too much work. Yeah. Right? For it - because in the overlap sections, then they'll- Well I don't think Jane's saying they're gonna transcribe it, but they'll just mark it as being - there's some background stuff there, right? But that's gonna be all over the place. How w- how will they tell the difference between that sort of background and the dormal - normal background of two people talking at once? Yeah. Yeah. Oh, I think - I think it'd be easy to to say "background laptop". But wait a minute, why would they treat them differently? How would they know that? Yeah. Well because one of them - Because otherwise it's gonna be too much work for them to mark it. They'll be marking it all over the place. Yeah. Oh, I s- background laptop or, background L_T wouldn't take any time. Sure, but how are they gonna tell bet- the difference between that and two people just talking at the same time? And - Oh, you can tell. Acoustically, can't you tell? Yeah. It's really good sound, so - Oh is it? Oh! Well, I mean, isn't there a category something like uh, "sounds for someone for whom there is no i- close mike"? Yeah that would be very important, yeah. Yeah. But how do we d- how do we do that for the I_B_ M folks? How can they tell that? Well we may just have to do it when it gets back here. Yes, that's my opinion as well. So we don't do anything for it - with it. Yeah. O_K. That sounds good. Yeah . That sounds good. Yeah. And they'll just mark it however they mark it, and we'll correct it when it comes back. So th- Yeah. @@ O_K. there was a category for @@ speech. O_K. Yeah, the default. Yeah, s- a- No, not default. Well, as it comes back, we have a uh - when we can use the channelized interface for encoding it, then it'll be easy for us to handle. But - Yeah. but if - if out of context, they can't tell if it's a channeled speak- uh, you know, a close-miked speaker or not, then that would be confusing to them. O_K. Right. O_K. I don't know, I - it doesn't - I don't - Either way would be fine with me, I don't really care. Yeah. So. Shall we uh, do digits and get out of here? I have o- I have one question. Do you think we should send the um - that whole meeting to them and not worry about pre-processing it? Or - Uh, what I mean is we - we should Yep. Yes ma'am. leave the part with the audio in the uh, beep file that we send to I_B_M for that one, or should we start after the - that part of the meeting is over Which part? in what we send. So, the part where they're using sounds from their - from their laptops. With - with the laptop sound, or - ? w- If we have speech from the laptop should we just uh, excise that from what we send to I_B_M, or should we i- give it to them and let them do with it what they can? just - I think we should just - it - it's gonna be too much work if we hafta O_K, that'd be nice to have a - a uniform procedure. worry about that I think. Yeah, I think if we just - m- send it all to them. you know. Worry about it when we get back. Good. And see how well they do. Let - Yeah, worry about it when we get back in. Yeah. And give them freedom to - to indicate if it's just not workable. Yeah, O_K, excellent. Yeah. Yeah. Cuz, I wouldn't - don't think we would mind having that transcribed, if they did it. I think - Yeah, yeah. As I say, we'll just have to listen to it and see how horrible it is. Yeah, e- Yeah. O_K. Alright. Sample it, rather. Yeah. I think that - that will be a little bit of a problem as it really switches around between two different channels, I think. What - what I would - That's great. Mm-hmm, and - and they're very - it's very audible? on the close-talking channels? Yeah. Oh well. Yeah. I mean, it's the same problem as the lapel mike. Yeah. But - Oh, interesting. Comparable, yeah. Yeah. O_K, alright. O_K. Let's do digits. Digits. O_K, so we read the transcript number first, right? So - Are we gonna do it altogether or separately? What time is it? Uh, why don't we do it together, that's - that's a nice fast way to do it. Uh, quarter to four. Oh, O_K. Mm-hmm. One, two, three, go! Transcript L_ six three. Transcript L_ five nine. Transcript L_ five seven. Transcript L_ fifty-eight. Transcript L_ six one. Five zero, three seven, eight zero, nine eight, four seven. zero nine, seven five, one three four six, nine two one two Eight nine two, five one six, four seven three seven. Four six, four three, three seven, three one, nine eight, one nine. Nine nine seven, O_ four three, nine eight two. Eight eight six eight, zero four four one, three five six four. Four six one, zero two seven, zero three eight. One two eight, nine two two, eight three five two. Four nine, zero four, one eight, nine one, nine six five eight. six two one, two four six, O_ seven six Six one, nine seven, seven four, eight zero, eight six. Six five one, six nine seven, three eight eight one. Seven three, five two, four three, zero six, six one. one zero, nine one, six six, nine five, four eight Five eight eight, eight four, one nine nine five. Nine six, two zero, zero seven, nine seven, nine O_. Three six, four zero, six six, zero seven, nine three. four seven O_, @@ O_ four eight, O_ five O_ Two two four five, three four seven five, six eight four four. Six one one zero, seven eight O_ eight, nine five O_ four. One six two, four O_ nine, nine seven nine eight. Three two one nine, eight seven four eight, nine zero four two. Four nine five, four nine, six O_, one four. Six four six, six six three, eight one zero. Two, three five two, seven zero, seven six one, six. Three eight zero zero, eight, five six three. Four nine six four, two four eight nine, seven one four six. One two, one three, zero seven, two zero, five five. One nine nine, two seven zero, one two six, five O_, nine two, nine one three nine, three five three eight Six two five five, four one O_ one, three one nine one, Zero nine four six, six one nine zero, three six nine nine. nine eight zero five, five one one six, five eight five six. Three nine two, nine three, four one eight three. one six one, seven five, five two two three eight nine six, six three one, five one two. Five six seven, eight three zero, two five four two. Six, three two four, one seven, five O_ seven, one. seven six, one two, nine two, eight five, four seven. One six three, one two O_, two O_ two four. It's kind of interesting if there're any more errors in these, than we had the first set. Nnn, yeah, I think there probably will be. Yeah. Do you guys plug your ears when you do it? I do. I usually do. I didn't this time. No. I do. I don't. No. I haven't been, no. You don't? How can you do that? I - I - Uh, concentration. Perhaps there are lots of errors in it but Gah! I - I closed, so. Total concentration. Are you guys ready? You hate to have your ears plugged? Really? Yeah. 