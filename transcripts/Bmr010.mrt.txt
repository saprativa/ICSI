O_K. We seem to be recording. @@ Alright! We're not crashing. So, sorry about not - Number four. not pre-doing everything. The lunch went a little later than I was expecting, Chuck. Hmm? O_K. Chuck was telling too many jokes, or something? Yeah. Yep. Pretty much. O_K. Does anybody have an agenda? No. Well, I'm - I sent a couple of items. They're - they're sort of practical. I don't know if you're - I thought somebody had. Yeah, that's right. if - if that's too practical for what we're focused on. Yeah, we only want th- useless things. Yeah. No, why don't we talk about practical things? Sure. I mean, we don't want anything too practical. Yeah, that would be - O_K. Well, um, I can give you an update on the transcription effort. Great. Uh, maybe raise the issue of microphone, uh, um procedures b- with reference to the cleanliness of the recordings. O_K, transcription, uh, microphone issues - And then maybe ask, th- uh, these guys. The - we have great - great, uh, p- steps forward in terms of the nonspeech-speech pre-segmenting of the signal. O_K. Well, we have steps forward. Well, it's a - it's a big improvement. Yeah. Yes. I would prefer this. Yeah, well. O_K. Uh - We talk about the - the results of You have some - Yeah. O_K. I have a little bit of I_RAM stuff but I'm not sure if that's of general interest or not. use - Uh, bigram? I_RAM . I_RAM . I_RAM. Well, m- maybe. I_RAM, bigram, you know. Bi- Bigram. Yeah, let's - let's see where we are at three-thirty. Um - Hmm. Since, uh - since I have to leave as usual at three-thirty, can we do the interesting stuff first? I beg your pardon? Well - Yeah. What's the interesting stuff? Which is - ? I beg your pardon? Yeah. Th- now you get to tell us what's the interesting part. But - Yeah. Please specify. Yeah. Well, uh, I guess the work that's been done on segmentation would be most - Yeah. I think that would be a good thing to start with. O_K. Um, and, um, the other thing, uh, which I'll just say very briefly that maybe relates to that a little bit, which is that, um, uh, one of the suggestions that came up in a brief meeting I had the other day when I was in Spain with, uh, Manolo Pardo and Javier, uh, Ferreiros, who was here before, Yeah. was, um, why not start with what they had before but add in the non-silence boundaries. So, in what Javier did before when they were doing, um - h- he was looking for, uh, speaker change points. Mm-hmm. Um. As a simplification, he originally did this only using silence as, uh, a putative, uh, speaker change point. Yeah. And, uh, he did not, say, look at points where you were changing broad sp- uh, phonetic class, for instance. And for Broadcast News, that was fine. Here obviously it's not. Yeah. And, um, so one of the things that they were pushing in d- in discussing with me is, um, w- why are you spending so much time, uh, on the, uh, feature issue, uh, when perhaps if you sort of deal with what you were using before Uh-huh. and then just broadened it a bit, instead of just ta- using silence as putative change point also - ? So then you've got - you already have the super-structure with Gaussians and H_- you know, simple H_M_Ms and so forth. Nnn, yeah. And you - you might - So there was a - there was a little bit of a - a - a - a difference of opinion because I - I thought that it was - it's interesting to look at what features are useful. Yeah. But, uh, on the other hand I saw that the - they had a good point that, uh, if we had something that worked for many cases before, maybe starting from there a little bit - Because ultimately we're gonna end up with some s- su- kind of structure like that, where you have some kind of simple H_M_M and you're testing the hypothesis that, Yeah. Yeah. uh, there is a change. So - Yeah. so anyway, I just - reporting that. But, uh, uh - O_K. So. Yeah, why don't we do the speech-nonspeech discussion? Yeah. Do - I - I hear - you - you didn't - Speech-nonspeech? O_K. Uh-huh. Yeah. Um, so, uh, what we basically did so far was using the mixed file to - to detect s- speech or nonspeech portions in that. Mm-hmm. And what I did so far is I just used our old Munich system, which is an H_M_M-ba- based system with Gaussian mixtures for s- speech and nonspeech. And it was a system which used only one Gaussian for silence and one Gaussian for speech. And now I added, uh, multi-mixture possibility for - Mm-hmm. Mm-hmm. for speech and nonspeech. And I did some training on - on one dialogue, which was transcribed by - Jose. Yeah. We - we did a nons- s- speech-nonspeech transcription. Adam, Dave, and I, we did, for that dialogue and I trained it on that. And I did some pre-segmentations for - for Jane. And I'm not sure how good they are or what - what the transcribers say. They - they can use it or - ? Uh, they - they think it's a terrific improvement. And, um, it real- it just makes a - a world of difference. Hmm. And, um, y- you also did some- something in addition which was, um, for those in which there was, uh, quiet speakers in the mix. Yeah. Uh, yeah. That - that was one - one - one thing, uh, why I added more mixtures for - for the speech. So I saw that there were Mm-hmm. loud - loudly speaking speakers and quietly speaking speakers. And so I did two mixtures, one for the loud speakers and one for the quiet speakers. And did you hand-label who was loud and who was quiet, or did you just - ? I did that for - for five minutes of one dialogue and that was enough to - to train the system. And so it - it adapts, uh, on - Right. Yeah. W- What - ? while running. So. Hopefully. What kind of, uh, front-end processing did you do? O_K. It's just our - our old Munich, uh, loudness-based spectrum on mel scale twenty - twenty critical bands and then loudness. Mm-hmm. And four additional features, which is energy, loudness, modified loudness, and zero crossing rate. So it's twenty-four - twenty-four features. Mm-hmm. Mmm. And you also provided me with several different versions, which I compared. Yeah. Yeah. And so you change parameters. What - do you wanna say something about the parameters that you change? Yeah. You can specify the minimum length of speech or - and silence portions which you want. And so I did some - some modifications in those parameters, basically changing the minimum - minimum length for s- for silence to have, er- to have, um - yeah - to have more or less, uh, silence portions in- inserted. So. Right. So this would work well for, Yeah. uh, pauses and utterance boundaries and things like that. But for overlap I imagine that doesn't work at all, that you'll have plenty of s- sections that are - Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. That's it. Yeah. Mm-hmm, mm-hmm. That's true. But it - it saves so much time - the - the transcribers just enormous, enormous savings. Fantastic. Yeah. Um - But - Yep. That's great. Um, just qu- one quickly, uh, still on the features. So you have these twenty-four features. Uh, a lot of them are spectral features. Is there a - a transformation, uh, like principal components transformation or something? Just - Yeah. No. No. W- w- we - originally we did that Yeah. It was I_S two. but we saw, uh, when we used it, uh, f- for our close-talking microphone, which - yeah, for our - for our recognizer in Munich - we saw that w- it's - it's not - it's not so necessary. It - it works as well f- O_K. with - with - without, uh, a L_D_A or something. O_K. No, I was j- curious. Yeah, I don't think it's a big deal for this application, but - but - Yeah, it's a - Yeah. Mm-hmm. Yeah. Right. Mm-hmm. O_K. But then there's another thing that also Thilo's involved with, which is, um - O_K, and - and also Da- Dave Gelbart. So there's this - this problem of - and w- and - so we had this meeting. Th- the - also Adam, before the - the - before you went away. Uh we, um - regarding the representation of overlaps, because at present, um, because of the limitations of th- the interface we're using, overlaps are, uh, not being encoded by the transcribers in as complete and, uh, detailed a way as it might be, and as might be desired - I think would be desired in the corpus ultimately. Mm-hmm. So we don't have start and end points at each point where there's an overlap. We just have the - the overlaps encoded in a simple bin. Well, O_K. So @@ the limits of the over- of - of the interface are such that we were - at this meeting we were entertaining how we might either expand the - the interface or find other tools which already do what would be useful. Because what would ultimately be, um, ideal in my - my view and I think - I mean, I had the sense that it was consensus, is that, um, a thorough-going musical score notation would be the best way to go. Because you can have multiple channels, there's a single time-line, it's very clear, flexible, and all those nice things. Mm-hmm. O_K. So, um, um, I spoke - I had a meeting with Dave Gelbart on - on - and he had, uh, excellent ideas on how the interface could be modified to - to do this kind of representation. But, um, he - in the meantime you were checking into the existence of already, um, existing interfaces which might already have these properties. So, do you wanna say something about that? Yes. Um, I talked with, uh, Munich guys from - from Ludwi- Ludwig Maximilians University, who do a lot of transcribing and transliterations. Mm-hmm. And they basically said they have - they have, uh, a tool they developed themselves and they can't give away, uh, f- it's too error-prone, and had - it's not supported, a- a- a- and - Yeah. But, um, Susanne Bur- Burger, who is at se- C_M_U, he wa- who was formally at - in Munich and w- and is now at - with C_M_U, she said she has something which she uses to do eight channels, uh, trans- transliterations, eight channels simultaneously, Excuse me. but it's running under Windows. Under Windows. Mm-hmm. So I'm not sure if - if - if we can use it. She said she would give it to us. It wouldn't be a problem. Mm-hmm. And I've got some - some kind of manual down in my office. Well, maybe we should get it and if it's good enough Yeah. we'll arrange Windows machines to be available. Mm-hmm. We could - uh, potentially so. I also wanted to be sure - So. I mean, I've - I've seen the - this - this is called Praat, P_R_A_A_T, which I guess means spee- speech in Dutch or something. Yep. Yeah, but then I'm not sure that's the right thing for us. But - In terms of it being Windows versus - But I'm just wondering, is - ? Yeah. No, no. Praat isn't - Praat's multi-platform. No. No, Praat - Yeah. Yeah. Oh! I see. Oh, I see. So Praat may not be - Yeah. That's not Praat. It's called "trans- transedit" I think. The - the, uh - the tool from - from Susanne. It's a different one. I see. Oh, I see. O_K. O_K. Alright. The other thing, uh, to keep in mind, uh - I mean, we've been very concerned to get all this rolling so that we would actually have data, Mmm, yeah. but, um, I think our outside sponsor is actually gonna kick in and ultimately that path will be smoothed out. So I don't know Mm-hmm. if we have a long-term need to do lots and lots of transcribing. I think we had a very quick need to get something out and we'd like to be able to do some later because just it's inter- it's interesting. But as far a- you know, uh, with - with any luck we'll be able to wind down the larger project. Oh. But you s- What our decision was is that we'll go ahead with what we have with a not very fine time scale on the overlaps. Yeah. Right. Yeah. And - and do what we can later to clean that up if we need to. Mm-hmm. Right. And - and I was just thinking that, um, if it were possible to bring that in, like, you know, this week, then when they're encoding the overlaps Uh-huh. it would be nice for them to be able to specify when - you know, the start points and end points of overlaps. uh Th- they're making really quick progress. Yeah. That's great. And, um, so my - my goal was - w- m- my charge was to get eleven hours by the end of the month. And it'll be - I'm - I'm - I'm clear that we'll be able to do that. That's great. Yeah. And did you, uh, forward Morgan Brian's thing? I sent it to, um - who did I send that to? I sent it to a list and I thought I sent it to the - e- to the local list. You saw that? Meeting Recorder. Oh, you did? O_K. So you probably did get that. So Brian did tell me that in fact what you said, that, uh - that our - that they are making progress and that he's going - that they're going - he's gonna check the f- the output of the first transcription and - I mean, basically it's - it's all the difference in the world. I mean, basically he's - he's on it now. and - Yeah. Oh, that's - this is a new development. O_K. So - so - so this is - so i- it'll happen. Super. Super. O_K. Great. Yeah. I mean, basically it's just saying that one of our - one of our best people is on it, you know, who just doesn't happen to be here anymore. Someone else pays him. So - So. Yeah. Isn't that great? But about the need for transcription, I mean, don't we - didn't we previously Yeah. decide that the I_B_M transcripts would have to be checked anyway and possibly augmented? Yes. That's true. Mm-hmm. So, I think having a good tool is worth something no matter what. Yeah. S- O_K. That's - that's a good point. Yeah, and Dave Gelbart did volunteer, and since he's not here, I'll repeat it - Good. to at least modify Transcriber, which, if we don't have something else that works, I think that's a pretty good way of going. Mmm. Mm-hmm. And we discussed on some methods to do it. My approach originally, and I've already hacked on it a little bit - it was too slow because I was trying to display all the waveforms. But he pointed out that you don't really have to. I think that's a good point. Mm-hmm. Mm-hmm. Hmm. That if you just display the mix waveform and then have a user interface for editing the different channels, that's perfectly sufficient. Yeah, exactly. And just keep those things separate. And - and, um, Dan Ellis's hack already allows them to be able to display different waveforms to clarify overlaps and things, so that's already - No. They can only display one, but they can listen to different ones. Oh, yes, but - Well, uh, yes, but what I mean is that, uh, from the transcriber's perspective, uh, those two functions are separate. And Dan Ellis's hack handles the, um, choice - the ability to choose different waveforms from moment to moment. But only to listen to, not to look at. Um - Yeah. The waveform you're looking at doesn't change. Yeah. That's true. Yeah, but that's - that's O_K, cuz they're - they're, Yeah. you know, they're focused on the ear anyway. And then - and then Right. Hmm. the hack to preserve the overlaps better would be one which creates different output files for each channel, which then would also serve Liz's request of having, Right. you know, a single channel, separable, uh, cleanly, Mm-hmm. easily separable, uh, transcript tied to a single channel, uh, audio. Mm-hmm. Have, uh, folks from NIST been in contact with you? Not directly. I'm trying to think if - if I could have gotten it over a list. I don't - I don't think so. O_K. O_K. Well, holidays may have interrupted things, cuz in - in - in - They seem to want to get absolutely clear on standards for - transcription standards and so forth with - with us. Oh! This was from before December. Yeah. Right. Because they're - they're presumably going to start recording next month. O_K. O_K. Oh, we should definitely get with them then, and So. agree upon a format. Though I don't remember email on that. So was I not in the loop on that? Um. Yeah, I don't think I mailed anybody. I just think I told them to contact Jane - that, uh, if they had a - Oh, O_K. That's right. if, uh - that - that, uh, as the point person on it. But - Yeah, I think that's right. Just, uh - So, yeah. Maybe I'll, uh, ping them a little bit about it to O_K. I'm keeping the conventions absolutely as simple as possible. get that straight. Yeah. So is it - cuz with any luck there'll actually be a - a - there'll be collections at Columbia, collections at - at U_W - I mean Dan - Dan is very interested in doing some other things, Right. Yeah. Yeah. Well, I think it's important both and collections at NIST. So - for the notation and the machine representation to be the same. Yeah. So. N- there was also this, uh, email from Dan regarding the speech-non- nonspeech segmentation thing. Yep. Yeah. Yeah. I don't know if, uh, uh, we wanna, uh - and Dan Gel- and Dave Gelbart is interested in pursuing the aspect of using amplitude as a - a - a - as a basis for the separation. Oh, yeah. He was talking - he was talking - I mean, uh, we - he had - @@ Cross-correlation. Cross- Yeah, cross-correlation. I had mentioned this a couple times before, the c- the commercial devices that do, uh, Cross- Uh-huh. uh, voice, uh - you know, active miking, basically look at the amp- at the energy at each of the mikes. And - and you basically compare the energy here to some function of all of the mikes. So, Yeah. O_K. Yeah. by doing that, you know, rather than setting any, uh, absolute threshold, you actually can do pretty good, uh, selection of who - who's talking. Uh - O_K. And those - those systems work very well, by the way, I mean, so people use them in panel discussions and so forth with sound reinforcement differing in - in sort of, uh - Uh-huh. and, uh, those - if - Boy, the guy I knew who built them, built them like twenty - twenty years ago, so they're - it's - the - the techniques work pretty well. Hmm. Fantastic. So. Cuz there is one thing that we don't have right now and that is the automatic, um, channel identifier. Mm-hmm. That - that, you know, that would g- help in terms of encoding of overlaps. The - the transcribers would have less, uh, disentangling to do if that were available. Yeah. So I think, you know, basically you can But. look at some - p- you have to play around a little bit, uh, to figure out what the right statistic is, but you compare each microphone to some statistic based on the - Mm-hmm. Mm-hmm. on the overall - Yeah. Mm-hmm. O_K. Uh, and we also have these - we have the advantage of having distant mikes too. So that, you cou- yo- Yeah, although the - the - using the close-talking I think would be much better. Wouldn't it? Um. Yeah. I - I don't know. I just - it'd be - Yeah. If I was actually working on it, I'd sit there and - and play around with it, and - and get a feeling for it. I mean, the - the - the, uh - But, uh, you certainly wanna use the close-talking, as a - at least. Right. I don't know if the other would - would add some other helpful dimension or not. Mm-hmm. Mm-hmm. O_K. What - what are the different, uh, classes to - to code, uh, the - the overlap, you will use? Um, to code d- so types of overlap? What you - you - Yeah. Um, so at a meeting that wasn't transcribed, we worked up a - a typology. And, um - Yeah. Look like, uh, you t- you explaining in the blackboard? The - ? Yeah? Yeah. Yes, exactly. That hasn't changed. So it i- the - it's basically a two-tiered structure where the first one is whether the person who's interrupted continues or not. And then below that there're subcategories, uh, that have more to do with, you know, is it, Mm-hmm. uh, simply backchannel or is it, um, someone completing someone else's thought, or is it someone in- introducing a new thought. Right. Huh. And I hope that if we do a forced alignment with the close-talking mike, that will be enough to recover Yeah. at least some of the time the time information of when the overlap occurred. Mm-hmm. Well, one would - Yeah. We hope. Yeah. Who knows? That'd be - that'd be nice. I mean, I - I - I - I've - So who's gonna do that? Who's gonna do forced alignment? Well, u- uh, I_B_M was going to. Um - Oh, O_K. Oh. and I imagine they still plan to but - but, you know, I haven't spoken with them about that recently. O_K. Uh-huh. Well, uh, my suggestion now is - is on all of these things to, uh, contact Brian. This is wonderful to have a direct contact like that. O_K. I'll do that. Yeah. Yeah. uh Well, th- lemme ask you this. It occurs to me - Yeah. one of my transcribers t- told me today that she'll be finished with one meeting, Mm-hmm. um, by - well, she said tomorrow but then she said - you know, but - the, you know - let's - let's just, uh, say Mm-hmm. maybe the day after just to be s- on the safe side. I could send Brian the, um - the transcript. I know these are - er, uh, I could send him that if it would be possible, or a good idea or not, to try to do a s- forced alignment on what we're - on the way we're encoding overlaps now. Well, just talk to him about it. Yep. Good. I mean, you know, basically he's - he just studies, he's a colleague, a friend, and, Yeah! Super. Super. uh, they - and - and, you know, the - the organization always did wanna help us. It was just a question of getting, you know, the right people connected in, who had the time. So, Yeah, yeah. Right. um, eh - Is he on the mailing list? The Meeting Recorder mailing li- ? We should add him. Oh! Yeah. Yeah. I - I - I don't know for sure. Did something happen, Morgan, that he got put on this, or was he already on it, or - ? Add him. No, I, eh, eh, p- It - it oc- I - h- it's - Yeah, something happened. I don't know what. But he's on it now. He asked for more work. Huh. That would be like - that'd be like him. He's great. Right. So, uh, where are we? Maybe, uh, uh, brief - Well, let's - why don't we talk about microphone issues? That was - that was a - Yeah. That'd be great. Um, so one thing is that I did look on Sony's for a replacement for the mikes - for the head m- head-worn ones cuz they're so uncomfortable. @@ But I think I need someone who knows more about mikes than I do, because I couldn't find a single other model that seemed like it would fit the connector, which seems really unlikely to me. Does anyone, like, know stores or know about mikes who - who would know the right questions to ask? Oh, I probably would. I mean, my knowledge is twenty years out of date but some of it's still the same. So - Mm-hmm. Uh, so maybe we c- we can take a look at that. You couldn't - you couldn't find the right connector to go into these things? Yep. Huh! When I looked, i- they listed one microphone and that's it as having that type of connector. But my guess is that Sony maybe uses a different number for their connector than everyone else does. And - and so - Mm-hmm. Well, let's look at it together and - it seems - it seems really unlikely to me that there's only one. And there's no adaptor for it? Seems like there'd be a - O_K. Yeah. As I said, who knows? Mm-hmm. Who - who are we buying these from? That'd be a - Um, I have it downstairs. I don't remember off the top of my head. Yeah. O_K. Yeah. We - we can try and look at that together. And then, uh - just in terms of how you wear them - I mean, I had thought about this before. I mean, when - when - when you use a product like DragonDictate, they have a very extensive description about how to wear the microphone and so on. Oh. But I felt that in a real situation we were very seldom gonna get people to really do it and maybe it wasn't worth concentrating on. But - Well, I think that that's - that's a good back-off position. That's what I was saying earlier, th- that, you know, we are gonna get some recordings that are imperfect and, hey, that's life. But I - I think that it - it doesn't hurt, uh, the naturalness of the situation to try to have people wear the microphones properly, if possible, because, Mm-hmm. um, the natural situation is really what we have with the microphones on the table. I mean, I think, Oh. That's true. you know, in the target applications that we're talking about, people aren't gonna be wearing head-mounted mikes anyway. So this is just for u- these head-mounted mikes are just for use with research. Yeah. Yeah. Mm-hmm. And, uh, it's gonna make - Yeah. @@ You know, if - if An- Andreas plays around with language modeling, he's not gonna be m- wanna be messed up by people breathing into the microphone. So it's - it's, uh, uh - Right. Well, I'll dig through the documentation to DragonDictate and ste- s- see if they still have the little form. But it does happen. Right? I mean, and any - Yeah. It's interesting, uh, I talked to some I_B_M guys, uh, last January, I think, I was there. And - so people who were working on the - on their ViaVoice Yeah. dictation product. And they said, uh, the breathing is really a - a terrible problem for them, to - to not recognize breathing as speech. Wow. So, anything to reduce breathing is - Yeah. Well, that's the - is - is a good thing. It seemed to me when I was using Dragon Mm-hmm. that it was really microphone placement helped an - in, uh - an enormous amount. So you want it Right. enough to the side so that when you exhale through your nose, it doesn't - the wind doesn't hit the mike. Mm-hmm. And then, uh - Everyone's adjusting their microphones, of course. And then just close enough so that you get good volume. So you know, wearing it right about here Yeah. Yeah. seems to be about the right way to do it. Is - Uh-huh. I remember when I was - when I - I - I - I used, uh, um, a prominent laboratory's, uh, uh, speech recognizer about, uh - This was, boy, this was a while ago, this was about twelve - twelve years ago or something. And, um, they were - they were perturbed with me because I was breathing in instead of breathing out. And they had models for - they - they had Markov models for br- breathing out but they didn't have them for breathing in. Uh - Yeah. That's interesting. Well, what I wondered is whether it's possible to have - to maybe use the display at the beginning to be able to - to judge how - how correctly - I mean, have someone do some routine whatever, Yeah. and - and then see if when they're breathing it's showing. I don't know if the - if it's - I - I mean, when - when it's on, you can see it. You can definitely see it. Absolutely. Absolutely. Can you see the breathing? Cuz I - Oh. Yeah. I- And so, you know, I've - I've sat here and watched sometimes the breathing, and the bar going up and down, and I'm thinking, I could say something, but I mean, I think - I don't want to make people self-conscious. Stop breathing! It - it's going to be imperfect. You're not gonna get it perfect. Yeah. Uh-huh. And you can do some, uh, you know, first-order thing about it, which is to have people move it, uh, uh, a- away from being just directly in front of the middle Yeah. Good. but not too far away. Yeah, i- And then, you know, I think there's not much - Because you can't al- you know, interfere w- you can't fine tune the meeting that much, I think. It's sort of - Right. Yeah. That's true. It just seems like i- if something l- simple like that can be tweaked and the quality goes, you know, uh, dramatically Yep. up, then it might be worth doing. And then also - the position of the mike also. If it's more directly, you'll get better volume. Yeah. So - so, like, yours is pretty far down below your mouth. Yeah. But - Mm-hmm. Yeah. My - my feedback from the transcribers is he is always close to crystal clear and - and just fan- fantastic to - Yeah. Mmm, yeah. Mm-hmm. I don't know why that is. Well, I mean, you - Yeah, of course. You're - you're also - uh, your volume is - is greater. But - but still, I mean, they - they say - I've been eating a lot. Uh. I- it makes their - their job extremely easy. Yeah. And then there's mass. Anyway. Mm-hmm. I could say something about - about the - Well, I don't know what you wanna do. Yeah. About what? About the transcribers or anything or - ? I don't know. Well, the other - why don't we do that? But, uh, just to - to, um - One more remark, uh, concerning the S_R_I recognizer. Um. It is useful to transcribe and then ultimately train models for things like breath, and also laughter is very, very frequent and important to - Mm-hmm. to model. So, So, if you can in your transcripts mark - mark them? mark very audible breaths and laughter especially, um - O_K. Mmm. They are. They're putting - Eh, so in curly brackets they put "inhale" or "breath". Mm-hmm. It - they - and then in curly brackets they say "laughter". Now they're - Oh, great. they're not being awfully precise, uh, m- So they're two types of laughter that are not being distinguished. One is Mm-hmm. when sometimes s- someone will start laughing when they're in the middle of a sentence. Mm-hmm. And - and then the other one is when they finish the sentence and then they laugh. So, um, I - I did s- I did some double checking to look through - I mean, you'd need to have extra hhh e- extra complications, like time tags indicating the beginning and ending of - of the laughing through the utterance. And that - and what they're doing is in both cases just saying "curly brackets laughing" a- after the unit. It's not so - I don't think it's, um - As - as long as there is an indication that there was laughter somewhere between two words Yeah. Good. Oh! O_K. I think that's sufficient, because Against - they could do forced alignment. actually the recognition of laughter once you kn- um - Yeah. you know, is pretty good. So as long as you can stick a - Oh, I didn't know that. you know, a t- a tag in there that - that indicates that there was laughter, O_K. that would probably be, uh, sufficient to train models. Then - That would be a really interesting prosodic feature, when - And let me ask y- and I gotta ask you one thing about that. So, um, Yeah. Hmm. if they laugh between two words, you - you'd get it Mm-hmm. in between the two words. But if they laugh across three or four words you - you get it after those four words. Does that matter? Right. Yeah. Well, the thing that you - is hard to deal with is whe- when they speak while laughing. Yeah. Um, and that's, uh - I don't think that we can do very well with that. So - Right. Yeah. But, um, that's not as frequent as just laughing between O_K. speaking, so - Uh is it? So are - do you treat breath and laughter as I think he's right. Yeah. Huh. I - I think it's frequent in - in the meeting. phonetically, or as word models, or what? We tried both. Uh, currently, um, we use special words. There was a - there's actually a word for - uh, it's not just breathing but all kinds of mouth - uh, mouth - mouth stuff. Mm-hmm. Mouth stuff? And then laughter is a - is a special word. How would we do that with the hybrid system? @@ Same thing. Same thing? So train a phone in the neural net? Yeah. Yeah. You ha- Oh. And each of these words has a dedicated phone. No - Oh, it does? So the - so the - the mouth noise, uh, word has just a single phone, um, that is for that. Right. So in the hybrid system we could train the net with Yeah. a laughter phone and a breath sound phone. Yeah. Yeah. I mean, it's - it's - it's always the same thing. Right? I mean, you could - you could say well, let - Mm-hmm. @@ we now think that laughter should have three sub- sub- sub-units in the - the three states, uh - different states. And then you would have three - I mean, you know, eh, eh, it's u- Yeah. And the - the pronun- the pronunciations - the pronunciations are l- are somewhat non-standard. They actually are - Do whatever you want. Yeah. Yeah. Yeah, yeah. No. uh, it's just a single, s- uh, you know, a single phone in the pronunciation, but it has a self-loop on it, so it can - To go on forever? r- can go on forever. And how do you handle it in the language model? It's just a - it's just a word. We train it like any other word. Yeah. It's just a word in the language model. Cool. We also tried, um, absorbing these - uh, both laughter and - and actually also noise, and, um - Sorry to interrupt. Yeah. Is - If you want, I got it. Andreas. Yes. The copies are ready . O_K. Anyway. We also tried absorbing that into the pause model - I mean, the - the - the model that - Mm-hmm. that matches the stuff between words. And, um, it didn't work as well. So. Huh. O_K. Mm-hmm. Can you hand me your digit form? Sorry. I just wanna mark that you did not read digits. O_K. Say hi for me. Good. You - you did get me to thinking about - I - I'm not really sure which is more frequent, whether f- f- laughing - I think it may be an individual thing. Some people are more prone to laughing when they're speaking. Yeah. Yeah. I think - I was noticing that with Dan in the one that we, uh - But I can't - Yeah. we hand tran- hand-segmented, that - th- he has these little chuckles as he talks. I'm sure it's very individual. And - and - Yeah. O_K. one thing that c- that we're not doing, of course, is we're not claiming to, uh, get - be getting a representation of mankind in these recordings. We have this very, very tiny sample of - of - Yeah. Yeah. Yeah. Speech researchers? Uh, yeah. And - Yeah, r- right. So, uh, who knows. Speech research. Uh - Yeah. Why don- why don't we just - since we're on this vein, why don't we just continue with, uh, what you were gonna say about the transcriptions and - ? O_K. Um, um, the - I - I'm really very for- I'm extremely fortunate with the people who, uh, applied and who are transcribing for us. They are, um, um, uh really perceptive and very, um - and I'm not just saying that cuz they might be hearing this. Cuz they're gonna be transcribing it in a few days. No, they're super. They're - the- they - very quick. O_K. Turn the mikes off and let's talk. Yeah, I know. I am - I'm serious. They're just super. So I, um, e- you know, I - I brought them in and, um, trained them in pairs because I think people can raise questions - you know, i- i- the- they think about different things and they think of different - and um, That's a good idea. I trained them to, uh, f- on about a minute or two of the one that was already transcribed. This also gives me a sense of - You know, I can - I can use that later, with reference to inter-coder reliability kind of issues. But the main thing was to get them used to the conventions and, you know, the idea of the - th- th- the size of the unit versus how long it takes to play it back so these - th- sort of calibration issues. And then, um, I just set them loose and they're - they all have e- a- already background in using computers. They're, um - they're trained in linguistics. They got - Good. Uh-huh. Oh, no. Is that good or bad? Well, they- they're very perce- they'll - So one of them said "well, you know, he really said " n ", not really " and ", Yeah. Yeah. so what - what should I do with that?" And I said, "well for our purposes, Yeah. Yeah. I do have a convention. If it's an - a noncanonical p-" That one, I think we - you know, with Eric's work, I sort of figure we - we can just treat that as a variant. O_K. But I told them if - if there's an obvious speech error, Yes. uh, like I said in one thing, and I gave my - my example, like I said, "microfon" in- instead of "microphone". Didn't bother - I knew it when I said it. I remember s- thinking "oh, that's not correctly pronounced". But it - but I thought it's not worth fixing cuz often when you're speaking everybody knows what - what you mean. You'll self-repair. Yeah. Yeah. But I have a convention that if it's obviously a noncanonical pronunciation - a speech error with - you know, wi- within the realm of resolution that you can tell in this native English - American English speaker, you know that I didn't mean to say "microfon." Then you'd put a little tick at the beginning of the word, and that just signals that, um, this is not standard, and then in curly brackets "pron error". Yeah. And, um, and other than that, it's w- word level. But, you know, the fact that they noticed, you know, the " nnn ". "He said " nnn ", not " and ". What shall I do with that?" I mean, they're very perceptive. And - and s- several of them are trained in I_P_A. C- they really could do phonetic transcription if - if we wanted them to. Mm-hmm. Right. Well - But - Hmm. Where were they when we needed them? Well, you know, it might be something we'd wanna do with some, uh, s- small subset of the whole thing. I think - We certainly wouldn't wanna do it with everything. And I'm also thinking these people are a terrific pool. I mean, if, uh - so I - I told them that, um, we don't know if this will continue past the end of the month and I also - Uh-huh. m- I think they know that the data p- source is limited and I may not be able to keep them employed till the end of the month even, although I hope to. The other thing we could do, actually, uh, is, And - uh, use them for a more detailed analysis of the overlaps. Oh, that'd be so super. They would be so - s- so terrific. Right? I mean, this was something that we were talking about. We could get a very detailed overlap if they were willing to transcribe each meeting four or five times. Right? One for each participant. So they could by hand - Well, that's one way to do it. But I've been saying the other thing is just go through it for the overlaps. Right? Yeah. Yeah. Mm-hmm, that's right. And with the right in- interface - Given that y- and - and do - so instead of doing phonetic, uh, uh, transcription for the whole thing, which Yeah. we know from the - Steve's experience with the Switchboard transcription is, you know, very, very time-consuming. And - and you know, it took them I don't know how many months to do - to get four hours. And so that hasn't been really our focus. Uh, we can consider it. But, I mean, the other thing is since we've been spending so much time thinking about overlaps is - is maybe get a much more detailed analysis of the overlaps. Yeah. Mm-hmm. But anyway, I'm - I'm open to c- our consideration. That'd be great. I - I don't wanna say that by fiat. I'm open to every consideration of Hmm. Yeah. what are some other kinds of detailed analysis that would be most useful. And, uh, uh, Mm-hmm. Hmm. I - I - I think this year we - we actually, uh, can do it. Oh, wonderful. It's a - we have - we have - due to @@ variations in funding we have - we seem to be doing, uh, very well on m- money for this - this year, and next year we may have - have much less. So I don't wanna hire a - Is - you mean two thousand one? Calendar year or - ? Uh, I mean, calendar year two thousand one. O_K. Yeah. So it's - uh, it's - we don't wanna hire a bunch of people, a long-term staff, because Full-time. Yeah. Mm-hmm. Yeah. the - the funding that we've gotten is sort of a big chunk for this year. But having temporary people doing some specific thing that we need is actually a perfect match to that kind of, uh, funding. So. Wonderful. And then school will start in - in the sixt- on the sixteenth. Some of them will have to cut back their hours at that point. But - Yeah. Yeah. Are they working full-time now, or - ? Some of them are. Yeah. Wow. Well, why do- I wouldn't say forty-hour weeks. No. But what I mean is - Oh, I shouldn't say it that way because that does sound like forty-hour weeks. No. I th- I - I would say they're probably - they don't have o- they don't have other things that are taking away their time. I don't see how someone could do forty hours a week on transcription. Hmm. But it's - you can't. Yeah. Yeah. No. You're right. It's - i- it would be too taxing. But, um, they're putting in a lot of - Yeah. And - and I checked them over. I - I - I haven't checked them all, but just spot-checking. They're fantastic. I - I remember when we were transcribing BeRP, uh, uh, I think it would be - uh, Ron Kay, uh, volunteered to - to do some of that. And, he was - the first - first stuff he did was transcribing Chuck. And he's saying "You - you know, I always thought Chuck spoke really well. " Yeah. Yeah. Well, you know, and I also thought, y- Liz has this, eh, you know, and I do also, this - this interest in the types of overlaps that are involved. These people would be great choices for doing coding of that type if we wanted, or We'd have to mark them. Mm-hmm. whatever. So, um. Mm-hmm. Yeah. I think it would also be interesting to have, uh, a couple of the meetings have more than one transcriber do, Mm-hmm. cuz I'm curious about inter-annotator agreement. Yeah. O_K. Yeah. Th- that'd be - Yeah. I think that's a - a good idea. You know, there's also, the e- In my mind, I think A- An- Andreas was leading to this topic, the idea that, um, we haven't yet seen the - the type of transcript that we get from I_B_M, and it may just be, you know, pristine. But on the other hand, given the lesser interface - Cuz this is, you know - we've got a good interface, we've got great headphones, m- um - It could be that they will uh - theirs will end up being a kind of fir- first pass or something. Something like that. Maybe an elaborate one, cuz again they probably are gonna do these alignments, which will also That's - that's true. Al- although you have to s- Don't you have to start with a close enough approximation of the - clear things up. of the verbal part to be able to - ? Well, tha- that's - that's debatable. Right? I mean, so the - so the argument is that if your statistical system is good O_K. it will in fact, uh, clean things up. Right? So it- it's got its own objective criterion. O_K. Yeah. And, uh, so in principle you could start up with something that was kind of rough - I mean, to give an example of, um, something we used to do, uh, at one point, uh, back - back when Chuck was here in early times, is we would take, um, da- take a word and, uh, have a canonical pronunciation and, uh, if there was five phones in a word, you'd break up the word, uh, into five equal-length pieces which is completely gross. Wrong. Yeah. Right? I mean, th- the timing is off all over the place in just about any word. Yeah. Mm-hmm. O_K. But it's O_ K. You start off with that and the statistical system then aligns things, and eventually you get something that doesn't really look too bad. Oh, excellent. O_K. So - so I think using a - a good aligner, um, actually can - can help a lot. Um. But, uh, you know, they both help each other. If you have a - if you have a better starting point, then it helps the aligner. If you have a good alignment, it helps the, uh, th- the human in - in taking less time to correct things. So - so - O_K. Excellent. I guess there's another aspect, too, and I don't know - uh, this - this is - very possibly a different, uh, topic. But, uh, just let me say with reference to this idea of, um, higher-order organization within meetings. So like in a - you know, the topics that are covered during a meeting with reference to the other, uh, Mm-hmm. uses of the data, so being able to find where so-and-so talked about such-and-such, then, um, um - e- I mean, I - I - I did sort of a - a rough pass on encoding, like, episode-like level Mm-hmm. things on the, uh, transcribed meeting - already transcribed meeting. Mm-hmm. And I don't know if, um - where that - i- if that's something that we wanna do with each meeting, sort of like a, um - it's like a manifest, when you get a box full of stuff, or - or if that's, um - Mm-hmm. I mean, i- I - I don't know what uh, level of detail would be most useful. I don't know i- if that's something that I should do when I look over it, or if we want someone else to do, or whatever. Mm-hmm. But this issue of the contents of the meeting in an outline form. O_K. Yeah. Meaning really isn't my thing. Um - I think it just - whoever is interested can do that. I mean, so if someone wants to use that data - O_K. We're running a little short here. We, uh, uh, cou- trying to - That's fine. I'm finished. eh, was - p- Well, you know, the thing I'm concerned about is we wanted to do these digits and - and I haven't heard, uh, from Jose yet. So - Oh, yeah. Oh, yes. Mm-hmm. O_K. What do you want? Uh - We could skip the digits. We don't have to read digits each time. Uh - I - I - I think it - you know, another - another bunch of digits. More data is good. O_K. Yeah. Sure. So - so I'd like to do that. But I think, do you, maybe, eh - ? Did you prepare some whole thing you wanted us just to see? Or what was that? Yeah. It's - it's prepared. Yeah. Uh, how long a - ? Oh, k- Sorry. I - I think it's - it's fast, because, uh, I have the results, eh, of the study of different energy without the law length . Eh, um, eh, @@ in the - in the measurement, uh, the average, uh, dividing by the - by the, um, variance. Yeah. Um, I - th- i- the other, uh - the - the last w- uh, meeting - eh, I don't know if you remain - we have problem to - with the - with - with the parameter - with the representations of parameter, Yes. because the - the valleys and the peaks in the signal, eh, look like, eh, it doesn't follow to the - to the energy in the signal. Right. And it was a problem, uh, with the scale. Eh, the scale. With what? Scale. Scale. Eh, and I - I change the scale and we can see the - the variance. O_K. But the bottom line is it's still not, uh, separating out very well. Right? O_K. Yeah. Yeah. The distribution - the distribution is - is similar. So that's - that's - that's enough then. O_K. Yeah. No, I mean, that there's no point in going through all of that if that's the bottom line, really. So, I - I think we have to start - Yeah. Yeah. Mm-hmm. Uh, I mean, there- there's two suggestions, really, which is, uh - what we said before is that, Mmm, yeah. um, it looks like, @@ at least that you haven't found an obvious way to normalize so that the energy is anything like a reliable, uh, indicator of the overlap. Yeah. Um, I - I'm - I'm still a little f- think that's a little funny. These things l- @@ seems like there should be, but - Yeah. Yeah. but you don't want to keep, uh - keep knocking at it if it's - if you're not getting any - any result with that. But, I mean, the other things that we talked about is, uh, pitch-related things and harmonicity-related things, so - which we thought also should be some kind of a reasonable indicator. Yeah. Um - But, uh, a completely different tack on it wou- is the one that was suggested, uh, by your colleagues in Spain, Yeah. which is to say, don't worry so much about the, uh, features. Yeah. That is to say, use, you know, as - as you're doing with the speech, uh, nonspeech, use some very general features. Yeah. And, uh, then, uh, look at it more from the aspect of modeling. Yeah. You know, have a - have a couple Markov models and - Yeah. Yeah. and, uh, try to indi- try to determine, you know, w- when is th- when are you in an overlap, when are you not in an overlap. Hmm. And let the, uh, uh, statistical system determine what's the right way to look at the data. I - I, um, Yeah. I think it would be interesting to find individual features and put them together. I think that you'd end up with a better system overall. But given the limitation in time Yeah. and given the fact that Javier's system already exists doing this sort of thing, Yeah. uh, but, uh, its main limitation is that, again, it's only looking at silences which would - Yeah. Yeah. maybe that's a better place to go. Yeah. So. Mm-hmm. I - I - I think that, eh, the possibility, eh, can be that, eh, Thilo, eh, working, eh, with a new class, Mm-hmm. not only, eh, nonspeech and speech, but, eh, in - in - in the speech class, Mm-hmm. dividing, eh, speech, eh, of - from a speaker and overlapping, to try - to - to do, eh, eh, a fast - a fast, eh, experiment to - to prove that, nnn, this fea- eh, general feature, Yeah. eh, can solve the - the - the problem, and wh- what - Maybe. Yeah. nnn, how far is - And, I - I have prepared the - the pitch tracker now. Mm-hmm. And I hope the - the next week I will have, eh, some results and we - we will show - we will see, eh, the - the parameter - the pitch, I see. eh, tracking in - with the program. Ha- h- have you ever looked at the, uh, uh - Javier's, uh, And, nnn, nnn - speech segmenter? No. Oh. Maybe m- you could, you kn- uh show Thilo that. No. No. Yeah. Yeah. Yeah. Sure. Cuz again the idea is there - the limitation there again was that he was - he was only using it to look at silence as a - as a - as a - as a p- putative I - Yeah. split point between speakers. But if you included, uh, O_K. broadened classes then in principle maybe you can cover the overlap cases. Yeah. Mmm, yeah. Yeah, but I'm not too sure if - if we can really represent Uh - overlap with - with the s- detector I - I - I used up to now, the - to speech-nonspeech as - Mm-hmm. I think with - Ah. it's only speech or it's - it's - it's nonspeech. So. That's right. But I think Javier's - Yeah. Mm-hmm. N- n- I think Javier's might be able to. It doesn't have the same Gaus- uh, H_M_ M modeling, which is I think a drawback. Yeah. O_K. But, uh - Well, it's - sort of has a Mmm, yeah. simple one. Right? It's - Does it? it's just - it's just a - isn't it just a Gaussian for each - ? Yeah. Yeah. Hmm. Mm-hmm. Yeah. And then he ch- you choose optimal splitting. Oh, it doesn't have - it doesn't have any temporal, uh - ? I thought it - @@ Maybe I'm misremembering, but I did not think it had a Markov - Yeah. I gues- I guess I don't remember either. Uh. It's been a while. Javier - Uh. Yeah. Uh, I could have a look at it. So. You mean Ja- eh, eh, Javier program? No, Javier di- doesn't worked with, uh, a Markov - Mm-hmm. Yeah, I didn't think so. Oh, O_K . So he's just - he just computes a Gaussian over potential - Oh, I see. I see. And - and - He on- only train - Yep. Yeah. It was only Gaussian. This is the idea. And so I - I think it would work fine for detecting overlap. It's just, uh, that i- it - he has the two-pass issue that - What he does is, as a first pass he - he - p- he does, um, a guess at where the divisions might be and he overestimates. And that's just a data reduction step, so that you're not trying at every time interval. O_K. And so those are the putative places where he tries. Yeah. Yeah. O_K. And right now he's doing that with silence and that doesn't work with the Meeting Recorder. Yeah. So if we used another method to get the first pass, I think it would probably work. It's a good method. Yeah. Sure. Yeah. Yeah, O_K. As long as the len- as long the segments are long enough. Yeah. O_k- O_K. So let me go back to what you had, though. Um. That's the other problem. So - Yeah. Mm-hmm. The other thing one could do is - Couldn't - I mean, it's - So you have two categories and you have Markov models for each. Yeah. Couldn't you have a third category? So you have, uh - you have, uh, nonspeech, single-person speech, and multiple-person speech? He has this on his board actually. Don't you have, like those - those several different categories on the board? Right? And then you have a Markov model for each? Um - I'm not sure. I - I thought about, uh, adding, uh, uh, another class too. But it's not too easy, I think, the - the transition between the different class, to model them in - in the system I have now. But it - it - it could be possible, I think, I see. I see. in principle. Yeah, I mean, I - @@ This is all pretty gross. I mean, the - th- the reason why, uh, I was suggesting originally that we look at features is because I thought, well, we're doing something we haven't done before, @@ Yeah. Yeah. we should at least look at the space and understand - Yeah. Yeah. It seems like if two people - two or more people talk at once, it should get louder, Yeah. uh, and, uh, uh, there should be some discontinuity in pitch contours, I had the impression. Yeah. and, uh, there should overall be a, um, smaller proportion of the total energy that is explained by any particular harmonic sequence in the spectrum. Yeah. Yeah. Right. So those are all things that should be there. So far, Mm-hmm. Yeah. um, uh, Jose has - has been - By the way, I was told I should be calling you Pepe, but - by your friends, but- Yeah. Oh. Anyway, um, Yeah . uh, the - has - has, uh, been exploring, uh, e- largely the energy issue and, um, as with a lot of things, it is not - uh, like this, it's not as simple as it sounds. And then there's, you know - Is it energy? Is it log energy? Is it L_P_C residual energy? Is it - is it - Yeah. is it, uh, delta of those things? Uh, what is it no- Obviously, just a simple number - absolute number isn't gonna work. So it should be with - compared to what? Should there be a long window for the normalizing factor and a short window for what you're looking at? Or, you know, how b- short should they be? So, Yeah. th- he's been playing around with a lot of these different things and - and so far at least has not come up with Hmm. any combination that really gave you an indicator. So Yeah. I - I still have a hunch that there's - it's in there some place, but it may be - given that you have a limited time here, it - it just may not be the best thing to - Yeah. to - to focus on for the remaining of it. So pitch-related and harmonic-related, To overrule , yeah. Yeah. I'm - I'm somewhat more hopeful for it. Yeah. But it seems like if we just wanna get something to work, Yeah. that, uh, their suggestion of - of - Yeah. Th- they were suggesting going to Markov models, uh, but in addition there's an expansion of what Javier did. And one of those things, looking at the statistical component, One. Yeah. even if the features that you give it are maybe not ideal for it, it's just sort of this general filter bank or - Yeah. or cepstrum or something, um - Eee it's in there somewhere probably. But, eh, what did you think about the possibility of using the Javier software? Eh, I mean, the, uh - the, uh - the BIC criterion, the - the - t- to train the - the Gaussian, eh, using the - the mark, eh, by hand, eh, eh, to distinguish be- mmm, to train overlapping zone and speech zone. I mean, eh, I - I - I think that an interesting, eh, experiment, eh, could be, th- eh, to prove that, mmm, if s- we suppose that, eh, the - the first step - I mean, the - the classifier what were the classifier from Javier or classifier from Thilo? W- What happen with the second step? I - I mean, what - what happen with the, eh - the, uh, clu- the, uh - the clu- the clustering process? Mm-hmm. Using the - the Gaussian. Yeah. You mean Javier's? What do you mean? I - I mean, that is - is enough - is enough, eh, to work well, eh, to, eh, separate or to distinguish, eh, between overlapping zone and, eh, speaker zone? Because th- if - if we - if we, eh, nnn, develop an classifier - I - and the second step doesn't work well, eh, we have another problem. N- Yeah. I had tried doing it by hand at one point with a very short sample, and it worked pretty well, but I haven't worked with it a lot. So what I d- I d- I took a hand-segmented sample and I added Nnn, yeah. ten times the amount of numbers at random, Yeah. Oh. and it did pick out Yeah. But is - is - if - pretty good boundaries. But this was just very anecdotal sort of thing. But it's possible with my segmentation by hand that we have information about the - the overlapping, uh - Yeah. Right. So if we - if we fed the hand-segmentation to Javier's The - N- n- Yeah. No. and it doesn't work, then we know something's wrong. The demonstration by hand. Segmentation by hand I - I - I think is the fast experiment. Yeah. I think that's probably worthwhile doing. Uh-huh. Uh, we can prove that the - Whether it'll work or not. Yeah. this kind o- Yeah. emph- emphasizes parameter and Gaussian - Yep. Y- do you know where his software is? Have you used it at all? I yeah have. I have. O_K. So. I - I have as well, so if you need - need help let me know. O_K. Let's read some digits. O_K. Mm-hmm. uuh Transcript two nine five one two nine seven O_. six O_ three O_ nine seven eight zero O_ one five O_ two zero five eight four uh, one six two eight five eight three two three three O_ three one five four five zero nine nine seven one one two eight four zero zero nine four O_ seven one zero one two four one five three one two six seven two O_ - Pa- Uh, correct that. six seven two one O_ eight six. Transcript two eight seven one dash two eight nine zero. three three eight four four six five two five eight zero six seven eight zero O_ one four zero one one eight one three one one six two five three four six eight one three four five zero six zero one seven one one two eight three three six O_ eight O_ nine six five O_ seven three eight zero eight six nine one two O_ two. Transcript two eight three one dash two eight five zero. one eight six seven zero six five two three four zero six one seven seven six three eight five one nine seven seven five six O_ zero zero one three two O_ eight four four five five O_ six seven eight O_ seven eight nine zero zero five one three three five O_ O_ five. O_K. Transcript two seven nine one dash two eight one zero. O_ zero two three seven three three two four seven five three O_ two six seven eight zero eight O_ one O_ seven zero three one five O_ three six two eight O_ O_ three four five zero two zero zero seven two O_ three three one seven eight nine five one two two zero nine eight five three O_ seven O_ eight. Transcript two eight one one dash two eight three zero. zero six one two zero five zero zero eight four four one zero one five six six seven four seven eight nine O_ one two nine four eight five nine two two zero three three six four nine five six seven nine seven nine eight three five zero O_ two seven nine five one five zero eight two five four. Transcript number two seven seven one two seven nine zero. nine O_ nine eight nine zero one five zero one two two eight eight four five two five O_ O_ three eight two four five six zero zero eight eight one nine five six six O_ five O_ two one eight seven zero seven zero two nine one two three zero zero five three six three five two four seven seven six four eight six two eight zero nine. And we are - That's hard to focus on that, you know, really, it's like - "alright, now where am I?" 